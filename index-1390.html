<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="This is a snapshot site for StackOverflow">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>StackOverflow Snapshot (old posts, page 1390) | StackOverflow Snapshot</title>
<link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="canonical" href="https://ohstackoverflow.netlify.app/index-1390.html">
<link rel="prev" href="index-1391.html" type="text/html">
<link rel="next" href="index-1389.html" type="text/html">
<!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]-->
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://ohstackoverflow.netlify.app/">

                <span id="blog-title">StackOverflow Snapshot</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="archive.html">Archive</a>
                </li>
<li>
<a href="categories/">Tags</a>

                
            </li>
</ul>
<ul class="nav navbar-nav navbar-right">
<div style="display:table;min-height:5rem;min-width:27rem;">
					<div class="input-group" style="display: table-cell;vertical-align: middle;">
						<input id="words" type="text" class="form-control" style="max-width:22rem;" onkeydown="if(event.keyCode==13){btn.click()}"><span class="input-group-btn" style="float:left">
							<button id="btn" class="btn btn-default" type="button" data-toggle="modal" data-target="#myModal">
								<span class="glyphicon glyphicon-search">
							</span></button>
						</span>
					</div>
<!-- /input-group -->
				</div>

				
                
                
                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><!-- 模态框（Modal） --><div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true">
	<div class="modal-dialog">
		<div class="modal-content">
			<div class="modal-header">
				<button type="button" class="close" data-dismiss="modal" aria-hidden="true">×
				</button>
				<h4 class="modal-title" id="myModalLabel">
					查找结果
				</h4>
			</div>
			<div class="modal-body">
				<div id="search-count" style="min-height:4rem;">
				查找中，请稍后...
				</div>
				<div id="search-result">
				</div>

				
			</div>
			<div class="modal-footer">
				<button type="button" class="btn btn-default" data-dismiss="modal">
					关闭
				</button>
			</div>
		</div>
<!-- /.modal-content -->
	</div>
<!-- /.modal-dialog -->
</div>
<!-- /.modal -->

<div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            

    


    
<div class="postindex">
    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/difference-between-a-linear-problem-and-a-non-linear-problem-essence-of-dot-product-and-kernel-trick/" class="u-url">Difference between a linear problem and a non-linear problem? Essence of Dot-Product and Kernel trick</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="posts/difference-between-a-linear-problem-and-a-non-linear-problem-essence-of-dot-product-and-kernel-trick/" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T02:58:53+08:00" itemprop="datePublished" title="2023-02-28 02:58">2023-02-28 02:58</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>The kernel trick maps a non-linear problem into a linear problem.</p>
<p>My questions are:<br>
1. What is the main difference between a linear and a non-linear problem?
What is the intuition behind the difference of these two classes of problem?
And How does kernel trick helps use the linear classifiers on a non-linear
problem?<br>
2. Why is the dot product so important in the two cases?</p>
<p>Thanks.</p>
<p><br><br></p>
<h2>Answer</h2>
<p>Many classifiers, among them the linear Support Vector Machine (SVM), can only
solve problems that are linearly separable, i.e. where the points belonging to
class 1 can be separated from the points belonging to class 2 by a hyperplane.</p>
<p>In many cases, a problem that is not linearly separable can be solved by
applying a transform phi() to the data points; this transform is said to
transform the points to <em>feature space</em>. The hope is that, in feature space,
the points will be linearly separable. (Note: This is not the kernel trick
yet... stay tuned.)</p>
<p>It can be shown that, the higher the dimension of the feature space, the
greater the number of problems that are linearly separable in that space.
Therefore, one would ideally want the feature space to be as high-dimensional
as possible.</p>
<p>Unfortunately, as the dimension of feature space increases, so does the amount
of computation required. This is where the kernel trick comes in. Many machine
learning algorithms (among them the SVM) can be formulated in such a way that
the only operation they perform on the data points is a scalar product between
two data points. (I will denote a scalar product between x1 and x2 by <code>&lt;x1,
x2&gt;</code>.)</p>
<p>If we transform our points to feature space, the scalar product now looks like
this:</p>
<p><code>&lt;phi(x1), phi(x2)&gt;</code></p>
<p>The key insight is that there exists a class of functions called <em>kernels</em>
that can be used to optimize the computation of this scalar product. A kernel
is a function <code>K(x1, x2)</code> that has the property that</p>
<p><code>K(x1, x2) = &lt;phi(x1), phi(x2)&gt;</code></p>
<p>for some function phi(). In other words: We can evaluate the scalar product in
the low-dimensional data space (where x1 and x2 "live") without having to
transform to the high-dimensional feature space (where phi(x1) and phi(x2)
"live") -- but we still get the benefits of transforming to the high-
dimensional feature space. This is called the <em>kernel trick</em>.</p>
<p>Many popular kernels, such as the Gaussian kernel, actually correspond to a
transform phi() that transforms into an <em>infinte-dimensional</em> feature space.
The kernel trick allows us to compute scalar products in this space without
having to represent points in this space explicitly (which, obviously, is
impossible on computers with finite amounts of memory).</p>
<p><br></p>
<h3>Suggest</h3>
<p>Many classifiers, among them the linear Support Vector Machine (SVM), can only
solve problems that are linearly separable, i.e. where the points belonging to
class 1 can be separated from the points belonging to class 2 by a hyperplane.</p>
<p>In many cases, a problem that is not linearly separable can be solved by
applying a transform phi() to the data points; this transform is said to
transform the points to <em>feature space</em>. The hope is that, in feature space,
the points will be linearly separable. (Note: This is not the kernel trick
yet... stay tuned.)</p>
<p>It can be shown that, the higher the dimension of the feature space, the
greater the number of problems that are linearly separable in that space.
Therefore, one would ideally want the feature space to be as high-dimensional
as possible.</p>
<p>Unfortunately, as the dimension of feature space increases, so does the amount
of computation required. This is where the kernel trick comes in. Many machine
learning algorithms (among them the SVM) can be formulated in such a way that
the only operation they perform on the data points is a scalar product between
two data points. (I will denote a scalar product between x1 and x2 by <code>&lt;x1,
x2&gt;</code>.)</p>
<p>If we transform our points to feature space, the scalar product now looks like
this:</p>
<p><code>&lt;phi(x1), phi(x2)&gt;</code></p>
<p>The key insight is that there exists a class of functions called <em>kernels</em>
that can be used to optimize the computation of this scalar product. A kernel
is a function <code>K(x1, x2)</code> that has the property that</p>
<p><code>K(x1, x2) = &lt;phi(x1), phi(x2)&gt;</code></p>
<p>for some function phi(). In other words: We can evaluate the scalar product in
the low-dimensional data space (where x1 and x2 "live") without having to
transform to the high-dimensional feature space (where phi(x1) and phi(x2)
"live") -- but we still get the benefits of transforming to the high-
dimensional feature space. This is called the <em>kernel trick</em>.</p>
<p>Many popular kernels, such as the Gaussian kernel, actually correspond to a
transform phi() that transforms into an <em>infinte-dimensional</em> feature space.
The kernel trick allows us to compute scalar products in this space without
having to represent points in this space explicitly (which, obviously, is
impossible on computers with finite amounts of memory).</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/algorithm-and-data-structure-for-solving-the-game-globs-flood-fill-floodit/" class="u-url">Algorithm and data structure for solving the game "Globs"/flood fill/"FloodIt"</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="posts/algorithm-and-data-structure-for-solving-the-game-globs-flood-fill-floodit/" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T02:58:31+08:00" itemprop="datePublished" title="2023-02-28 02:58">2023-02-28 02:58</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>Suggest an algorithm and data structure for solving the game Globs
(http://www.deadwhale.com/play.php?game=131). It's pretty fun in a geeky kind
of way.</p>
<p><strong>State the time-space complexity (big-O) of your approach in terms of N</strong> ,
the size of the grid (N&gt;=14). <strong>Good-enough efficient algorithms with low
complexity are preferred.</strong></p>
<p>(MatrixFrog correctly points out this game is also known as FloodIt, and
Smashery gave a solution 3 months ago in the link he cites below. All you
dudes suggesting pruning/greedy with only 1 lookahead, that gives suboptimal
solutions.)</p>
<p>The game generates a random square grid of nxn nodes, where each node is
colored one of six colors (Grn=1, Ylw=2, Red=3, Blu=4, Pur=5, Orn=6). Level 1
has 9x9 grid, then n increases each level, up to 14. Each level you can take
up to 25 turns or else you lose. On each turn you choose which color to change
the top left node to e.g. Grn-&gt;Red, such that any connected adjacent
(horiz/vert) nodes of the new color get assimilated into a shape, and 1 pt per
node assimilated is ADDED to your score. The scoring objective is to complete
each grid in as few turns as possible, e.g. if you do it in 16 turns, then
your 9 unused moves =&gt; 2*9 MULTIPLIER times your total accumulated score.</p>
<p>Obviously there are a ton of ways to decompose this, and the default choice of
recursive backtracking with a 14x14 grid is a viable contender; What other
types of data structures does this lend itself to? A* ? Don't get hung up on
optimality, I'm wondering if there is a "good-enough" algorithm.</p>
<p>(I thought it might be a fun project to code up a robot and get silly-high
scores. Although I scored 3.5E+12 all by my fleshware self.)</p>
<p><br><br></p>
<h2>Answer</h2>
<p>This game really grabbed my interest, so I spent a couple of days working on
it.</p>
<p>The first thing I noticed, is that it is easy to show that after the first
board (maybe 2 in some cases), the fastest way to raise the score is by using
the multiplier. Because of this, I built a system with the goal of solving
each board in the fewest number of steps. I started out wanting to use A*
because it is generally built for just these types of search problems...
however, this problem still turned out to be a doozie.</p>
<p>When talking about A<em>, the effectiveness of it really boils down your choice
of heuristic estimation. The closer you get to guessing the actual distance,
the fewer nodes that will have to be expanded in order to reach the goal. For
this problem, I went through a number of ideas for estimation, but most of
them broke the A</em> rule, which is that you can NOT over estimate the actual
distance, or else you break the optimality of A*.</p>
<p>There are a few that work however. Others in this thread have posted about
just taking the number of remaining colors as the estimation, which is
admissible because it cannot over estimate (you have to change colors at least
once for each remaining color not part of the main "flood" area. The problem
with this heuristic is that it very poorly estimates the actual distance. Take
for instance the first move, which generally has an estimation of the number
of colors, 6. It often expands into 2 moves, each of which generally has an
estimation of 7, and so on and so on. Take this 5 levels deep and for a board
size of 10x10, most leafs have an estimation of 11. This heuristic is
basically an implementation of a breadth first search until you reach within 4
or 5 moves from your goal. This is not very efficient and in my own tests, the
exponents run a much around board size 9, which often requires about 14 moves
in the solution. It should be noted my solution was very high level however
and not much care was taken to speed things up.</p>
<p>The problem is that A<em> is really only good when each step makes a significant
refinement to the actual distance of the overall solution. Looking at the
problem directly, you probably wont find a good heuristic that can do much
better than this without over estimating the cost. However, if you transform
the problem into another problem, better heuristics jump out at you. The
heuristic "number of colors remaining" is answering the question, what is the
smallest number of possible moves remaining. To the answer that question, I
asked myself "which spot on the board requires the maximum number of steps to
get to"? I ended up settling on the answer to "how many steps is it to the
bottom right corner" for my heuristic. This is fairly easy to implement by
running another A</em> search that works more like finding map directions and then
counting the number of steps in the solution. I realize this is an arbitrary
point on the board to select, however it worked quite well in testing and
running A* on every remaining point took a fair amount of time on my single
processor test machine.</p>
<p>This heuristic alone had a tendency to collapse after the bottom right corner
became part of the flooded area however, so the final result was MAX(bottom
right corner min steps, number of colors remaining not part of main flood).
This was finally able to achieve some very large board sizes in under a second
with my high level implementation.</p>
<p>I'll leave the record setting to you.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/alpha-beta-prunning-with-transposition-table-iterative-deepening/" class="u-url">Alpha-beta prunning with transposition table, iterative deepening</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="posts/alpha-beta-prunning-with-transposition-table-iterative-deepening/" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T02:58:14+08:00" itemprop="datePublished" title="2023-02-28 02:58">2023-02-28 02:58</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>I'm trying to implement alpha-beta min-max prunning enhanced with
transposition tables. I use this pseudocode as reference:</p>
<p>http://people.csail.mit.edu/plaat/mtdf.html#abmem</p>
<div class="code"><pre class="code literal-block"><span class="k">function</span><span class="w"> </span><span class="nf">AlphaBetaWithMemory</span><span class="p">(</span>n : node_type; alpha , beta , d : integer<span class="p">)</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="n">integer</span><span class="p">;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">retrieve</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">OK</span><span class="w"> </span><span class="n">then</span><span class="w"> </span><span class="o">/*</span><span class="w"> </span><span class="n">Transposition</span><span class="w"> </span><span class="nb">table</span><span class="w"> </span><span class="n">lookup</span><span class="w"> </span><span class="o">*/</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">n</span><span class="p">.</span><span class="n">lowerbound</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="nb">beta</span><span class="w"> </span><span class="n">then</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">n</span><span class="p">.</span><span class="n">lowerbound</span><span class="p">;</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">n</span><span class="p">.</span><span class="n">upperbound</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="nb">alpha</span><span class="w"> </span><span class="n">then</span><span class="w"> </span><span class="k">return</span><span class="w"> </span><span class="n">n</span><span class="p">.</span><span class="n">upperbound</span><span class="p">;</span>
<span class="w">        </span><span class="n">alpha</span><span class="w"> </span><span class="s">:=</span><span class="w"> </span><span class="s">max(alpha,</span><span class="w"> </span><span class="s">n.lowerbound)</span><span class="p">;</span>
<span class="w">        </span><span class="n">beta</span><span class="w"> </span><span class="s">:=</span><span class="w"> </span><span class="s">min(beta,</span><span class="w"> </span><span class="s">n.upperbound)</span><span class="p">;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">d</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="n">then</span><span class="w"> </span><span class="n">g</span><span class="w"> </span><span class="p">:=</span><span class="w"> </span><span class="n">evaluate</span><span class="p">(</span><span class="n">n</span><span class="p">);</span><span class="w"> </span><span class="o">/*</span><span class="w"> </span><span class="n">leaf</span><span class="w"> </span><span class="n">node</span><span class="w"> </span><span class="o">*/</span>
<span class="w">    </span><span class="k">else</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="n">MAXNODE</span><span class="w"> </span><span class="n">then</span>
<span class="w">        </span><span class="n">g</span><span class="w"> </span><span class="p">:=</span><span class="w"> </span><span class="o">-</span><span class="n">INFINITY</span><span class="p">;</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="s">:=</span><span class="w"> </span><span class="s">alpha</span><span class="p">;</span><span class="w"> </span><span class="o">/*</span><span class="w"> </span><span class="nb">save</span><span class="w"> </span><span class="n">original</span><span class="w"> </span><span class="nb">alpha</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="o">*/</span>
<span class="w">        </span><span class="n">c</span><span class="w"> </span><span class="p">:=</span><span class="w"> </span><span class="n">firstchild</span><span class="p">(</span><span class="n">n</span><span class="p">);</span>
<span class="w">        </span><span class="k">while</span><span class="w"> </span><span class="p">(</span><span class="n">g</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="nb">beta</span><span class="p">)</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="p">(</span><span class="n">c</span><span class="w"> </span>!<span class="p">=</span><span class="w"> </span><span class="n">NOCHILD</span><span class="p">)</span><span class="w"> </span><span class="n">do</span>
<span class="w">            </span><span class="n">g</span><span class="w"> </span><span class="p">:=</span><span class="w"> </span><span class="nb">max</span><span class="p">(</span><span class="n">g</span><span class="p">,</span><span class="w"> </span><span class="n">AlphaBetaWithMemory</span><span class="p">(</span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="nb">beta</span><span class="p">,</span><span class="w"> </span><span class="n">d</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">));</span>
<span class="w">            </span><span class="n">a</span><span class="w"> </span><span class="s">:=</span><span class="w"> </span><span class="s">max(a,</span><span class="w"> </span><span class="s">g)</span><span class="p">;</span>
<span class="w">            </span><span class="n">c</span><span class="w"> </span><span class="s">:=</span><span class="w"> </span><span class="s">nextbrother(c)</span><span class="p">;</span>
<span class="w">    </span><span class="k">else</span><span class="w"> </span><span class="o">/*</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="n">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">MINNODE</span><span class="w"> </span><span class="o">*/</span>
<span class="w">        </span><span class="n">g</span><span class="w"> </span><span class="p">:=</span><span class="w"> </span><span class="o">+</span><span class="n">INFINITY</span><span class="p">;</span><span class="w"> </span><span class="n">b</span><span class="w"> </span><span class="s">:=</span><span class="w"> </span><span class="s">beta</span><span class="p">;</span><span class="w"> </span><span class="o">/*</span><span class="w"> </span><span class="nb">save</span><span class="w"> </span><span class="n">original</span><span class="w"> </span><span class="nb">beta</span><span class="w"> </span><span class="n">value</span><span class="w"> </span><span class="o">*/</span>
<span class="w">        </span><span class="n">c</span><span class="w"> </span><span class="p">:=</span><span class="w"> </span><span class="n">firstchild</span><span class="p">(</span><span class="n">n</span><span class="p">);</span>
<span class="w">        </span><span class="k">while</span><span class="w"> </span><span class="p">(</span><span class="n">g</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="nb">alpha</span><span class="p">)</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="p">(</span><span class="n">c</span><span class="w"> </span>!<span class="p">=</span><span class="w"> </span><span class="n">NOCHILD</span><span class="p">)</span><span class="w"> </span><span class="n">do</span>
<span class="w">            </span><span class="n">g</span><span class="w"> </span><span class="p">:=</span><span class="w"> </span><span class="nb">min</span><span class="p">(</span><span class="n">g</span><span class="p">,</span><span class="w"> </span><span class="n">AlphaBetaWithMemory</span><span class="p">(</span><span class="n">c</span><span class="p">,</span><span class="w"> </span><span class="nb">alpha</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">,</span><span class="w"> </span><span class="n">d</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">));</span>
<span class="w">            </span><span class="n">b</span><span class="w"> </span><span class="s">:=</span><span class="w"> </span><span class="s">min(b,</span><span class="w"> </span><span class="s">g)</span><span class="p">;</span>
<span class="w">            </span><span class="n">c</span><span class="w"> </span><span class="s">:=</span><span class="w"> </span><span class="s">nextbrother(c)</span><span class="p">;</span>

<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">g</span><span class="w"> </span><span class="o">&lt;=</span><span class="w"> </span><span class="nb">alpha</span><span class="w"> </span><span class="n">then</span><span class="w"> </span>
<span class="w">        </span><span class="n">n</span><span class="p">.</span><span class="n">upperbound</span><span class="w"> </span><span class="p">:=</span><span class="w"> </span><span class="n">g</span><span class="p">;</span><span class="w"> </span>
<span class="w">        </span><span class="n">store</span><span class="w"> </span><span class="s">n.upperbound</span><span class="p">;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">g</span><span class="w"> </span><span class="o">&gt;</span><span class="w">  </span><span class="nb">alpha</span><span class="w"> </span><span class="n">and</span><span class="w"> </span><span class="n">g</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="nb">beta</span><span class="w"> </span><span class="n">then</span>
<span class="w">        </span><span class="n">n</span><span class="p">.</span><span class="n">lowerbound</span><span class="w"> </span><span class="p">:=</span><span class="w"> </span><span class="n">g</span><span class="p">;</span><span class="w"> </span>
<span class="w">        </span><span class="n">n</span><span class="p">.</span><span class="n">upperbound</span><span class="w"> </span><span class="p">:=</span><span class="w"> </span><span class="n">g</span><span class="p">;</span><span class="w"> </span>
<span class="w">        </span><span class="n">store</span><span class="w"> </span><span class="s">n.lowerbound,</span><span class="w"> </span><span class="s">n.upperbound</span><span class="p">;</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="n">g</span><span class="w"> </span><span class="o">&gt;=</span><span class="w"> </span><span class="nb">beta</span><span class="w"> </span><span class="n">then</span><span class="w"> </span>
<span class="w">        </span><span class="n">n</span><span class="p">.</span><span class="n">lowerbound</span><span class="w"> </span><span class="p">:=</span><span class="w"> </span><span class="n">g</span><span class="p">;</span><span class="w"> </span>
<span class="w">        </span><span class="n">store</span><span class="w"> </span><span class="s">n.lowerbound</span><span class="p">;</span>
<span class="k">return</span><span class="w"> </span><span class="n">g</span><span class="p">;</span>
</pre></div>

<p>Three questions to this algorithm:</p>
<ol>
<li>
<p>I belive that I should store depth (=distance to leaf level) with each saved transposition table entry and use entry only when entry.depth&gt;=currentDepth (= entry is more or equal distant from leaves level). That is not shown in above pseudocode and is not discussed there, I wanted to make sure I understand that correctly.</p>
</li>
<li>
<p>I would like to store best move for each position to use it for move ordering AND extracting best move after the search stops. In pure min-max it's obvious which move is the best, but which move is the best when iterating with alpha-beta cutoffs? Can I assume that the best move for given position is the best move found when the loop ends (with cut-off or without)?</p>
</li>
<li>
<p>When executing this algorithm in iterative deepening scheme - should I clear transposition table before each depth increase? I think not, I'd like tu use stored position from previous iteration, but I'm not sure if the information is adequate for deeper searches (It should be when checking table entry depth)? </p>
</li>
</ol>
<p><br><br></p>
<h2>Answer</h2>
<ol>
<li>You're right. <code>entry.depth</code> stores the number of plies the information in the transposition table entry are based on. So you can use those information only when <code>entry.depth &gt;= remaining_depth</code>.</li>
</ol>
<p>The logic is that we don't want to use a result weaker than the "normal"
search.</p>
<p>Sometimes, for debugging purpose, the condition is changed to:</p>
<div class="code"><pre class="code literal-block">    entry.depth == remaining_depth
</pre></div>

<p>this avoids some search instabilities. Anyway it doesn't guarantee the same
result of a search without transposition table.</p>
<ol>
<li>There isn't always a best move to store.</li>
</ol>
<p>When the search fails low, there isn't a "best move". The only thing we know
is that no move is good enough to produce a score bigger than <code>alpha</code>. There
is no way to guess which move is best.</p>
<p>So you should store a move in the hash table only for lower bounds (beta-
cutoff i.e. a refutation move) and exact scores (PV node).</p>
<ol>
<li>No, you shouldn't. With iterative deepening the same position is reached again and again and the transposition table can speed up the search.</li>
</ol>
<p>You should clear the transposition table between moves (or, better, use an
additional <code>entry.age</code> field).</p>
    </div>
    </article>
</div>

        <nav class="postindexpager"><ul class="pager">
<li class="previous">
                <a href="index-1391.html" rel="prev">Newer posts</a>
            </li>
            <li class="next">
                <a href="index-1389.html" rel="next">Older posts</a>
            </li>
        </ul></nav>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2023         Go to StackOverflow Chinese Site  <a href="http://stackoverflow.ink">StackOverflow-ZH</a>  
            
        </footer>
</div>
</div>


            <script src="assets/js/all-nocdn.js"></script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script><script src="assets/js/search.js"></script>
</body>
</html>
