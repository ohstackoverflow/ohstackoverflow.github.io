<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="This is a snapshot site for StackOverflow">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>StackOverflow Snapshot (old posts, page 1378) | StackOverflow Snapshot</title>
<link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="canonical" href="https://ohstackoverflow.netlify.app/index-1378.html">
<link rel="prev" href="index-1379.html" type="text/html">
<link rel="next" href="index-1377.html" type="text/html">
<!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]-->
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://ohstackoverflow.netlify.app/">

                <span id="blog-title">StackOverflow Snapshot</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="archive.html">Archive</a>
                </li>
<li>
<a href="categories/">Tags</a>

                
            </li>
</ul>
<ul class="nav navbar-nav navbar-right">
<div style="display:table;min-height:5rem;min-width:27rem;">
					<div class="input-group" style="display: table-cell;vertical-align: middle;">
						<input id="words" type="text" class="form-control" style="max-width:22rem;" onkeydown="if(event.keyCode==13){btn.click()}"><span class="input-group-btn" style="float:left">
							<button id="btn" class="btn btn-default" type="button" data-toggle="modal" data-target="#myModal">
								<span class="glyphicon glyphicon-search">
							</span></button>
						</span>
					</div>
<!-- /input-group -->
				</div>

				
                
                
                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><!-- 模态框（Modal） --><div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true">
	<div class="modal-dialog">
		<div class="modal-content">
			<div class="modal-header">
				<button type="button" class="close" data-dismiss="modal" aria-hidden="true">×
				</button>
				<h4 class="modal-title" id="myModalLabel">
					查找结果
				</h4>
			</div>
			<div class="modal-body">
				<div id="search-count" style="min-height:4rem;">
				查找中，请稍后...
				</div>
				<div id="search-result">
				</div>

				
			</div>
			<div class="modal-footer">
				<button type="button" class="btn btn-default" data-dismiss="modal">
					关闭
				</button>
			</div>
		</div>
<!-- /.modal-content -->
	</div>
<!-- /.modal-dialog -->
</div>
<!-- /.modal -->

<div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            

    


    
<div class="postindex">
    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/how-to-utilize-hebbian-learning/" class="u-url">How to utilize Hebbian learning?</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="posts/how-to-utilize-hebbian-learning/" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T02:46:07+08:00" itemprop="datePublished" title="2023-02-28 02:46">2023-02-28 02:46</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>I want to upgrade my evolution simulator to use Hebb learning, like this one.
I basically want small creatures to be able to learn how to find food. I
achieved that with the basic feedforward networks, but I'm stuck at
understanding how to do it with Hebb learning. The basic principle of Hebb
learning is that, if two neurons fire together, they wire together.</p>
<p>So, the weights are updated like this:</p>
<div class="code"><pre class="code literal-block">weight_change = learning_rate * input * output
</pre></div>

<p>The information I've found on how this can be useful is pretty scarce, and I
don't get it.</p>
<p>In my current version of the simulator, the weights between an action and an
input (movement, eyes) are increased when a creature eats a piece of food, and
I fail to see how that can translate into this new model. There simply is no
room to tell if it did something right or wrong here, because the only
parameters are input and output! Basically, if one input activates movement in
one direction, the weight would just keep on increasing, no matter if the
creature is eating something or not!</p>
<p>Am I applying Hebb learning in a wrong way? Just for reference, I'm using
Python.</p>
<p><br><br></p>
<h2>Answer</h2>
<p><code>Hebbs law</code> is a brilliant insight for <code>associative learning</code>, but its only
part of the picture. And you are right, implemented as you have done, and left
unchecked a weight will just keep on increasing. The key is to add in some
form of normalisation or limiting process. This is illustrated quite well of
the wiki page for Oja's rule. What I suggest you do is add in a <code>post-synaptic
divisive normalisation</code> step, what this means is that you divide through a
weight by the sum of all the weights converging on the same post-synaptic
neuron (i.e. the sum of all weights converging on a neuron is fixed at <code>1</code>).</p>
<p>What you want to do can be done by building a network that utilises <code>Hebbian
learning</code>. I'm not quite sure on what you are passing in as input into your
system, or how you've set things up. But you could look at <code>LISSOM</code> which is
an Hebbian extension to SOM, (self-organising map).</p>
<p>In a layer of this kind typically all the neurons may be interconnected. You
pass in the input vector, and allow the activity in the network to settle,
this is some number of settling steps. Then you update the weights. You do
this during the training phase, at the end of which associated items in the
input space will tend to form grouped activity patches in the output map.</p>
<p>It's also worth noting that the brain is massively interconnected, and highly
recursive (i.e. there is feedforward, feedback, lateral interconnectivity,
microcircuits, and a lot of other stuff too..).</p>
<p><br></p>
<h3>Suggest</h3>
<p>Although Hebbian learning, as a general concept, forms the basis for many
learning algorithms, including backpropagation, the simple, linear formula
which you use is very limited. Not only do weights rise infinitely, even when
the network has learned all the patterns, but the network can perfectly learn
only orthogonal (linearly independent) patterns.</p>
<p>Linear Hebbian learning is not even biologically plausible. Biological neural
networks are much bigger than yours and are highly non-linear, both the
neurons and the synapses between them. In big, non-linear networks, the
chances that your patterns are close to orthogonal are higher.</p>
<p>So, if you insist on using a neural network, I suggest adding hidden layers of
neurons and introducing non-linearities, both in the weights, e.g. as fraxel
proposed, and in firing of neurons---here you might use a sigmoid function,
like <code>tanh</code> (yes, using negative values for "non-firing" is good since it can
lead to reducing weights). In its generalized form, Hebbian rule can be
expressed as</p>
<div class="code"><pre class="code literal-block">weight_change = learning_rate * f1(input, weight) * f2(output, target_output)
</pre></div>

<p>where <code>f1</code> and <code>f2</code> are some functions. In your case, there is no
<code>target_output</code>, so <code>f2</code> is free to ignore it.</p>
<p>In order to have neurons in your hidden layers fire, and thus to get a
connection between input and output, you can initialize the weights to random
values.</p>
<p>But is a neural network really necessary, or even suitable for your problem?
Have you considered simple correlation? I mean, Hebb derived his rule to
explain how learning might function in biological systems, not as the best
possible machine learning algorithm.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/good-implementations-of-reinforcement-learning/" class="u-url">Good implementations of reinforcement learning?</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="posts/good-implementations-of-reinforcement-learning/" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T02:45:45+08:00" itemprop="datePublished" title="2023-02-28 02:45">2023-02-28 02:45</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>For an ai-class project I need to implement a reinforcement learning algorithm
which beats a simple game of tetris. The game is written in Java and we have
the source code. I know the basics of reinforcement learning theory but was
wondering if anyone in the SO community had hands on experience with this type
of thing.</p>
<ol>
<li>What would your recommended readings be for an implementation of reinforced learning in a tetris game?</li>
<li>Are there any good open source projects that accomplish similar things that would be worth checking out?</li>
</ol>
<p>Edit: The more specific the better, but general resources about the subject
are welcomed.</p>
<p><strong>Follow up:</strong></p>
<p>Thought it would be nice if I posted a followup.</p>
<p>Here's the solution (code and writeup) I ended up with for any future students
:).</p>
<p><strong>Paper</strong> / <strong>Code</strong></p>
<p><br><br></p>
<h2>Answer</h2>
<p>Take a look at the 2009 RL-competition. One of the problem domains is a tetris
game. There was a tetris problem the year before too. Here’s the 52-page final
report from that year’s fifth-place finalist, which goes into a lot of detail
about how the agent worked.</p>
<p><br></p>
<h3>Suggest</h3>
<p>The Heaton Research ebook is quite good at explaining neural network concepts
(with code). Chapter 4 is dedicated to machine learning and the various
training methods for your networks. There is a downloadable library and sample
applications for you to look at.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/what-is-energy-in-image-processing/" class="u-url">What is "energy" in image processing?</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="posts/what-is-energy-in-image-processing/" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T02:45:17+08:00" itemprop="datePublished" title="2023-02-28 02:45">2023-02-28 02:45</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>I've read across several Image Processing books and websites, but I'm still
not sure the true definition of the term "energy" in Image Processing. I've
found several definition, but sometimes they just don't match.</p>
<p>When we say "energy" in Image processing, what are we implying?</p>
<p><br><br></p>
<h2>Answer</h2>
<p>There is more than one definition of "energy" in image processing, so it
depends on the context of where it was used.</p>
<p>Energy is used to describe a measure of "information" when formulating an
operation under a probability framework such as MAP (maximum a priori)
estimation in conjunction with Markov Random Fields. Sometimes the energy can
be a negative measure to be minimised and sometimes it is a positive measure
to be maximized.</p>
<p><br></p>
<h3>Suggest</h3>
<p>It depends on the context, but in general, in Signal Processing, "energy"
corresponds to the mean squared value of the signal (typically measured with
respect to the global mean value). This concept is usually associated with the
Parseval theorem, which allows us to think of the total energy as distributed
along "frequencies" (and so one can say, for example, that a image has most of
its energy concentrated in low frequencies).</p>
<p>Another -related- use is in image transforms: for example, the DCT transform
(basis of the JPEG compression method) transforms a blocks of pixels (8x8
image) into a matrix of transformed coefficients; for typical images, it
results that, while the original 8x8 image has its energy evenly distributed
among the 64 pixels, the transformed image has its energy concentrated in the
left-upper "pixels" (which, again, correspond to "low frequencies", in some
analagous sense).</p>
    </div>
    </article>
</div>

        <nav class="postindexpager"><ul class="pager">
<li class="previous">
                <a href="index-1379.html" rel="prev">Newer posts</a>
            </li>
            <li class="next">
                <a href="index-1377.html" rel="next">Older posts</a>
            </li>
        </ul></nav>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2023         Go to StackOverflow Chinese Site  <a href="http://stackoverflow.ink">StackOverflow-ZH</a>  
            
        </footer>
</div>
</div>


            <script src="assets/js/all-nocdn.js"></script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script><script src="assets/js/search.js"></script>
</body>
</html>
