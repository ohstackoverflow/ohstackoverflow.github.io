<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="This is a snapshot site for StackOverflow">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>StackOverflow Snapshot (old posts, page 1356) | StackOverflow Snapshot</title>
<link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="canonical" href="https://ohstackoverflow.netlify.app/index-1356.html">
<link rel="prev" href="index-1357.html" type="text/html">
<link rel="next" href="index-1355.html" type="text/html">
<!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]-->
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://ohstackoverflow.netlify.app/">

                <span id="blog-title">StackOverflow Snapshot</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="archive.html">Archive</a>
                </li>
<li>
<a href="categories/">Tags</a>

                
            </li>
</ul>
<ul class="nav navbar-nav navbar-right">
<div style="display:table;min-height:5rem;min-width:27rem;">
					<div class="input-group" style="display: table-cell;vertical-align: middle;">
						<input id="words" type="text" class="form-control" style="max-width:22rem;" onkeydown="if(event.keyCode==13){btn.click()}"><span class="input-group-btn" style="float:left">
							<button id="btn" class="btn btn-default" type="button" data-toggle="modal" data-target="#myModal">
								<span class="glyphicon glyphicon-search">
							</span></button>
						</span>
					</div>
<!-- /input-group -->
				</div>

				
                
                
                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><!-- 模态框（Modal） --><div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true">
	<div class="modal-dialog">
		<div class="modal-content">
			<div class="modal-header">
				<button type="button" class="close" data-dismiss="modal" aria-hidden="true">×
				</button>
				<h4 class="modal-title" id="myModalLabel">
					查找结果
				</h4>
			</div>
			<div class="modal-body">
				<div id="search-count" style="min-height:4rem;">
				查找中，请稍后...
				</div>
				<div id="search-result">
				</div>

				
			</div>
			<div class="modal-footer">
				<button type="button" class="btn btn-default" data-dismiss="modal">
					关闭
				</button>
			</div>
		</div>
<!-- /.modal-content -->
	</div>
<!-- /.modal-dialog -->
</div>
<!-- /.modal -->

<div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            

    


    
<div class="postindex">
    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/how-to-compute-precision-recall-accuracy-and-f1-score-for-the-multiclass-case-with-scikit-learn/" class="u-url">How to compute precision, recall, accuracy and f1-score for the multiclass case with scikit learn?</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="posts/how-to-compute-precision-recall-accuracy-and-f1-score-for-the-multiclass-case-with-scikit-learn/" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T02:23:55+08:00" itemprop="datePublished" title="2023-02-28 02:23">2023-02-28 02:23</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>I'm working in a sentiment analysis problem the data looks like this:</p>
<div class="code"><pre class="code literal-block">label instances
    5    1190
    4     838
    3     239
    1     204
    2     127
</pre></div>

<p>So my data is unbalanced since 1190 <code>instances</code> are labeled with <code>5</code>. For the
classification Im using scikit's SVC. The problem is I do not know how to
balance my data in the right way in order to compute accurately the precision,
recall, accuracy and f1-score for the multiclass case. So I tried the
following approaches:</p>
<p>First:</p>
<div class="code"><pre class="code literal-block">    wclf = SVC(kernel='linear', C= 1, class_weight={1: 10})
    wclf.fit(X, y)
    weighted_prediction = wclf.predict(X_test)

print 'Accuracy:', accuracy_score(y_test, weighted_prediction)
print 'F1 score:', f1_score(y_test, weighted_prediction,average='weighted')
print 'Recall:', recall_score(y_test, weighted_prediction,
                              average='weighted')
print 'Precision:', precision_score(y_test, weighted_prediction,
                                    average='weighted')
print '\n clasification report:\n', classification_report(y_test, weighted_prediction)
print '\n confussion matrix:\n',confusion_matrix(y_test, weighted_prediction)
</pre></div>

<p>Second:</p>
<div class="code"><pre class="code literal-block">auto_wclf = SVC(kernel='linear', C= 1, class_weight='auto')
auto_wclf.fit(X, y)
auto_weighted_prediction = auto_wclf.predict(X_test)

print 'Accuracy:', accuracy_score(y_test, auto_weighted_prediction)

print 'F1 score:', f1_score(y_test, auto_weighted_prediction,
                            average='weighted')

print 'Recall:', recall_score(y_test, auto_weighted_prediction,
                              average='weighted')

print 'Precision:', precision_score(y_test, auto_weighted_prediction,
                                    average='weighted')

print '\n clasification report:\n', classification_report(y_test,auto_weighted_prediction)

print '\n confussion matrix:\n',confusion_matrix(y_test, auto_weighted_prediction)
</pre></div>

<p>Third:</p>
<div class="code"><pre class="code literal-block"><span class="n">clf</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">'linear'</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">prediction</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>


<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_score</span><span class="p">,</span> \
    <span class="n">recall_score</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">,</span> \
    <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">f1_score</span>

<span class="nb">print</span> <span class="s1">'Accuracy:'</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span>
<span class="nb">print</span> <span class="s1">'F1 score:'</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span>
<span class="nb">print</span> <span class="s1">'Recall:'</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span>
<span class="nb">print</span> <span class="s1">'Precision:'</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span>
<span class="nb">print</span> <span class="s1">'</span><span class="se">\n</span><span class="s1"> clasification report:</span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">prediction</span><span class="p">)</span>
<span class="nb">print</span> <span class="s1">'</span><span class="se">\n</span><span class="s1"> confussion matrix:</span><span class="se">\n</span><span class="s1">'</span><span class="p">,</span><span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">prediction</span><span class="p">)</span>


<span class="n">F1</span> <span class="n">score</span><span class="p">:</span><span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="n">local</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python2</span><span class="mf">.7</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">sklearn</span><span class="o">/</span><span class="n">metrics</span><span class="o">/</span><span class="n">classification</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">676</span><span class="p">:</span> <span class="ne">DeprecationWarning</span><span class="p">:</span> <span class="n">The</span> <span class="n">default</span> <span class="err">`</span><span class="n">weighted</span><span class="err">`</span> <span class="n">averaging</span> <span class="ow">is</span> <span class="n">deprecated</span><span class="p">,</span> <span class="ow">and</span> <span class="kn">from</span> <span class="nn">version</span> <span class="mf">0.18</span><span class="p">,</span> <span class="n">use</span> <span class="n">of</span> <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span> <span class="ow">or</span> <span class="n">F</span><span class="o">-</span><span class="n">score</span> <span class="k">with</span> <span class="n">multiclass</span> <span class="ow">or</span> <span class="n">multilabel</span> <span class="n">data</span> <span class="ow">or</span> <span class="n">pos_label</span><span class="o">=</span><span class="kc">None</span> <span class="n">will</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">an</span> <span class="n">exception</span><span class="o">.</span> <span class="n">Please</span> <span class="nb">set</span> <span class="n">an</span> <span class="n">explicit</span> <span class="n">value</span> <span class="k">for</span> <span class="err">`</span><span class="n">average</span><span class="err">`</span><span class="p">,</span> <span class="n">one</span> <span class="n">of</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="s1">'micro'</span><span class="p">,</span> <span class="s1">'macro'</span><span class="p">,</span> <span class="s1">'weighted'</span><span class="p">,</span> <span class="s1">'samples'</span><span class="p">)</span><span class="o">.</span> <span class="n">In</span> <span class="n">cross</span> <span class="n">validation</span> <span class="n">use</span><span class="p">,</span> <span class="k">for</span> <span class="n">instance</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">"f1_weighted"</span> <span class="n">instead</span> <span class="n">of</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">"f1"</span><span class="o">.</span>
  <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
<span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="n">local</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python2</span><span class="mf">.7</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">sklearn</span><span class="o">/</span><span class="n">metrics</span><span class="o">/</span><span class="n">classification</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">1172</span><span class="p">:</span> <span class="ne">DeprecationWarning</span><span class="p">:</span> <span class="n">The</span> <span class="n">default</span> <span class="err">`</span><span class="n">weighted</span><span class="err">`</span> <span class="n">averaging</span> <span class="ow">is</span> <span class="n">deprecated</span><span class="p">,</span> <span class="ow">and</span> <span class="kn">from</span> <span class="nn">version</span> <span class="mf">0.18</span><span class="p">,</span> <span class="n">use</span> <span class="n">of</span> <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span> <span class="ow">or</span> <span class="n">F</span><span class="o">-</span><span class="n">score</span> <span class="k">with</span> <span class="n">multiclass</span> <span class="ow">or</span> <span class="n">multilabel</span> <span class="n">data</span> <span class="ow">or</span> <span class="n">pos_label</span><span class="o">=</span><span class="kc">None</span> <span class="n">will</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">an</span> <span class="n">exception</span><span class="o">.</span> <span class="n">Please</span> <span class="nb">set</span> <span class="n">an</span> <span class="n">explicit</span> <span class="n">value</span> <span class="k">for</span> <span class="err">`</span><span class="n">average</span><span class="err">`</span><span class="p">,</span> <span class="n">one</span> <span class="n">of</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="s1">'micro'</span><span class="p">,</span> <span class="s1">'macro'</span><span class="p">,</span> <span class="s1">'weighted'</span><span class="p">,</span> <span class="s1">'samples'</span><span class="p">)</span><span class="o">.</span> <span class="n">In</span> <span class="n">cross</span> <span class="n">validation</span> <span class="n">use</span><span class="p">,</span> <span class="k">for</span> <span class="n">instance</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">"f1_weighted"</span> <span class="n">instead</span> <span class="n">of</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">"f1"</span><span class="o">.</span>
  <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
<span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="n">local</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python2</span><span class="mf">.7</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">sklearn</span><span class="o">/</span><span class="n">metrics</span><span class="o">/</span><span class="n">classification</span><span class="o">.</span><span class="n">py</span><span class="p">:</span><span class="mi">1082</span><span class="p">:</span> <span class="ne">DeprecationWarning</span><span class="p">:</span> <span class="n">The</span> <span class="n">default</span> <span class="err">`</span><span class="n">weighted</span><span class="err">`</span> <span class="n">averaging</span> <span class="ow">is</span> <span class="n">deprecated</span><span class="p">,</span> <span class="ow">and</span> <span class="kn">from</span> <span class="nn">version</span> <span class="mf">0.18</span><span class="p">,</span> <span class="n">use</span> <span class="n">of</span> <span class="n">precision</span><span class="p">,</span> <span class="n">recall</span> <span class="ow">or</span> <span class="n">F</span><span class="o">-</span><span class="n">score</span> <span class="k">with</span> <span class="n">multiclass</span> <span class="ow">or</span> <span class="n">multilabel</span> <span class="n">data</span> <span class="ow">or</span> <span class="n">pos_label</span><span class="o">=</span><span class="kc">None</span> <span class="n">will</span> <span class="n">result</span> <span class="ow">in</span> <span class="n">an</span> <span class="n">exception</span><span class="o">.</span> <span class="n">Please</span> <span class="nb">set</span> <span class="n">an</span> <span class="n">explicit</span> <span class="n">value</span> <span class="k">for</span> <span class="err">`</span><span class="n">average</span><span class="err">`</span><span class="p">,</span> <span class="n">one</span> <span class="n">of</span> <span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="s1">'micro'</span><span class="p">,</span> <span class="s1">'macro'</span><span class="p">,</span> <span class="s1">'weighted'</span><span class="p">,</span> <span class="s1">'samples'</span><span class="p">)</span><span class="o">.</span> <span class="n">In</span> <span class="n">cross</span> <span class="n">validation</span> <span class="n">use</span><span class="p">,</span> <span class="k">for</span> <span class="n">instance</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">"f1_weighted"</span> <span class="n">instead</span> <span class="n">of</span> <span class="n">scoring</span><span class="o">=</span><span class="s2">"f1"</span><span class="o">.</span>
  <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
 <span class="mf">0.930416613529</span>
</pre></div>

<p>However, Im getting warnings like this:</p>
<div class="code"><pre class="code literal-block"><span class="o">/</span><span class="n">usr</span><span class="o">/</span><span class="k">local</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python2</span><span class="mf">.7</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">sklearn</span><span class="o">/</span><span class="n">metrics</span><span class="o">/</span><span class="n">classification</span><span class="p">.</span><span class="n">py</span><span class="o">:</span><span class="mi">1172</span><span class="o">:</span>
<span class="n">DeprecationWarning</span><span class="o">:</span><span class="w"> </span><span class="n">The</span><span class="w"> </span><span class="k">default</span><span class="w"> </span><span class="n n-Quoted">`weighted`</span><span class="w"> </span><span class="n">averaging</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">deprecated</span><span class="p">,</span>
<span class="k">and</span><span class="w"> </span><span class="k">from</span><span class="w"> </span><span class="n">version</span><span class="w"> </span><span class="mf">0.18</span><span class="p">,</span><span class="w"> </span><span class="k">use</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="kt">precision</span><span class="p">,</span><span class="w"> </span><span class="n">recall</span><span class="w"> </span><span class="k">or</span><span class="w"> </span><span class="n">F</span><span class="o">-</span><span class="n">score</span><span class="w"> </span><span class="k">with</span><span class="w"> </span>
<span class="n">multiclass</span><span class="w"> </span><span class="k">or</span><span class="w"> </span><span class="n">multilabel</span><span class="w"> </span><span class="k">data</span><span class="w"> </span><span class="k">or</span><span class="w"> </span><span class="n">pos_label</span><span class="o">=</span><span class="k">None</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">result</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">an</span><span class="w"> </span>
<span class="n">exception</span><span class="p">.</span><span class="w"> </span><span class="n">Please</span><span class="w"> </span><span class="k">set</span><span class="w"> </span><span class="n">an</span><span class="w"> </span><span class="n">explicit</span><span class="w"> </span><span class="k">value</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n n-Quoted">`average`</span><span class="p">,</span><span class="w"> </span><span class="k">one</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="p">(</span><span class="k">None</span><span class="p">,</span><span class="w"> </span>
<span class="s1">'micro'</span><span class="p">,</span><span class="w"> </span><span class="s1">'macro'</span><span class="p">,</span><span class="w"> </span><span class="s1">'weighted'</span><span class="p">,</span><span class="w"> </span><span class="s1">'samples'</span><span class="p">).</span><span class="w"> </span><span class="k">In</span><span class="w"> </span><span class="k">cross</span><span class="w"> </span><span class="k">validation</span><span class="w"> </span><span class="k">use</span><span class="p">,</span><span class="w"> </span><span class="k">for</span><span class="w"> </span>
<span class="k">instance</span><span class="p">,</span><span class="w"> </span><span class="n">scoring</span><span class="o">=</span><span class="s2">"f1_weighted"</span><span class="w"> </span><span class="n">instead</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">scoring</span><span class="o">=</span><span class="s2">"f1"</span>
</pre></div>

<p>How can I deal correctly with my unbalanced data in order to compute in the
right way classifier's metrics?</p>
<p><br><br></p>
<h2>Answer</h2>
<p>I think there is a lot of confusion about which weights are used for what. I
am not sure I know precisely what bothers you so I am going to cover different
topics, bear with me ;).</p>
<h3>Class weights</h3>
<p>The weights from the <code>class_weight</code> parameter are used to <strong>train the
classifier</strong>. They <strong>are not used in the calculation of any of the metrics you
are using</strong> : with different class weights, the numbers will be different
simply because the classifier is different.</p>
<p>Basically in every scikit-learn classifier, the class weights are used to tell
your model how important a class is. That means that during the training, the
classifier will make extra efforts to classify properly the classes with high
weights.<br>
How they do that is algorithm-specific. If you want details about how it works
for SVC and the doc does not make sense to you, feel free to mention it.</p>
<h3>The metrics</h3>
<p>Once you have a classifier, you want to know how well it is performing. Here
you can use the metrics you mentioned: <code>accuracy</code>, <code>recall_score</code>,
<code>f1_score</code>...</p>
<p>Usually when the class distribution is unbalanced, accuracy is considered a
poor choice as it gives high scores to models which just predict the most
frequent class.</p>
<p>I will not detail all these metrics but note that, with the exception of
<code>accuracy</code>, they are naturally applied at the class level: as you can see in
this <code>print</code> of a classification report they are defined for each class. They
rely on concepts such as <code>true positives</code> or <code>false negative</code> that require
defining which class is the <em>positive</em> one.</p>
<div class="code"><pre class="code literal-block">             precision    recall  f1-score   support

          0       0.65      1.00      0.79        17
          1       0.57      0.75      0.65        16
          2       0.33      0.06      0.10        17
avg / total       0.52      0.60      0.51        50
</pre></div>

<h3>The warning</h3>
<div class="code"><pre class="code literal-block"><span class="n">F1</span><span class="w"> </span><span class="n">score</span><span class="o">:/</span><span class="n">usr</span><span class="o">/</span><span class="k">local</span><span class="o">/</span><span class="n">lib</span><span class="o">/</span><span class="n">python2</span><span class="mf">.7</span><span class="o">/</span><span class="n">site</span><span class="o">-</span><span class="n">packages</span><span class="o">/</span><span class="n">sklearn</span><span class="o">/</span><span class="n">metrics</span><span class="o">/</span><span class="n">classification</span><span class="p">.</span><span class="n">py</span><span class="o">:</span><span class="mi">676</span><span class="o">:</span><span class="w"> </span><span class="n">DeprecationWarning</span><span class="o">:</span><span class="w"> </span><span class="n">The</span><span class="w"> </span>
<span class="k">default</span><span class="w"> </span><span class="n n-Quoted">`weighted`</span><span class="w"> </span><span class="n">averaging</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">deprecated</span><span class="p">,</span><span class="w"> </span><span class="k">and</span><span class="w"> </span><span class="k">from</span><span class="w"> </span><span class="n">version</span><span class="w"> </span><span class="mf">0.18</span><span class="p">,</span><span class="w"> </span>
<span class="k">use</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="kt">precision</span><span class="p">,</span><span class="w"> </span><span class="n">recall</span><span class="w"> </span><span class="k">or</span><span class="w"> </span><span class="n">F</span><span class="o">-</span><span class="n">score</span><span class="w"> </span><span class="k">with</span><span class="w"> </span><span class="n">multiclass</span><span class="w"> </span><span class="k">or</span><span class="w"> </span><span class="n">multilabel</span><span class="w"> </span><span class="k">data</span><span class="w">  </span>
<span class="k">or</span><span class="w"> </span><span class="n">pos_label</span><span class="o">=</span><span class="k">None</span><span class="w"> </span><span class="n">will</span><span class="w"> </span><span class="n">result</span><span class="w"> </span><span class="k">in</span><span class="w"> </span><span class="n">an</span><span class="w"> </span><span class="n">exception</span><span class="p">.</span><span class="w"> </span><span class="n">Please</span><span class="w"> </span><span class="k">set</span><span class="w"> </span><span class="n">an</span><span class="w"> </span><span class="n">explicit</span><span class="w"> </span>
<span class="k">value</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n n-Quoted">`average`</span><span class="p">,</span><span class="w"> </span><span class="k">one</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="p">(</span><span class="k">None</span><span class="p">,</span><span class="w"> </span><span class="s1">'micro'</span><span class="p">,</span><span class="w"> </span><span class="s1">'macro'</span><span class="p">,</span><span class="w"> </span><span class="s1">'weighted'</span><span class="p">,</span><span class="w"> </span>
<span class="s1">'samples'</span><span class="p">).</span><span class="w"> </span><span class="k">In</span><span class="w"> </span><span class="k">cross</span><span class="w"> </span><span class="k">validation</span><span class="w"> </span><span class="k">use</span><span class="p">,</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="k">instance</span><span class="p">,</span><span class="w"> </span>
<span class="n">scoring</span><span class="o">=</span><span class="s2">"f1_weighted"</span><span class="w"> </span><span class="n">instead</span><span class="w"> </span><span class="k">of</span><span class="w"> </span><span class="n">scoring</span><span class="o">=</span><span class="s2">"f1"</span><span class="p">.</span>
</pre></div>

<p>You get this warning because you are using the f1-score, recall and precision
without defining how they should be computed! The question could be rephrased:
from the above classification report, how do you output <strong>one</strong> global number
for the f1-score? You could:</p>
<ol>
<li>Take the average of the f1-score for each class: that's the <code>avg / total</code> result above. It's also called <em>macro</em> averaging.</li>
<li>Compute the f1-score using the global count of true positives / false negatives, etc. (you sum the number of true positives / false negatives for each class). Aka <em>micro</em> averaging.</li>
<li>Compute a weighted average of the f1-score. Using <code>'weighted'</code> in scikit-learn will weigh the f1-score by the support of the class: the more elements a class has, the more important the f1-score for this class in the computation.</li>
</ol>
<p>These are 3 of the options in scikit-learn, the warning is there to say you
<strong>have to pick one</strong>. So you have to specify an <code>average</code> argument for the
score method.</p>
<p>Which one you choose is up to how you want to measure the performance of the
classifier: for instance macro-averaging does not take class imbalance into
account and the f1-score of class 1 will be just as important as the f1-score
of class 5. If you use weighted averaging however you'll get more importance
for the class 5.</p>
<p>The whole argument specification in these metrics is not super-clear in
scikit-learn right now, it will get better in version 0.18 according to the
docs. They are removing some non-obvious standard behavior and they are
issuing warnings so that developers notice it.</p>
<h3>Computing scores</h3>
<p>Last thing I want to mention (feel free to skip it if you're aware of it) is
that scores are only meaningful if they are computed on data that the
classifier <strong>has never seen</strong>. This is extremely important as any score you
get on data that was used in fitting the classifier is completely irrelevant.</p>
<p>Here's a way to do it using <code>StratifiedShuffleSplit</code>, which gives you a random
splits of your data (after shuffling) that preserve the label distribution.</p>
<div class="code"><pre class="code literal-block"><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>
<span class="kn">from</span> <span class="nn">sklearn.cross_validation</span> <span class="kn">import</span> <span class="n">StratifiedShuffleSplit</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">f1_score</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">,</span> <span class="n">classification_report</span><span class="p">,</span> <span class="n">confusion_matrix</span>

<span class="c1"># We use a utility to generate artificial classification data.</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">n_informative</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_classes</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">sss</span> <span class="o">=</span> <span class="n">StratifiedShuffleSplit</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">n_iter</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="k">for</span> <span class="n">train_idx</span><span class="p">,</span> <span class="n">test_idx</span> <span class="ow">in</span> <span class="n">sss</span><span class="p">:</span>
    <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train_idx</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">test_idx</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">train_idx</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span>
    <span class="n">svc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">svc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">f1_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">"macro"</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">precision_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">"macro"</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">recall_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">"macro"</span><span class="p">))</span>
</pre></div>

<p><br></p>
<h3>Suggest</h3>
<p>Lot of very detailed answers here but I don't think you are answering the
right questions. As I understand the question, there are two concerns:</p>
<ol>
<li>How to I score a multiclass problem?</li>
<li>How do I deal with unbalanced data?</li>
</ol>
<h3>1.</h3>
<p>You can use most of the scoring functions in scikit-learn with both multiclass
problem as with single class problems. Ex.:</p>
<div class="code"><pre class="code literal-block"><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_recall_fscore_support</span> <span class="k">as</span> <span class="n">score</span>

<span class="n">predicted</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">]</span> 
<span class="n">y_test</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span>

<span class="n">precision</span><span class="p">,</span> <span class="n">recall</span><span class="p">,</span> <span class="n">fscore</span><span class="p">,</span> <span class="n">support</span> <span class="o">=</span> <span class="n">score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predicted</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'precision: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">precision</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'recall: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">recall</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'fscore: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">fscore</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'support: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">support</span><span class="p">))</span>
</pre></div>

<p>This way you end up with tangible and interpretable numbers for each of the
classes.</p>
<div class="code"><pre class="code literal-block">| Label | Precision | Recall | FScore | Support |
|-------|-----------|--------|--------|---------|
| 1     | 94%       | 83%    | 0.88   | 204     |
| 2     | 71%       | 50%    | 0.54   | 127     |
| ...   | ...       | ...    | ...    | ...     |
| 4     | 80%       | 98%    | 0.89   | 838     |
| 5     | 93%       | 81%    | 0.91   | 1190    |
</pre></div>

<p>Then...</p>
<h3>2.</h3>
<p>... you can tell if the unbalanced data is even a problem. If the scoring for
the less represented classes (class 1 and 2) are lower than for the classes
with more training samples (class 4 and 5) then you know that the unbalanced
data is in fact a problem, and you can act accordingly, as described in some
of the other answers in this thread. However, if the same class distribution
is present in the data you want to predict on, your unbalanced training data
is a good representative of the data, and hence, the unbalance is a good
thing.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/what-is-the-difference-between-q-learning-and-sarsa/" class="u-url">What is the difference between Q-learning and SARSA?</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="posts/what-is-the-difference-between-q-learning-and-sarsa/" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T02:23:27+08:00" itemprop="datePublished" title="2023-02-28 02:23">2023-02-28 02:23</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>Although I know that SARSA is on-policy while Q-learning is off-policy, when
looking at their formulas it's hard (to me) to see any difference between
these two algorithms.</p>
<p>According to the book Reinforcement Learning: An Introduction (by Sutton and
Barto). In the SARSA algorithm, given a policy, the corresponding action-value
function Q (in the state s and action a, at timestep t), i.e. Q(st, at), can
be updated as follows</p>
<blockquote>
<p>Q(st, at) = Q(st, at) + α<em>(rt + γ</em>Q(st+1, at+1) - Q(st, at))</p>
</blockquote>
<p>On the other hand, the update step for the Q-learning algorithm is the
following</p>
<blockquote>
<p>Q(st, at) = Q(st, at) + α<em>(rt + γ</em>maxa Q(st+1, a) - Q(st, at))</p>
</blockquote>
<p>which can also be written as</p>
<blockquote>
<p>Q(st, at) = (1 - α) * Q(st, at) + α * (rt + γ*maxa Q(st+1, a))</p>
</blockquote>
<p>where γ (gamma) is the discount factor and rt is the reward received from the
environment at timestep t.</p>
<p>Is the difference between these two algorithms the fact that SARSA only looks
up the next policy value while Q-learning looks up the next <em>maximum</em> policy
value?</p>
<p><strong>TLDR (and my own answer)</strong></p>
<p>Thanks to all those answering this question since I first asked it. I've made
a github repo playing with Q-Learning and empirically understood what the
difference is. It all amounts to how <em><strong>you select your next best action</strong></em> ,
which from an algorithmic standpoint can be a <em>mean</em> , <em>max</em> or <em>best</em> action
depending on how you chose to implement it.</p>
<p>The other main difference is <em>when</em> this selection is happening (e.g.,
<em>online</em> vs <em>offline</em> ) and how/why that affects learning. If you are reading
this in 2019 and are more of a hands-on person, playing with a RL toy problem
is probably the best way to understand the differences.</p>
<p>One last <strong>important</strong> note is that both Suton &amp; Barto as well as Wikipedia
often have <em>mixed, confusing</em> or <em>wrong</em> formulaic representations with
regards to the <em>next state best/max action and reward</em> :</p>
<blockquote>
<p>r(t+1)</p>
</blockquote>
<p>is in fact</p>
<blockquote>
<p>r(t)</p>
</blockquote>
<p><br><br></p>
<h2>Answer</h2>
<p>Yes, this is the only difference. On-policy SARSA learns action values
relative to the policy it follows, while off-policy Q-Learning does it
relative to the greedy policy. Under some common conditions, they both
converge to the real value function, but at different rates. Q-Learning tends
to converge a little slower, but has the capabilitiy to continue learning
while changing policies. Also, Q-Learning is not guaranteed to converge when
combined with linear approximation.</p>
<p>In practical terms, under the ε-greedy policy, Q-Learning computes the
difference between Q(s,a) and the maximum action value, while SARSA computes
the difference between Q(s,a) and the weighted sum of the average action value
and the maximum:</p>
<p>Q-Learning: Q(st+1,at+1) = maxaQ(st+1,a)</p>
<p>SARSA: Q(st+1,at+1) = ε·meanaQ(st+1,a) + (1-ε)·maxaQ(st+1,a)</p>
<p><br></p>
<h3>Suggest</h3>
<p>Yes, this is the only difference. On-policy SARSA learns action values
relative to the policy it follows, while off-policy Q-Learning does it
relative to the greedy policy. Under some common conditions, they both
converge to the real value function, but at different rates. Q-Learning tends
to converge a little slower, but has the capabilitiy to continue learning
while changing policies. Also, Q-Learning is not guaranteed to converge when
combined with linear approximation.</p>
<p>In practical terms, under the ε-greedy policy, Q-Learning computes the
difference between Q(s,a) and the maximum action value, while SARSA computes
the difference between Q(s,a) and the weighted sum of the average action value
and the maximum:</p>
<p>Q-Learning: Q(st+1,at+1) = maxaQ(st+1,a)</p>
<p>SARSA: Q(st+1,at+1) = ε·meanaQ(st+1,a) + (1-ε)·maxaQ(st+1,a)</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/what-s-is-the-difference-between-train-validation-and-test-set-in-neural-networks/" class="u-url">What's is the difference between train, validation and test set, in neural networks?</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="posts/what-s-is-the-difference-between-train-validation-and-test-set-in-neural-networks/" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T02:23:03+08:00" itemprop="datePublished" title="2023-02-28 02:23">2023-02-28 02:23</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>I'm using this library to implement a learning agent.</p>
<p>I have generated the training cases, but I don't know for sure what the
validation and test sets are.<br>
The teacher says:</p>
<blockquote>
<p>70% should be train cases, 10% will be test cases and the rest 20% should be
validation cases.</p>
</blockquote>
<p><em>edit</em></p>
<p>I have this code for training, but I have no idea when to <em>stop</em> training.</p>
<div class="code"><pre class="code literal-block"><span class="w">  </span><span class="nv">def</span><span class="w"> </span><span class="nv">train</span><span class="ss">(</span><span class="nv">self</span>,<span class="w"> </span><span class="nv">train</span>,<span class="w"> </span><span class="nv">validation</span>,<span class="w"> </span><span class="nv">N</span><span class="o">=</span><span class="mi">0</span>.<span class="mi">3</span>,<span class="w"> </span><span class="nv">M</span><span class="o">=</span><span class="mi">0</span>.<span class="mi">1</span><span class="ss">)</span>:
<span class="w">    </span>#<span class="w"> </span><span class="nv">N</span>:<span class="w"> </span><span class="nv">learning</span><span class="w"> </span><span class="nv">rate</span>
<span class="w">    </span>#<span class="w"> </span><span class="nv">M</span>:<span class="w"> </span><span class="nv">momentum</span><span class="w"> </span><span class="nv">factor</span>
<span class="w">    </span><span class="nv">accuracy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">list</span><span class="ss">()</span>
<span class="w">    </span><span class="k">while</span><span class="ss">(</span><span class="nv">True</span><span class="ss">)</span>:
<span class="w">        </span><span class="nv">error</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span>.<span class="mi">0</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="nv">p</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">train</span>:
<span class="w">            </span><span class="nv">input</span>,<span class="w"> </span><span class="nv">target</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">p</span>
<span class="w">            </span><span class="nv">self</span>.<span class="nv">update</span><span class="ss">(</span><span class="nv">input</span><span class="ss">)</span>
<span class="w">            </span><span class="nv">error</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">error</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nv">self</span>.<span class="nv">backPropagate</span><span class="ss">(</span><span class="nv">target</span>,<span class="w"> </span><span class="nv">N</span>,<span class="w"> </span><span class="nv">M</span><span class="ss">)</span>
<span class="w">        </span><span class="nv">print</span><span class="w"> </span><span class="s2">"validation"</span>
<span class="w">        </span><span class="nv">total</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="nv">p</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">validation</span>:
<span class="w">            </span><span class="nv">input</span>,<span class="w"> </span><span class="nv">target</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">p</span>
<span class="w">            </span><span class="nv">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">self</span>.<span class="nv">update</span><span class="ss">(</span><span class="nv">input</span><span class="ss">)</span>
<span class="w">            </span><span class="nv">total</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="nv">sum</span><span class="ss">(</span>[<span class="nv">abs</span><span class="ss">(</span><span class="nv">target</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nv">output</span><span class="ss">)</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="nv">target</span>,<span class="w"> </span><span class="nv">output</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">zip</span><span class="ss">(</span><span class="nv">target</span>,<span class="w"> </span><span class="nv">output</span><span class="ss">)</span>]<span class="ss">)</span><span class="w"> </span>#<span class="nv">calculates</span><span class="w"> </span><span class="nv">sum</span><span class="w"> </span><span class="nv">of</span><span class="w"> </span><span class="nv">absolute</span><span class="w"> </span><span class="nv">diference</span><span class="w"> </span><span class="nv">between</span><span class="w"> </span><span class="nv">target</span><span class="w"> </span><span class="nv">and</span><span class="w"> </span><span class="nv">output</span>

<span class="w">        </span><span class="nv">accuracy</span>.<span class="nv">append</span><span class="ss">(</span><span class="nv">total</span><span class="ss">)</span>
<span class="w">        </span><span class="nv">print</span><span class="w"> </span><span class="nv">min</span><span class="ss">(</span><span class="nv">accuracy</span><span class="ss">)</span>
<span class="w">        </span><span class="nv">print</span><span class="w"> </span><span class="nv">sum</span><span class="ss">(</span><span class="nv">accuracy</span>[<span class="o">-</span><span class="mi">5</span>:]<span class="ss">)</span><span class="o">/</span><span class="mi">5</span>
<span class="w">        </span>#<span class="k">if</span><span class="w"> </span><span class="nv">i</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="mi">100</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span>:
<span class="w">        </span><span class="nv">print</span><span class="w"> </span><span class="s1">'error %-14f'</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="nv">error</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span>?<span class="w"> </span><span class="o">&lt;</span><span class="w"> </span>?:
<span class="w">            </span><span class="k">break</span>
</pre></div>

<p><em>edit</em></p>
<p>I can get an average error of 0.2 with validation data, after maybe 20
training iterations, that should be 80%?</p>
<p>average error = sum of absolute difference between validation target and
output, given the validation data input/size of validation data.</p>
<div class="code"><pre class="code literal-block"><span class="mf">1</span>
<span class="w">        </span><span class="n">avg</span><span class="w"> </span><span class="n">error</span><span class="w"> </span><span class="mf">0.520395</span><span class="w"> </span>
<span class="w">        </span><span class="nb">val</span><span class="n">idation</span>
<span class="w">        </span><span class="mf">0.246937882684</span>
<span class="mf">2</span>
<span class="w">        </span><span class="n">avg</span><span class="w"> </span><span class="n">error</span><span class="w"> </span><span class="mf">0.272367</span><span class="w">   </span>
<span class="w">        </span><span class="nb">val</span><span class="n">idation</span>
<span class="w">        </span><span class="mf">0.228832420879</span>
<span class="mf">3</span>
<span class="w">        </span><span class="n">avg</span><span class="w"> </span><span class="n">error</span><span class="w"> </span><span class="mf">0.249578</span><span class="w">    </span>
<span class="w">        </span><span class="nb">val</span><span class="n">idation</span>
<span class="w">        </span><span class="mf">0.216253590304</span>
<span class="w">        </span><span class="mf">...</span>
<span class="mf">22</span>
<span class="w">        </span><span class="n">avg</span><span class="w"> </span><span class="n">error</span><span class="w"> </span><span class="mf">0.227753</span>
<span class="w">        </span><span class="nb">val</span><span class="n">idation</span>
<span class="w">        </span><span class="mf">0.200239244714</span>
<span class="mf">23</span>
<span class="w">        </span><span class="n">avg</span><span class="w"> </span><span class="n">error</span><span class="w"> </span><span class="mf">0.227905</span><span class="w">    </span>
<span class="w">        </span><span class="nb">val</span><span class="n">idation</span>
<span class="w">        </span><span class="mf">0.199875013416</span>
</pre></div>

<p><br><br></p>
<h2>Answer</h2>
<p>The training and validation sets are used during training.</p>
<div class="code"><pre class="code literal-block"><span class="k">for</span><span class="w"> </span><span class="nv">each</span><span class="w"> </span><span class="nv">epoch</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="nv">each</span><span class="w"> </span><span class="nv">training</span><span class="w"> </span><span class="nv">data</span><span class="w"> </span><span class="nv">instance</span>
<span class="w">        </span><span class="nv">propagate</span><span class="w"> </span><span class="nv">error</span><span class="w"> </span><span class="nv">through</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">network</span>
<span class="w">        </span><span class="nv">adjust</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">weights</span>
<span class="w">        </span><span class="nv">calculate</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">accuracy</span><span class="w"> </span><span class="nv">over</span><span class="w"> </span><span class="nv">training</span><span class="w"> </span><span class="nv">data</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="nv">each</span><span class="w"> </span><span class="nv">validation</span><span class="w"> </span><span class="nv">data</span><span class="w"> </span><span class="nv">instance</span>
<span class="w">        </span><span class="nv">calculate</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">accuracy</span><span class="w"> </span><span class="nv">over</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">validation</span><span class="w"> </span><span class="nv">data</span>
<span class="w">    </span><span class="k">if</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">threshold</span><span class="w"> </span><span class="nv">validation</span><span class="w"> </span><span class="nv">accuracy</span><span class="w"> </span><span class="nv">is</span><span class="w"> </span><span class="nv">met</span>
<span class="w">        </span><span class="k">exit</span><span class="w"> </span><span class="nv">training</span>
<span class="w">    </span><span class="k">else</span>
<span class="w">        </span><span class="k">continue</span><span class="w"> </span><span class="nv">training</span>
</pre></div>

<p>Once you're finished training, then you run against your testing set and
verify that the accuracy is sufficient.</p>
<p><strong>Training Set</strong> : this data set is used to adjust the weights on the neural
network.</p>
<p><strong>Validation Set</strong> : this data set is used to minimize overfitting. You're not
adjusting the weights of the network with this data set, you're just verifying
that any increase in accuracy over the training data set actually yields an
increase in accuracy over a data set that has not been shown to the network
before, or at least the network hasn't trained on it (i.e. validation data
set). If the accuracy over the training data set increases, but the accuracy
over the validation data set stays the same or decreases, then you're
overfitting your neural network and you should stop training.</p>
<p><strong>Testing Set</strong> : this data set is used only for testing the final solution in
order to confirm the actual predictive power of the network.</p>
<p><br></p>
<h3>Suggest</h3>
<blockquote>
<p><strong>Training set</strong> : A set of examples used for learning, that is to fit the
parameters [i.e., weights] of the classifier.</p>
<p><strong>Validation set</strong> : A set of examples used to tune the parameters [i.e.,
architecture, not weights] of a classifier, for example to choose the number
of hidden units in a neural network.</p>
<p><strong>Test set</strong> : A set of examples used only to assess the performance
[generalization] of a fully specified classifier.</p>
</blockquote>
<p>From ftp://ftp.sas.com/pub/neural/FAQ1.txt section " <em>What are the population,
sample, training set, design set, validation</em> "</p>
<p>The error surface will be different for different sets of data from your data
set (batch learning). Therefore if you find a very good local minima for your
test set data, that may not be a very good point, and may be a very bad point
in the surface generated by some other set of data for the same problem.
Therefore you need to compute such a model which not only finds a good weight
configuration for the training set but also should be able to predict new data
(which is not in the training set) with good error. In other words the network
should be able to <em>generalize</em> the examples so that it <em>learns</em> the data and
does not simply remembers or loads the training set by overfitting the
training data.</p>
<p>The validation data set is a set of data for the function you want to learn,
which you are not directly using to train the network. You are training the
network with a set of data which you call the training data set. If you are
using gradient based algorithm to train the network then the error surface and
the gradient at some point will completely depend on the training data set
thus the training data set is being directly used to adjust the weights. To
make sure you don't overfit the network you need to input the validation
dataset to the network and check if the error is within some range. Because
the validation set is not being using directly to adjust the weights of the
netowork, therefore a good error for the validation and also the test set
indicates that the network predicts well for the train set examples, also it
is expected to perform well when new example are presented to the network
which was not used in the training process.</p>
<p>Early stopping is a way to stop training. There are different variations
available, the main outline is, both the train and the validation set errors
are monitored, the train error decreases at each iteration (backprop and
brothers) and at first the validation error decreases. The training is stopped
at the moment the validation error starts to rise. The weight configuration at
this point indicates a model, which predicts the training data well, as well
as the data <em>which is not seen by the network</em> . But because the validation
data <em>actually</em> affects the weight configuration indirectly to select the
weight configuration. This is where the Test set comes in. This set of data is
never used in the training process. Once a model is selected based on the
validation set, the test set data is applied on the network model and the
error for this set is found. This error is a representative of the error which
we can expect from absolutely new data for the same problem.</p>
<p><strong>EDIT:</strong></p>
<p>Also, in the case you do not have enough data for a validation set, you can
use crossvalidation to tune the parameters as well as estimate the test error.</p>
    </div>
    </article>
</div>

        <nav class="postindexpager"><ul class="pager">
<li class="previous">
                <a href="index-1357.html" rel="prev">Newer posts</a>
            </li>
            <li class="next">
                <a href="index-1355.html" rel="next">Older posts</a>
            </li>
        </ul></nav>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2023         Go to StackOverflow Chinese Site  <a href="http://stackoverflow.ink">StackOverflow中文网</a>  
            
        </footer>
</div>
</div>


            <script src="assets/js/all-nocdn.js"></script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script><script src="assets/js/search.js"></script>
</body>
</html>
