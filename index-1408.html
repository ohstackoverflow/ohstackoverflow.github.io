<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="This is a snapshot site for StackOverflow">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>StackOverflow Snapshot (old posts, page 1408) | StackOverflow Snapshot</title>
<link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="canonical" href="https://ohstackoverflow.netlify.app/index-1408.html">
<link rel="prev" href="index-1409.html" type="text/html">
<link rel="next" href="index-1407.html" type="text/html">
<!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]-->
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://ohstackoverflow.netlify.app/">

                <span id="blog-title">StackOverflow Snapshot</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="archive.html">Archive</a>
                </li>
<li>
<a href="categories/">Tags</a>

                
            </li>
</ul>
<ul class="nav navbar-nav navbar-right">
<div style="display:table;min-height:5rem;min-width:27rem;">
					<div class="input-group" style="display: table-cell;vertical-align: middle;">
						<input id="words" type="text" class="form-control" style="max-width:22rem;" onkeydown="if(event.keyCode==13){btn.click()}"><span class="input-group-btn" style="float:left">
							<button id="btn" class="btn btn-default" type="button" data-toggle="modal" data-target="#myModal">
								<span class="glyphicon glyphicon-search">
							</span></button>
						</span>
					</div>
<!-- /input-group -->
				</div>

				
                
                
                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><!-- 模态框（Modal） --><div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true">
	<div class="modal-dialog">
		<div class="modal-content">
			<div class="modal-header">
				<button type="button" class="close" data-dismiss="modal" aria-hidden="true">×
				</button>
				<h4 class="modal-title" id="myModalLabel">
					查找结果
				</h4>
			</div>
			<div class="modal-body">
				<div id="search-count" style="min-height:4rem;">
				查找中，请稍后...
				</div>
				<div id="search-result">
				</div>

				
			</div>
			<div class="modal-footer">
				<button type="button" class="btn btn-default" data-dismiss="modal">
					关闭
				</button>
			</div>
		</div>
<!-- /.modal-content -->
	</div>
<!-- /.modal-dialog -->
</div>
<!-- /.modal -->

<div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            

    


    
<div class="postindex">
    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/keras-error-on-predict/" class="u-url">keras error on predict</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="posts/keras-error-on-predict/" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T03:17:46+08:00" itemprop="datePublished" title="2023-02-28 03:17">2023-02-28 03:17</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>I am trying to use a keras neural network to recognize canvas images of drawn
digits and output the digit. I have saved the neural network and use django to
run the web interface. But whenever I run it, I get an internal server error
and an error on the server side code. The error says <strong>Exception: Error when
checking : expected dense_input_1 to have shape (None, 784) but got array with
shape (784, 1)</strong>. My only main view is</p>
<div class="code"><pre class="code literal-block"><span class="kn">from</span> <span class="nn">django.shortcuts</span> <span class="kn">import</span> <span class="n">render</span>
<span class="kn">from</span> <span class="nn">django.http</span> <span class="kn">import</span> <span class="n">HttpResponse</span>
<span class="kn">import</span> <span class="nn">StringIO</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">model_from_json</span>
<span class="k">def</span> <span class="nf">home</span><span class="p">(</span><span class="n">request</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">request</span><span class="o">.</span><span class="n">method</span><span class="o">==</span><span class="s2">"POST"</span><span class="p">:</span>
        <span class="n">vari</span><span class="o">=</span><span class="n">request</span><span class="o">.</span><span class="n">POST</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">"imgBase64"</span><span class="p">,</span><span class="s2">""</span><span class="p">)</span>
        <span class="n">imgstr</span><span class="o">=</span><span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="sa">r</span><span class="s1">'base64,(.*)'</span><span class="p">,</span> <span class="n">vari</span><span class="p">)</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">tempimg</span> <span class="o">=</span> <span class="n">StringIO</span><span class="o">.</span><span class="n">StringIO</span><span class="p">(</span><span class="n">imgstr</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">'base64'</span><span class="p">))</span>
        <span class="n">im</span><span class="o">=</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">tempimg</span><span class="p">)</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span><span class="s2">"L"</span><span class="p">)</span>
        <span class="n">im</span><span class="o">.</span><span class="n">thumbnail</span><span class="p">((</span><span class="mi">28</span><span class="p">,</span><span class="mi">28</span><span class="p">),</span> <span class="n">Image</span><span class="o">.</span><span class="n">ANTIALIAS</span><span class="p">)</span>
        <span class="n">img_np</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">asarray</span><span class="p">(</span><span class="n">im</span><span class="p">)</span>
        <span class="n">img_np</span><span class="o">=</span><span class="n">img_np</span><span class="o">.</span><span class="kp">flatten</span><span class="p">()</span>
        <span class="n">img_np</span><span class="o">.</span><span class="kp">astype</span><span class="p">(</span><span class="s2">"float32"</span><span class="p">)</span>
        <span class="n">img_np</span><span class="o">=</span><span class="n">img_np</span><span class="o">/</span><span class="mi">255</span>
        <span class="n">json_file</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s1">'model.json'</span><span class="p">,</span> <span class="s1">'r'</span><span class="p">)</span>
        <span class="n">loaded_model_json</span> <span class="o">=</span> <span class="n">json_file</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
        <span class="n">json_file</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
        <span class="n">loaded_model</span> <span class="o">=</span> <span class="n">model_from_json</span><span class="p">(</span><span class="n">loaded_model_json</span><span class="p">)</span>
        <span class="c1"># load weights into new model</span>
        <span class="n">loaded_model</span><span class="o">.</span><span class="n">load_weights</span><span class="p">(</span><span class="s2">"model.h5"</span><span class="p">)</span>
        <span class="c1"># evaluate loaded model on test data</span>
        <span class="n">loaded_model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'binary_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'rmsprop'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>
        <span class="n">output</span><span class="o">=</span><span class="n">loaded_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">img_np</span><span class="p">)</span>
        <span class="n">score</span><span class="o">=</span><span class="n">output</span><span class="o">.</span><span class="kp">tolist</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">HttpResponse</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">render</span><span class="p">(</span><span class="n">request</span><span class="p">,</span> <span class="s2">"digit/index.html"</span><span class="p">)</span>
</pre></div>

<p>The links I have checked out are:</p>
<ul>
<li>Here</li>
<li>Here </li>
<li>and Here</li>
</ul>
<p><strong>Edit</strong> Complying with Rohan's suggestion, this is my stack trace</p>
<div class="code"><pre class="code literal-block"><span class="n">Internal</span><span class="w"> </span><span class="n">Server</span><span class="w"> </span><span class="n">Error</span><span class="p">:</span><span class="w"> </span><span class="o">/</span><span class="n">home</span><span class="o">/</span>
<span class="n">Traceback</span><span class="w"> </span><span class="p">(</span><span class="n">most</span><span class="w"> </span><span class="n">recent</span><span class="w"> </span><span class="n">call</span><span class="w"> </span><span class="n">last</span><span class="p">):</span>
<span class="w">  </span><span class="n">File</span><span class="w"> </span><span class="s2">"/usr/local/lib/python2.7/dist-packages/django/core/handlers/base.py"</span><span class="p">,</span><span class="w"> </span><span class="n">line</span><span class="w"> </span><span class="mi">149</span><span class="p">,</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">get_response</span>
<span class="w">    </span><span class="n">response</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">process_exception_by_middleware</span><span class="p">(</span><span class="n">e</span><span class="p">,</span><span class="w"> </span><span class="n">request</span><span class="p">)</span>
<span class="w">  </span><span class="n">File</span><span class="w"> </span><span class="s2">"/usr/local/lib/python2.7/dist-packages/django/core/handlers/base.py"</span><span class="p">,</span><span class="w"> </span><span class="n">line</span><span class="w"> </span><span class="mi">147</span><span class="p">,</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">get_response</span>
<span class="w">    </span><span class="n">response</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">wrapped_callback</span><span class="p">(</span><span class="n">request</span><span class="p">,</span><span class="w"> </span><span class="o">*</span><span class="n">callback_args</span><span class="p">,</span><span class="w"> </span><span class="o">**</span><span class="n">callback_kwargs</span><span class="p">)</span>
<span class="w">  </span><span class="n">File</span><span class="w"> </span><span class="s2">"/home/vivek/keras/neural/digit/views.py"</span><span class="p">,</span><span class="w"> </span><span class="n">line</span><span class="w"> </span><span class="mi">27</span><span class="p">,</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">home</span>
<span class="n">output</span><span class="o">=</span><span class="n">loaded_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">img_np</span><span class="p">)</span>
<span class="w">  </span><span class="n">File</span><span class="w"> </span><span class="s2">"/usr/local/lib/python2.7/dist-packages/keras/models.py"</span><span class="p">,</span><span class="w"> </span><span class="n">line</span><span class="w"> </span><span class="mi">671</span><span class="p">,</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">predict</span>
<span class="k">return</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span><span class="w"> </span><span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">)</span>
<span class="w">  </span><span class="n">File</span><span class="w"> </span><span class="s2">"/usr/local/lib/python2.7/dist-packages/keras/engine/training.py"</span><span class="p">,</span><span class="w"> </span><span class="n">line</span><span class="w"> </span><span class="mi">1161</span><span class="p">,</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">predict</span>
<span class="n">check_batch_dim</span><span class="o">=</span><span class="n">False</span><span class="p">)</span>
<span class="w">  </span><span class="n">File</span><span class="w"> </span><span class="s2">"/usr/local/lib/python2.7/dist-packages/keras/engine/training.py"</span><span class="p">,</span><span class="w"> </span><span class="n">line</span><span class="w"> </span><span class="mi">108</span><span class="p">,</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">standardize_input_data</span>
<span class="nb">str</span><span class="p">(</span><span class="n">array</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="n">Exception</span><span class="p">:</span><span class="w"> </span><span class="n">Error</span><span class="w"> </span><span class="n">when</span><span class="w"> </span><span class="n">checking</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="n">expected</span><span class="w"> </span><span class="n">dense_input_1</span><span class="w"> </span><span class="n">to</span><span class="w"> </span><span class="n">have</span><span class="w"> </span><span class="n">shape</span><span class="w"> </span><span class="p">(</span><span class="n">None</span><span class="p">,</span><span class="w"> </span><span class="mi">784</span><span class="p">)</span><span class="w"> </span><span class="n">but</span><span class="w"> </span><span class="n">got</span><span class="w"> </span><span class="n">array</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">shape</span><span class="w"> </span><span class="p">(</span><span class="mi">784</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span>
</pre></div>

<p>Also, I have my model that I used to train the network initially.</p>
<div class="code"><pre class="code literal-block"><span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">from</span> <span class="nn">keras.datasets</span> <span class="kn">import</span> <span class="n">mnist</span>
<span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dense</span>
<span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Dropout</span>
<span class="kn">from</span> <span class="nn">keras.utils</span> <span class="kn">import</span> <span class="n">np_utils</span>
<span class="c1"># fix random seed for reproducibility</span>
<span class="kp">seed</span> <span class="o">=</span> <span class="mi">7</span>
<span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="kp">seed</span><span class="p">(</span><span class="kp">seed</span><span class="p">)</span>
<span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span> <span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span> <span class="o">=</span> <span class="n">mnist</span><span class="o">.</span><span class="n">load_data</span><span class="p">()</span>
<span class="k">for</span> <span class="kp">item</span> <span class="ow">in</span> <span class="n">y_train</span><span class="o">.</span><span class="kp">shape</span><span class="p">:</span>
    <span class="nb">print</span> <span class="kp">item</span>
<span class="n">num_pixels</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="kp">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">X_train</span><span class="o">.</span><span class="kp">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="kp">reshape</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="kp">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">num_pixels</span><span class="p">)</span><span class="o">.</span><span class="kp">astype</span><span class="p">(</span><span class="s1">'float32'</span><span class="p">)</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="o">.</span><span class="kp">reshape</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="kp">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">num_pixels</span><span class="p">)</span><span class="o">.</span><span class="kp">astype</span><span class="p">(</span><span class="s1">'float32'</span><span class="p">)</span>
<span class="c1"># normalize inputs from 0-255 to 0-1</span>
<span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span> <span class="o">/</span> <span class="mi">255</span>
<span class="nb">print</span> <span class="n">X_train</span><span class="o">.</span><span class="kp">shape</span>
<span class="c1"># one hot encode outputs</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">np_utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="n">np_utils</span><span class="o">.</span><span class="n">to_categorical</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="n">y_test</span><span class="o">.</span><span class="kp">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="c1"># define baseline model</span>
<span class="k">def</span> <span class="nf">baseline_model</span><span class="p">():</span>
    <span class="c1"># create model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">()</span>
    <span class="n">model</span><span class="o">.</span><span class="kp">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_pixels</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="n">num_pixels</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">'normal'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'relu'</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="kp">add</span><span class="p">(</span><span class="n">Dense</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">init</span><span class="o">=</span><span class="s1">'normal'</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">'softmax'</span><span class="p">))</span>
    <span class="c1"># Compile model</span>
    <span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">'categorical_crossentropy'</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">'adam'</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">'accuracy'</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">model</span>
<span class="c1"># build the model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">baseline_model</span><span class="p">()</span>
<span class="c1"># Fit the model</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">validation_data</span><span class="o">=</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">),</span> <span class="n">nb_epoch</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># Final evaluation of the model</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Baseline Error: </span><span class="si">%.2f%%</span><span class="s2">"</span> <span class="o">%</span> <span class="p">(</span><span class="mi">100</span><span class="o">-</span><span class="n">scores</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="mi">100</span><span class="p">))</span>
<span class="c1"># serialize model to JSON</span>
<span class="n">model_json</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to_json</span><span class="p">()</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">"model.json"</span><span class="p">,</span> <span class="s2">"w"</span><span class="p">)</span> <span class="k">as</span> <span class="n">json_file</span><span class="p">:</span>
    <span class="n">json_file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">model_json</span><span class="p">)</span>
<span class="c1"># serialize weights to HDF5</span>
<span class="n">model</span><span class="o">.</span><span class="n">save_weights</span><span class="p">(</span><span class="s2">"model.h5"</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Saved model to disk"</span><span class="p">)</span>
</pre></div>

<p><strong>Edit</strong> I tried reshaping the img to (1,784) and it also failed, giving the
same error as the title of this question</p>
<p>Thanks for the help, and leave comments on how I should add to the question.</p>
<p><br><br></p>
<h2>Answer</h2>
<p>You're asking the neural network to evaluate 784 cases with one input each
instead of a single case with 784 inputs. I had the same problem and I solved
it having an array with a single element which is an array of the inputs. See
the example below, the first one works whereas the second one gives the same
error you're experiencing.</p>
<div class="code"><pre class="code literal-block">model.predict(np.array([[0.5, 0.0, 0.1, 0.0, 0.0, 0.4, 0.0, 0.0, 0.1, 0.0, 0.0]]))
model.predict(np.array([0.5, 0.0, 0.1, 0.0, 0.0, 0.4, 0.0, 0.0, 0.1, 0.0, 0.0]))
</pre></div>

<p>hope this solves it for you as well :)</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/what-are-the-differences-between-contextual-embedding-and-word-embedding/" class="u-url">What are the differences between contextual embedding and word embedding</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="posts/what-are-the-differences-between-contextual-embedding-and-word-embedding/" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T03:17:25+08:00" itemprop="datePublished" title="2023-02-28 03:17">2023-02-28 03:17</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>I am trying to understand the concept of embedding for the deep learning
models.</p>
<p>I understand how employing <code>word2vec</code> can address the limitations of using the
one-hot vectors.</p>
<p>However, recently I see a plethora of blog posts stating ELMo, BERT, etc.
talking about contextual embedding.</p>
<p>How are word embeddings different from contextual embeddings?</p>
<p><br><br></p>
<h2>Answer</h2>
<p>Both embedding techniques, traditional <strong>word embedding</strong> (e.g. word2vec,
Glove) and <strong>contextual embedding</strong> (e.g. ELMo, BERT), aim to learn a
<strong>continuous (vector) representation</strong> for each word in the documents.
Continuous representations can be used in downstream machine learning tasks.</p>
<p>Traditional <strong>word embedding techniques</strong> learn a global word embedding. They
first build a global vocabulary using unique words in the documents by
ignoring the meaning of words in different context. Then, similar
representations are learnt for the words appeared more frequently close each
other in the documents. The problem is that in such word representations the
words' contextual meaning (the meaning derived from the words' surroundings),
is ignored. For example, <strong>only one</strong> representation is learnt for "left" in
sentence "I <strong>left</strong> my phone on the <strong>left</strong> side of the table." However,
"left" has two different meanings in the sentence, and needs to have two
different representations in the embedding space.</p>
<p>On the other hand, <strong>contextual embedding methods</strong> are used to learn
<strong>sequence-level semantics</strong> by considering the sequence of all words in the
documents. Thus, such techniques learn <strong>different representations</strong> for
<strong>polysemous words</strong> , e.g. "left" in example above, based on their context.</p>
<p><br></p>
<h3>Suggest</h3>
<p>Word embeddings and contextual embeddings are slightly different.</p>
<p>While both word embeddings and contextual embeddings are obtained from the
models using unsupervised learning, there are some differences.</p>
<p>Word embeddings provided by <code>word2vec</code> or <code>fastText</code> has a vocabulary
(dictionary) of words. The elements of this vocabulary (or dictionary) are
words and its corresponding word embeddings. Hence, given a word, its
embeddings is always the same in whichever sentence it occurs. Here, the pre-
trained word embeddings are <code>static</code>.</p>
<p>However, contextual embeddings (are generally obtained from the transformer
based models). The emeddings are obtained from a model by passing the entire
sentence to the pre-trained model. Note that, here there is a vocabulary of
words, but the vocabulary will not contain the contextual embeddings. The
embeddings generated for each word depends on the other words in a given
sentence. (The other words in a given sentence is referred as <code>context</code>. The
transformer based models work on attention mechanism, and attention is a way
to look at the relation between a word with its neighbors). Thus, given a
word, it will not have a static embeddings, but the embeddings are dynamically
generated from pre-trained (or fine-tuned) model.</p>
<p>For example, consider the two sentences:</p>
<ol>
<li>I will show you a valid point of reference and talk to the point.</li>
<li>Where have you placed the point.</li>
</ol>
<p>Now, the word embeddings from a pre-trained embeddings such as word2vec, the
embeddings for the word <code>'point'</code> is same for both of its occurrences in
example 1 and also the same for the word <code>'point'</code> in example 2. (all three
occurrences has same embeddings).</p>
<p>While, the embeddings from BERT or ELMO or any such transformer based models,
the the two occurrences of the word <code>'point'</code> in example 1 will have different
embeddings. Also, the word <code>'point'</code> occurring in example 2 will have
different embeddings than the ones in example 1.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/implementing-the-td-gammon-algorithm/" class="u-url">Implementing the TD-Gammon algorithm</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="posts/implementing-the-td-gammon-algorithm/" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T03:17:08+08:00" itemprop="datePublished" title="2023-02-28 03:17">2023-02-28 03:17</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>I am attempting to implement the algorithm from the TD-Gammon article by
Gerald Tesauro. The core of the learning algorithm is described in the
following paragraph:</p>
<blockquote>
<p><img alt="enter image description here" src="images/ZaXPB.png"></p>
</blockquote>
<p>I have decided to have a single hidden layer (if that was enough to play
world-class backgammon in the early 1990's, then it's enough for me). I am
pretty certain that everything except the <code>train()</code> function is correct (they
are easier to test), but I have no idea whether I have implemented this final
algorithm correctly.</p>
<div class="code"><pre class="code literal-block"><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="k">class</span> <span class="nc">TD_network</span><span class="p">:</span>
<span class="w">    </span><span class="sd">"""</span>
<span class="sd">    Neural network with a single hidden layer and a Temporal Displacement training algorithm</span>
<span class="sd">    taken from G. Tesauro's 1995 TD-Gammon article.</span>
<span class="sd">    """</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_input</span><span class="p">,</span> <span class="n">num_hidden</span><span class="p">,</span> <span class="n">num_output</span><span class="p">,</span> <span class="n">hnorm</span><span class="p">,</span> <span class="n">dhnorm</span><span class="p">,</span> <span class="n">onorm</span><span class="p">,</span> <span class="n">donorm</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w21</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">num_hidden</span><span class="p">,</span> <span class="n">num_input</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w32</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">num_output</span><span class="p">,</span> <span class="n">num_hidden</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b2</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">num_hidden</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b3</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">num_output</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hnorm</span> <span class="o">=</span> <span class="n">hnorm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dhnorm</span> <span class="o">=</span> <span class="n">dhnorm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">onorm</span> <span class="o">=</span> <span class="n">onorm</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">donorm</span> <span class="o">=</span> <span class="n">donorm</span>

    <span class="k">def</span> <span class="nf">value</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""Evaluates the NN output"""</span>
        <span class="k">assert</span><span class="p">(</span><span class="nb">input</span><span class="o">.</span><span class="kp">shape</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">w21</span><span class="p">[</span><span class="mi">1</span><span class="p">,:]</span><span class="o">.</span><span class="kp">shape</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w21</span><span class="o">.</span><span class="kp">dot</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b2</span>
        <span class="n">hn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hnorm</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">o</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w32</span><span class="o">.</span><span class="kp">dot</span><span class="p">(</span><span class="n">hn</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b3</span>
        <span class="k">return</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">onorm</span><span class="p">(</span><span class="n">o</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">gradient</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="nb">input</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Calculates the gradient of the NN at the given input. Outputs a list of dictionaries</span>
<span class="sd">        where each dict corresponds to the gradient of an output node, and each element in</span>
<span class="sd">        a given dict gives the gradient for a subset of the weights. </span>
<span class="sd">        """</span> 
        <span class="k">assert</span><span class="p">(</span><span class="nb">input</span><span class="o">.</span><span class="kp">shape</span> <span class="o">==</span> <span class="bp">self</span><span class="o">.</span><span class="n">w21</span><span class="p">[</span><span class="mi">1</span><span class="p">,:]</span><span class="o">.</span><span class="kp">shape</span><span class="p">)</span>
        <span class="n">J</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">h</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w21</span><span class="o">.</span><span class="kp">dot</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b2</span>
        <span class="n">hn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">hnorm</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>
        <span class="n">o</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w32</span><span class="o">.</span><span class="kp">dot</span><span class="p">(</span><span class="n">hn</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b3</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b3</span><span class="p">)):</span>
            <span class="n">db3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b3</span><span class="o">.</span><span class="kp">shape</span><span class="p">)</span>
            <span class="n">db3</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">donorm</span><span class="p">(</span><span class="n">o</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

            <span class="n">dw32</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w32</span><span class="o">.</span><span class="kp">shape</span><span class="p">)</span>
            <span class="n">dw32</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">donorm</span><span class="p">(</span><span class="n">o</span><span class="p">[</span><span class="n">i</span><span class="p">])</span><span class="o">*</span><span class="n">hn</span>

            <span class="n">db2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">multiply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dhnorm</span><span class="p">(</span><span class="n">h</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">w32</span><span class="p">[</span><span class="n">i</span><span class="p">,:])</span><span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">donorm</span><span class="p">(</span><span class="n">o</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">dw21</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">transpose</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="kp">outer</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">db2</span><span class="p">))</span>

            <span class="n">J</span><span class="o">.</span><span class="kp">append</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">db3</span> <span class="o">=</span> <span class="n">db3</span><span class="p">,</span> <span class="n">dw32</span> <span class="o">=</span> <span class="n">dw32</span><span class="p">,</span> <span class="n">db2</span> <span class="o">=</span> <span class="n">db2</span><span class="p">,</span> <span class="n">dw21</span> <span class="o">=</span> <span class="n">dw21</span><span class="p">))</span>
        <span class="k">return</span><span class="p">(</span><span class="n">J</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_states</span><span class="p">,</span> <span class="n">end_result</span><span class="p">,</span> <span class="n">a</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">l</span> <span class="o">=</span> <span class="mf">0.7</span><span class="p">):</span>
<span class="w">        </span><span class="sd">"""</span>
<span class="sd">        Trains the network using a single series of input states representing a game from beginning</span>
<span class="sd">        to end, and a final (supervised / desired) output for the end state</span>
<span class="sd">        """</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">(</span><span class="n">input_state</span><span class="p">)</span> <span class="k">for</span> <span class="n">input_state</span> <span class="ow">in</span> <span class="n">input_states</span><span class="p">]</span>
        <span class="n">outputs</span><span class="o">.</span><span class="kp">append</span><span class="p">(</span><span class="n">end_result</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">input_states</span><span class="p">)):</span>
            <span class="n">delta</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
                <span class="n">db3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b3</span><span class="o">.</span><span class="kp">shape</span><span class="p">),</span>
                <span class="n">dw32</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w32</span><span class="o">.</span><span class="kp">shape</span><span class="p">),</span>
                <span class="n">db2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b2</span><span class="o">.</span><span class="kp">shape</span><span class="p">),</span>
                <span class="n">dw21</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w21</span><span class="o">.</span><span class="kp">shape</span><span class="p">))</span>
            <span class="n">grad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="kp">gradient</span><span class="p">(</span><span class="n">input_states</span><span class="p">[</span><span class="n">t</span><span class="p">])</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">b3</span><span class="p">)):</span>
                <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">delta</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="n">td_sum</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">([</span><span class="n">l</span><span class="o">**</span><span class="p">(</span><span class="n">t</span><span class="o">-</span><span class="n">k</span><span class="p">)</span><span class="o">*</span><span class="n">grad</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">key</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)])</span>
                    <span class="n">delta</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">+=</span> <span class="n">a</span><span class="o">*</span><span class="p">(</span><span class="n">outputs</span><span class="p">[</span><span class="n">t</span> <span class="o">+</span> <span class="mi">1</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">outputs</span><span class="p">[</span><span class="n">t</span><span class="p">][</span><span class="n">i</span><span class="p">])</span><span class="o">*</span><span class="n">td_sum</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">w21</span> <span class="o">+=</span> <span class="n">delta</span><span class="p">[</span><span class="s2">"dw21"</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">w32</span> <span class="o">+=</span> <span class="n">delta</span><span class="p">[</span><span class="s2">"dw32"</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">b2</span> <span class="o">+=</span> <span class="n">delta</span><span class="p">[</span><span class="s2">"db2"</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">b3</span> <span class="o">+=</span> <span class="n">delta</span><span class="p">[</span><span class="s2">"db3"</span><span class="p">]</span>
</pre></div>

<p>The way I use this is I play through a whole game (or rather, the neural net
plays against itself), and then I send the states of that game, from start to
finish, into <code>train()</code>, along with the final result. It then takes this game
log, and applies the above formula to alter weights using the first game
state, then the first and second game states, and so on until the final time,
when it uses the entire list of game states. Then I repeat that many times and
hope that the network learns.</p>
<p>To be clear, I am not after feedback on my code writing. This was never meant
to be more than a quick and dirty implementation to see that I have all the
nuts and bolts in the right spots.</p>
<p>However, I have no idea whether it is correct, as I have thus far been unable
to make it capable of playing tic-tac-toe at any reasonable level. There could
be many reasons for that. Maybe I'm not giving it enough hidden nodes (I have
used 10 to 12). Maybe it needs more games to train (I have used 200 000).
Maybe it would do better with different normalisation functions (I've tried
sigmoid and ReLU, leaky and non-leaky, in different variations). Maybe the
learning parameters are not tuned right. Maybe tic-tac-toe and its
deterministic gameplay means it "locks in" on certain paths in the game tree.
Or maybe the training implementation is just wrong. Which is why I'm here.</p>
<p>Have I misunderstood Tesauro's algorithm?</p>
<p><br><br></p>
<h2>Answer</h2>
<p>I can't say that I entirely understand your implementation, but this line
jumps out to me:</p>
<div class="code"><pre class="code literal-block"><span class="w">                    </span><span class="n">td_sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">sum</span><span class="p">(</span><span class="o">[</span><span class="n">l**(t-k)*grad[i</span><span class="o">][</span><span class="n">key</span><span class="o">]</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="k">range</span><span class="p">(</span><span class="n">t</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="p">)</span><span class="err">]</span><span class="p">)</span>
</pre></div>

<p>Comparing with the formula you reference:</p>
<p><img alt="" src="images/ZaXPB.png"></p>
<p>I see at least two differences:</p>
<ul>
<li>Your implementation sums over <code>t+1</code> elements compared to <code>t</code> elements in the formula</li>
<li>The gradient should be indexed with the same <code>k</code> as used in <code>l**(t-k)</code>, but in your implementation it is indexed with <code>i</code> and <code>key</code>, without any reference to <code>k</code>
</li>
</ul>
<p>Perhaps if you fix these discrepancies your solution will behave more as
expected.</p>
    </div>
    </article>
</div>

        <nav class="postindexpager"><ul class="pager">
<li class="previous">
                <a href="index-1409.html" rel="prev">Newer posts</a>
            </li>
            <li class="next">
                <a href="index-1407.html" rel="next">Older posts</a>
            </li>
        </ul></nav>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2023         Go to StackOverflow Chinese Site  <a href="http://stackoverflow.ink">StackOverflow-ZH</a>  
            
        </footer>
</div>
</div>


            <script src="assets/js/all-nocdn.js"></script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script><script src="assets/js/search.js"></script>
</body>
</html>
