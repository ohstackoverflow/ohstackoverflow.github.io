<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="This is a snapshot site for StackOverflow">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>StackOverflow Snapshot (old posts, page 1410) | StackOverflow Snapshot</title>
<link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="canonical" href="https://ohstackoverflow.netlify.app/index-1410.html">
<link rel="prev" href="index-1411.html" type="text/html">
<link rel="next" href="index-1409.html" type="text/html">
<!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]-->
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://ohstackoverflow.netlify.app/">

                <span id="blog-title">StackOverflow Snapshot</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="archive.html">Archive</a>
                </li>
<li>
<a href="categories/">Tags</a>

                
            </li>
</ul>
<ul class="nav navbar-nav navbar-right">
<div style="display:table;min-height:5rem;min-width:27rem;">
					<div class="input-group" style="display: table-cell;vertical-align: middle;">
						<input id="words" type="text" class="form-control" style="max-width:22rem;" onkeydown="if(event.keyCode==13){btn.click()}"><span class="input-group-btn" style="float:left">
							<button id="btn" class="btn btn-default" type="button" data-toggle="modal" data-target="#myModal">
								<span class="glyphicon glyphicon-search">
							</span></button>
						</span>
					</div>
<!-- /input-group -->
				</div>

				
                
                
                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><!-- 模态框（Modal） --><div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true">
	<div class="modal-dialog">
		<div class="modal-content">
			<div class="modal-header">
				<button type="button" class="close" data-dismiss="modal" aria-hidden="true">×
				</button>
				<h4 class="modal-title" id="myModalLabel">
					查找结果
				</h4>
			</div>
			<div class="modal-body">
				<div id="search-count" style="min-height:4rem;">
				查找中，请稍后...
				</div>
				<div id="search-result">
				</div>

				
			</div>
			<div class="modal-footer">
				<button type="button" class="btn btn-default" data-dismiss="modal">
					关闭
				</button>
			</div>
		</div>
<!-- /.modal-content -->
	</div>
<!-- /.modal-dialog -->
</div>
<!-- /.modal -->

<div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            

    


    
<div class="postindex">
    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/how-to-implement-the-gaussian-mutation-operator-for-a-genetic-algorithm-in-java/" class="u-url">How to implement the Gaussian mutation operator for a genetic algorithm in Java</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="posts/how-to-implement-the-gaussian-mutation-operator-for-a-genetic-algorithm-in-java/" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T03:23:00+08:00" itemprop="datePublished" title="2023-02-28 03:23">2023-02-28 03:23</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>I try to learn and implement a simple genetic algorithm library for my
project. At this time, evolution, selection of population is ready, and I'm
trying to implement a simple good mutation operator like the Gaussian mutation
operator (GMO) for my genetic evolution engine in Java and Scala.</p>
<p>I find some information on Gaussian mutation operator (GMO) into the paper <em>A
mutation operator based on a Pareto ranking for multi-objective evolutionary
algorithms</em> (P.M. Mateo, I. Alberto), page 6 and 7.</p>
<p>But I have some problem to find other information on how to implement this
Gaussian mutation operator and other useful variants of this operator in Java.
What should I do?</p>
<p>I'm using the <code>random.nextGaussian()</code> function of random Java util, but this
method only returns a random number between 0 and 1.</p>
<p>So,</p>
<p>a) How can I modify the precision of the return number in this case? (For
example, I want to get a random double number between 0 and 1 with step equal
to 0.00001.)</p>
<p>b) and how can I specify <code>mu</code> and <code>sigma</code> for this function, because I want to
search locally about a value of my genome, not between -1 and 1. How can I
ajust that local research around my genome value?</p>
<p>After research, I found an answer for the b) question. It seems I can displace
the Gaussian random number like this:</p>
<div class="code"><pre class="code literal-block"> newGenomeValue = oldGenomeValue + (( gaussiandRndNumber * sigma ) + mean )
</pre></div>

<p>where <code>mean</code> = my genome value.</p>
<p>(Cf. method of bottom page in How can I generate random numbers with a normal
or Gaussian distribution?.)</p>
<p><br><br></p>
<h2>Answer</h2>
<p>To answer question a, all you have to do is round to the nearest 0.00001 to
get your answer in those units. For example:</p>
<div class="code"><pre class="code literal-block">  step = 0.00001;
  quantized_x = step * Math.rint(x / step);
</pre></div>

<p>Now for part b, you have the right idea and the code you presented should
work. All you need to do is rescale your variable to the desired range. The
only thing I can add is that the underlying reason this works is the change of
variables theorem from calculus:
http://en.wikipedia.org/wiki/Integration_by_substitution</p>
<p>If you work out this formula in the case of a Gaussian distribution with 0
mean and standard deviation 1 being transformed by a linear shift and a
rescaling, then you will see that what you wrote out was indeed correct.</p>
<p>Putting it all together, here is some code that should do the trick:</p>
<div class="code"><pre class="code literal-block"><span class="nv">double</span><span class="w"> </span><span class="nv">next_gaussian</span><span class="ss">()</span>
{
<span class="w">    </span><span class="nv">double</span><span class="w"> </span><span class="nv">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">rng</span>.<span class="nv">nextGaussian</span><span class="ss">()</span><span class="c1">;  //Use whichever method you like </span>
<span class="w">                                    </span><span class="o">//</span><span class="nv">here</span><span class="w"> </span><span class="nv">to</span><span class="w"> </span><span class="nv">generate</span><span class="w"> </span><span class="nv">an</span><span class="w"> </span><span class="nv">initial</span><span class="w"> </span>[<span class="o">-</span><span class="mi">1</span>,<span class="mi">1</span>]<span class="w"> </span><span class="nv">gaussian</span><span class="w"> </span><span class="nv">distribution</span>

<span class="w">    </span><span class="nv">y</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="ss">(</span><span class="nv">x</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">0</span>.<span class="mi">5</span><span class="ss">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">0</span>.<span class="mi">5</span><span class="c1">;                //Rescale to [0,1]</span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nv">Math</span>.<span class="nv">rint</span><span class="ss">(</span><span class="nv">y</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">100000</span>.<span class="mi">0</span><span class="ss">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="mi">0</span>.<span class="mi">00001</span><span class="c1">; //Quantize to step size 0.00001</span>
}
</pre></div>

<p><br></p>
<h3>Suggest</h3>
<p>I strongly suggest to <strong>DO NOT</strong> use the Java's random number generator. It
uses the linear congruential generator, which has known limitations:</p>
<blockquote>
<p>If higher quality random numbers are needed, and sufficient memory is
available (~ 2 kilobytes), then the Mersenne twister algorithm provides a
vastly longer period (219937-1) and variate uniformity.[9] The Mersenne
twister generates higher-quality deviates than almost any LCG.[citation
needed] A common Mersenne twister implementation, interestingly enough, uses
an LCG to generate seed data.* (From Wikipedia)</p>
</blockquote>
<p>Accordingly, I suggest you to consider a Mersenne twister implementation. In
particular, I'm using the ECJ's implementation, which also has the ability to
generate <strong>Gaussian numbers</strong>.</p>
<p>If you need compatibility with Java's Random interface use
http://code.google.com/p/ecj/source/browse/trunk/ecj/ec/util/MersenneTwister.java.</p>
<p>http://code.google.com/p/ecj/source/browse/trunk/ecj/ec/util/MersenneTwisterFast.java
is faster, but it does not implement the Random interface.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/neural-network-in-javascript-not-learning-properly/" class="u-url">Neural network in Javascript not learning properly</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="posts/neural-network-in-javascript-not-learning-properly/" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T03:22:39+08:00" itemprop="datePublished" title="2023-02-28 03:22">2023-02-28 03:22</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>I've tried to rewrite neural network found here to javascript. My javascript
code looks like this.</p>
<div class="code"><pre class="code literal-block"><span class="k">function</span><span class="w"> </span><span class="n">NeuralFactor</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">    </span><span class="nf">var</span><span class="w"> </span><span class="n">self</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">this</span><span class="p">;</span>
<span class="w">    </span><span class="n">this</span><span class="p">.</span><span class="n">weight</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">weight</span><span class="p">;</span>
<span class="w">    </span><span class="n">this</span><span class="p">.</span><span class="n">delta</span><span class="w"> </span><span class="o">=</span><span class="w">  </span><span class="mi">0</span><span class="p">;</span>
<span class="err">}</span>

<span class="k">function</span><span class="w"> </span><span class="n">Sigmoid</span><span class="p">(</span><span class="k">value</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="mi">1</span><span class="w"> </span><span class="o">/</span><span class="w"> </span><span class="p">(</span><span class="mi">1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Math</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="o">-</span><span class="k">value</span><span class="p">));</span>
<span class="err">}</span>

<span class="k">function</span><span class="w"> </span><span class="n">Neuron</span><span class="p">(</span><span class="n">isInput</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">    </span><span class="nf">var</span><span class="w"> </span><span class="n">self</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">this</span><span class="p">;</span>
<span class="w">    </span><span class="n">this</span><span class="p">.</span><span class="n">pulse</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">function</span><span class="p">()</span><span class="w"> </span><span class="err">{</span>
<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="k">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="k">input</span><span class="p">.</span><span class="n">forEach</span><span class="p">(</span><span class="k">function</span><span class="p">(</span><span class="n">item</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="k">output</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">item</span><span class="p">.</span><span class="n">signal</span><span class="p">.</span><span class="k">output</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">item</span><span class="p">.</span><span class="n">factor</span><span class="p">.</span><span class="n">weight</span><span class="p">;</span>
<span class="w">        </span><span class="err">}</span><span class="p">);</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="k">output</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">bias</span><span class="p">.</span><span class="n">weight</span><span class="p">;</span>
<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="k">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">Sigmoid</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="k">output</span><span class="p">);</span>
<span class="w">    </span><span class="err">}</span><span class="p">;</span>

<span class="w">    </span><span class="n">this</span><span class="p">.</span><span class="n">bias</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">NeuralFactor</span><span class="p">(</span><span class="n">isInput</span><span class="w"> </span><span class="vm">?</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="err">:</span><span class="w"> </span><span class="n">Math</span><span class="p">.</span><span class="n">random</span><span class="p">());</span>
<span class="w">    </span><span class="n">this</span><span class="p">.</span><span class="n">error</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">    </span><span class="n">this</span><span class="p">.</span><span class="k">input</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">[]</span><span class="p">;</span>
<span class="w">    </span><span class="n">this</span><span class="p">.</span><span class="k">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>

<span class="w">    </span><span class="n">this</span><span class="p">.</span><span class="n">findInput</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">signal</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">        </span><span class="nf">var</span><span class="w"> </span><span class="k">input</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="k">input</span><span class="p">.</span><span class="k">filter</span><span class="p">(</span><span class="k">function</span><span class="p">(</span><span class="k">input</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">            </span><span class="k">return</span><span class="w"> </span><span class="n">signal</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="k">input</span><span class="p">.</span><span class="n">signal</span><span class="p">;</span>
<span class="w">        </span><span class="err">}</span><span class="p">)</span><span class="o">[</span><span class="n">0</span><span class="o">]</span><span class="p">;</span>
<span class="w">        </span><span class="k">return</span><span class="w"> </span><span class="k">input</span><span class="p">;</span>
<span class="w">    </span><span class="err">}</span><span class="p">;</span>
<span class="err">}</span>

<span class="k">function</span><span class="w"> </span><span class="n">NeuralLayer</span><span class="p">()</span><span class="w"> </span><span class="err">{</span>
<span class="w">    </span><span class="nf">var</span><span class="w"> </span><span class="n">self</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">this</span><span class="p">;</span>
<span class="w">    </span><span class="n">this</span><span class="p">.</span><span class="n">pulse</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">function</span><span class="p">()</span><span class="w"> </span><span class="err">{</span>
<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">neurons</span><span class="p">.</span><span class="n">forEach</span><span class="p">(</span><span class="k">function</span><span class="p">(</span><span class="n">neuron</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">            </span><span class="n">neuron</span><span class="p">.</span><span class="n">pulse</span><span class="p">();</span>
<span class="w">        </span><span class="err">}</span><span class="p">);</span>
<span class="w">    </span><span class="err">}</span><span class="p">;</span>
<span class="w">    </span><span class="n">this</span><span class="p">.</span><span class="n">neurons</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">[]</span><span class="p">;</span>
<span class="w">    </span><span class="n">this</span><span class="p">.</span><span class="n">train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">learningRate</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">neurons</span><span class="p">.</span><span class="n">forEach</span><span class="p">(</span><span class="k">function</span><span class="p">(</span><span class="n">neuron</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">            </span><span class="n">neuron</span><span class="p">.</span><span class="n">bias</span><span class="p">.</span><span class="n">weight</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">neuron</span><span class="p">.</span><span class="n">bias</span><span class="p">.</span><span class="n">delta</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">learningRate</span><span class="p">;</span>
<span class="w">            </span><span class="n">neuron</span><span class="p">.</span><span class="n">bias</span><span class="p">.</span><span class="n">delta</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">            </span><span class="n">neuron</span><span class="p">.</span><span class="k">input</span><span class="p">.</span><span class="n">forEach</span><span class="p">(</span><span class="k">function</span><span class="p">(</span><span class="k">input</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">                </span><span class="k">input</span><span class="p">.</span><span class="n">factor</span><span class="p">.</span><span class="n">weight</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="k">input</span><span class="p">.</span><span class="n">factor</span><span class="p">.</span><span class="n">delta</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">learningRate</span><span class="p">;</span>
<span class="w">                </span><span class="k">input</span><span class="p">.</span><span class="n">factor</span><span class="p">.</span><span class="n">delta</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">            </span><span class="err">}</span><span class="p">)</span>
<span class="w">        </span><span class="err">}</span><span class="p">)</span>
<span class="w">    </span><span class="err">}</span>
<span class="err">}</span>

<span class="k">function</span><span class="w"> </span><span class="n">NeuralNet</span><span class="p">(</span><span class="n">inputCount</span><span class="p">,</span><span class="w"> </span><span class="n">hiddenCount</span><span class="p">,</span><span class="w"> </span><span class="n">outputCount</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">    </span><span class="nf">var</span><span class="w"> </span><span class="n">self</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">this</span><span class="p">;</span>
<span class="w">    </span><span class="n">this</span><span class="p">.</span><span class="n">inputLayer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">NeuralLayer</span><span class="p">();</span>
<span class="w">    </span><span class="n">this</span><span class="p">.</span><span class="n">hiddenLayer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">NeuralLayer</span><span class="p">();</span>
<span class="w">    </span><span class="n">this</span><span class="p">.</span><span class="n">outputLayer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">NeuralLayer</span><span class="p">();</span>
<span class="w">    </span><span class="n">this</span><span class="p">.</span><span class="n">learningRate</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mf">0.5</span><span class="p">;</span>

<span class="w">    </span><span class="k">for</span><span class="p">(</span><span class="nf">var</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">inputCount</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">inputLayer</span><span class="p">.</span><span class="n">neurons</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="k">new</span><span class="w"> </span><span class="n">Neuron</span><span class="p">(</span><span class="k">true</span><span class="p">));</span>

<span class="w">    </span><span class="k">for</span><span class="p">(</span><span class="nf">var</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">hiddenCount</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">hiddenLayer</span><span class="p">.</span><span class="n">neurons</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="k">new</span><span class="w"> </span><span class="n">Neuron</span><span class="p">());</span>

<span class="w">    </span><span class="k">for</span><span class="p">(</span><span class="nf">var</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">outputCount</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">outputLayer</span><span class="p">.</span><span class="n">neurons</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="k">new</span><span class="w"> </span><span class="n">Neuron</span><span class="p">());</span>

<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="nf">var</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">hiddenCount</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="nf">var</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">inputCount</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="o">++</span><span class="p">)</span>
<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">hiddenLayer</span><span class="p">.</span><span class="n">neurons</span><span class="o">[</span><span class="n">i</span><span class="o">]</span><span class="p">.</span><span class="k">input</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="err">{</span>
<span class="w">                </span><span class="nl">signal</span><span class="p">:</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">inputLayer</span><span class="p">.</span><span class="n">neurons</span><span class="o">[</span><span class="n">j</span><span class="o">]</span><span class="p">,</span>
<span class="w">                </span><span class="nl">factor</span><span class="p">:</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">NeuralFactor</span><span class="p">(</span><span class="n">Math</span><span class="p">.</span><span class="n">random</span><span class="p">())</span>
<span class="w">            </span><span class="err">}</span><span class="p">);</span>

<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="nf">var</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">outputCount</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="nf">var</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">hiddenCount</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="o">++</span><span class="p">)</span>
<span class="w">            </span><span class="n">self</span><span class="p">.</span><span class="n">outputLayer</span><span class="p">.</span><span class="n">neurons</span><span class="o">[</span><span class="n">i</span><span class="o">]</span><span class="p">.</span><span class="k">input</span><span class="p">.</span><span class="n">push</span><span class="p">(</span><span class="err">{</span>
<span class="w">                </span><span class="nl">signal</span><span class="p">:</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">hiddenLayer</span><span class="p">.</span><span class="n">neurons</span><span class="o">[</span><span class="n">j</span><span class="o">]</span><span class="p">,</span>
<span class="w">                </span><span class="nl">factor</span><span class="p">:</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">NeuralFactor</span><span class="p">(</span><span class="n">Math</span><span class="p">.</span><span class="n">random</span><span class="p">())</span>
<span class="w">            </span><span class="err">}</span><span class="p">);</span>

<span class="w">    </span><span class="n">this</span><span class="p">.</span><span class="n">pulse</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">function</span><span class="p">()</span><span class="w"> </span><span class="err">{</span>
<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">hiddenLayer</span><span class="p">.</span><span class="n">pulse</span><span class="p">();</span>
<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">outputLayer</span><span class="p">.</span><span class="n">pulse</span><span class="p">();</span>
<span class="w">    </span><span class="err">}</span><span class="p">;</span>

<span class="w">    </span><span class="n">this</span><span class="p">.</span><span class="n">backPropagation</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="n">desiredResults</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">        </span><span class="k">for</span><span class="p">(</span><span class="nf">var</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">outputLayer</span><span class="p">.</span><span class="n">neurons</span><span class="p">.</span><span class="n">length</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">            </span><span class="nf">var</span><span class="w"> </span><span class="n">outputNeuron</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">outputLayer</span><span class="p">.</span><span class="n">neurons</span><span class="o">[</span><span class="n">i</span><span class="o">]</span><span class="p">;</span>
<span class="w">            </span><span class="nf">var</span><span class="w"> </span><span class="k">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">outputNeuron</span><span class="p">.</span><span class="k">output</span><span class="p">;</span>
<span class="w">            </span><span class="n">outputNeuron</span><span class="p">.</span><span class="n">error</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">desiredResults</span><span class="o">[</span><span class="n">i</span><span class="o">]</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="k">output</span><span class="p">)</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">output</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="mf">1.0</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="k">output</span><span class="p">);</span>
<span class="w">        </span><span class="err">}</span>
<span class="w">        </span><span class="k">for</span><span class="p">(</span><span class="nf">var</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">hiddenLayer</span><span class="p">.</span><span class="n">neurons</span><span class="p">.</span><span class="n">length</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">            </span><span class="nf">var</span><span class="w"> </span><span class="n">hiddenNeuron</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">hiddenLayer</span><span class="p">.</span><span class="n">neurons</span><span class="o">[</span><span class="n">i</span><span class="o">]</span><span class="p">;</span>
<span class="w">            </span><span class="nf">var</span><span class="w"> </span><span class="n">error</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">            </span><span class="k">for</span><span class="p">(</span><span class="nf">var</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">outputLayer</span><span class="p">.</span><span class="n">neurons</span><span class="p">.</span><span class="n">length</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">                </span><span class="nf">var</span><span class="w"> </span><span class="n">outputNeuron</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">outputLayer</span><span class="p">.</span><span class="n">neurons</span><span class="o">[</span><span class="n">j</span><span class="o">]</span><span class="p">;</span>
<span class="w">                </span><span class="n">error</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">outputNeuron</span><span class="p">.</span><span class="n">error</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">outputNeuron</span><span class="p">.</span><span class="n">findInput</span><span class="p">(</span><span class="n">hiddenNeuron</span><span class="p">).</span><span class="n">factor</span><span class="p">.</span><span class="n">weight</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">hiddenNeuron</span><span class="p">.</span><span class="k">output</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="p">(</span><span class="mf">1.0</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="n">hiddenNeuron</span><span class="p">.</span><span class="k">output</span><span class="p">);</span>
<span class="w">            </span><span class="err">}</span>
<span class="w">            </span><span class="n">hiddenNeuron</span><span class="p">.</span><span class="n">error</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">error</span><span class="p">;</span>
<span class="w">        </span><span class="err">}</span>
<span class="w">        </span><span class="k">for</span><span class="p">(</span><span class="nf">var</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">outputLayer</span><span class="p">.</span><span class="n">neurons</span><span class="p">.</span><span class="n">length</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">            </span><span class="nf">var</span><span class="w"> </span><span class="n">outputNeuron</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">outputLayer</span><span class="p">.</span><span class="n">neurons</span><span class="o">[</span><span class="n">j</span><span class="o">]</span><span class="p">;</span>
<span class="w">            </span><span class="k">for</span><span class="p">(</span><span class="nf">var</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">hiddenLayer</span><span class="p">.</span><span class="n">neurons</span><span class="p">.</span><span class="n">length</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">                </span><span class="nf">var</span><span class="w"> </span><span class="n">hiddenNeuron</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">hiddenLayer</span><span class="p">.</span><span class="n">neurons</span><span class="o">[</span><span class="n">i</span><span class="o">]</span><span class="p">;</span>
<span class="w">                </span><span class="n">outputNeuron</span><span class="p">.</span><span class="n">findInput</span><span class="p">(</span><span class="n">hiddenNeuron</span><span class="p">).</span><span class="n">factor</span><span class="p">.</span><span class="n">delta</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">outputNeuron</span><span class="p">.</span><span class="n">error</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">hiddenNeuron</span><span class="p">.</span><span class="k">output</span><span class="p">;</span>
<span class="w">            </span><span class="err">}</span>
<span class="w">            </span><span class="n">outputNeuron</span><span class="p">.</span><span class="n">bias</span><span class="p">.</span><span class="n">delta</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">outputNeuron</span><span class="p">.</span><span class="n">error</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">outputNeuron</span><span class="p">.</span><span class="n">bias</span><span class="p">.</span><span class="n">weight</span><span class="p">;</span>
<span class="w">        </span><span class="err">}</span>
<span class="w">        </span><span class="k">for</span><span class="p">(</span><span class="nf">var</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">hiddenLayer</span><span class="p">.</span><span class="n">neurons</span><span class="p">.</span><span class="n">length</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">            </span><span class="nf">var</span><span class="w"> </span><span class="n">hiddenNeuron</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">hiddenLayer</span><span class="p">.</span><span class="n">neurons</span><span class="o">[</span><span class="n">j</span><span class="o">]</span><span class="p">;</span>
<span class="w">            </span><span class="k">for</span><span class="p">(</span><span class="nf">var</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">inputLayer</span><span class="p">.</span><span class="n">neurons</span><span class="p">.</span><span class="n">length</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">                </span><span class="nf">var</span><span class="w"> </span><span class="n">inputNeuron</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">inputLayer</span><span class="p">.</span><span class="n">neurons</span><span class="o">[</span><span class="n">i</span><span class="o">]</span><span class="p">;</span>
<span class="w">                </span><span class="n">hiddenNeuron</span><span class="p">.</span><span class="n">findInput</span><span class="p">(</span><span class="n">inputNeuron</span><span class="p">).</span><span class="n">factor</span><span class="p">.</span><span class="n">delta</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">hiddenNeuron</span><span class="p">.</span><span class="n">error</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">inputNeuron</span><span class="p">.</span><span class="k">output</span><span class="p">;</span>
<span class="w">            </span><span class="err">}</span>
<span class="w">            </span><span class="n">hiddenNeuron</span><span class="p">.</span><span class="n">bias</span><span class="p">.</span><span class="n">delta</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">hiddenNeuron</span><span class="p">.</span><span class="n">error</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">hiddenNeuron</span><span class="p">.</span><span class="n">bias</span><span class="p">.</span><span class="n">weight</span><span class="p">;</span>
<span class="w">        </span><span class="err">}</span>
<span class="w">    </span><span class="err">}</span><span class="p">;</span>
<span class="w">    </span><span class="n">this</span><span class="p">.</span><span class="n">train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">function</span><span class="p">(</span><span class="k">input</span><span class="p">,</span><span class="w"> </span><span class="n">desiredResults</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">        </span><span class="k">for</span><span class="p">(</span><span class="nf">var</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">inputLayer</span><span class="p">.</span><span class="n">neurons</span><span class="p">.</span><span class="n">length</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">            </span><span class="nf">var</span><span class="w"> </span><span class="n">neuron</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">self</span><span class="p">.</span><span class="n">inputLayer</span><span class="p">.</span><span class="n">neurons</span><span class="o">[</span><span class="n">i</span><span class="o">]</span><span class="p">;</span>
<span class="w">            </span><span class="n">neuron</span><span class="p">.</span><span class="k">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">input</span><span class="o">[</span><span class="n">i</span><span class="o">]</span><span class="p">;</span>
<span class="w">        </span><span class="err">}</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">pulse</span><span class="p">();</span>
<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">backPropagation</span><span class="p">(</span><span class="n">desiredResults</span><span class="p">);</span>

<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">hiddenLayer</span><span class="p">.</span><span class="n">train</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">learningRate</span><span class="p">);</span>
<span class="w">        </span><span class="n">self</span><span class="p">.</span><span class="n">outputLayer</span><span class="p">.</span><span class="n">train</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">learningRate</span><span class="p">);</span>
<span class="w">    </span><span class="err">}</span><span class="p">;</span>

<span class="err">}</span>
</pre></div>

<p>Now I'm trying to learn it how to resolve XOR problem. I'm teaching it like
this:</p>
<div class="code"><pre class="code literal-block"><span class="nf">var</span><span class="w"> </span><span class="n">net</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="n">NeuralNet</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">1</span><span class="p">);</span>

<span class="nf">var</span><span class="w"> </span><span class="n">testInputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">[</span><span class="n">[0,0</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="o">[</span><span class="n">0,1</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="o">[</span><span class="n">1,0</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="o">[</span><span class="n">1,1</span><span class="o">]</span><span class="err">]</span><span class="p">;</span>
<span class="nf">var</span><span class="w"> </span><span class="n">testOutputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">[</span><span class="n">[1</span><span class="o">]</span><span class="p">,</span><span class="o">[</span><span class="n">0</span><span class="o">]</span><span class="p">,</span><span class="o">[</span><span class="n">0</span><span class="o">]</span><span class="p">,</span><span class="o">[</span><span class="n">1</span><span class="o">]</span><span class="err">]</span><span class="p">;</span>

<span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="nf">var</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">1000</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">++</span><span class="p">)</span>
<span class="w">    </span><span class="k">for</span><span class="p">(</span><span class="nf">var</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mi">4</span><span class="p">;</span><span class="w"> </span><span class="n">j</span><span class="o">++</span><span class="p">)</span>
<span class="w">        </span><span class="n">net</span><span class="p">.</span><span class="n">train</span><span class="p">(</span><span class="n">testInputs</span><span class="o">[</span><span class="n">j</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="n">testOutputs</span><span class="o">[</span><span class="n">j</span><span class="o">]</span><span class="p">);</span>

<span class="k">function</span><span class="w"> </span><span class="n">UseNet</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="w"> </span><span class="n">b</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">    </span><span class="n">net</span><span class="p">.</span><span class="n">inputLayer</span><span class="p">.</span><span class="n">neurons</span><span class="o">[</span><span class="n">0</span><span class="o">]</span><span class="p">.</span><span class="k">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">a</span><span class="p">;</span>
<span class="w">    </span><span class="n">net</span><span class="p">.</span><span class="n">inputLayer</span><span class="p">.</span><span class="n">neurons</span><span class="o">[</span><span class="n">1</span><span class="o">]</span><span class="p">.</span><span class="k">output</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">b</span><span class="p">;</span>
<span class="w">    </span><span class="n">net</span><span class="p">.</span><span class="n">pulse</span><span class="p">();</span>

<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="n">net</span><span class="p">.</span><span class="n">outputLayer</span><span class="p">.</span><span class="n">neurons</span><span class="o">[</span><span class="n">0</span><span class="o">]</span><span class="p">.</span><span class="k">output</span><span class="p">;</span>
<span class="err">}</span>
</pre></div>

<p>The problem is that all results that I get is close to 0.5 and pretty random,
no matter what arguments I use. For example:</p>
<div class="code"><pre class="code literal-block">UseNet(0,0) =&gt; 0.5107701166677714
UseNet(0,1) =&gt; 0.4801498747476413
UseNet(1,0) =&gt; 0.5142463167153447
UseNet(1,1) =&gt; 0.4881829364416052
</pre></div>

<p>What can be wrong with my code?</p>
<p><br><br></p>
<h2>Answer</h2>
<p>This network is big enough for the XOR problem and I can't see any obvious
mistakes, so I suspect it's getting stuck in a local minimum.</p>
<p>Try going through the training set 10,000 times instead of 1000; this gives it
a better chance of breaking out of any minima and converging. You can also
increase convergence a lot by upping the number of hidden neurons, tweaking η
(the learning rate) or adding momentum. To implement the latter, try using
this as your training function:</p>
<div class="code"><pre class="code literal-block"><span class="n">this</span><span class="o">.</span><span class="n">train</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">function</span><span class="p">(</span><span class="n">learningRate</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="k">var</span><span class="w"> </span><span class="n">momentum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="w"> </span><span class="o">/*</span><span class="w"> </span><span class="n">Some</span><span class="w"> </span><span class="n">value</span><span class="p">,</span><span class="w"> </span><span class="n">probably</span><span class="w"> </span><span class="n">fairly</span><span class="w"> </span><span class="n">small</span><span class="o">.</span><span class="w"> </span><span class="o">*/</span><span class="p">;</span>
<span class="w">    </span><span class="bp">self</span><span class="o">.</span><span class="n">neurons</span><span class="o">.</span><span class="n">forEach</span><span class="p">(</span><span class="n">function</span><span class="p">(</span><span class="n">neuron</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">        </span><span class="n">neuron</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">weight</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="n">neuron</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">delta</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">learningRate</span><span class="p">;</span>
<span class="w">        </span><span class="n">neuron</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">delta</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">        </span><span class="n">neuron</span><span class="o">.</span><span class="n">input</span><span class="o">.</span><span class="n">forEach</span><span class="p">(</span><span class="n">function</span><span class="p">(</span><span class="n">input</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">            </span><span class="n">input</span><span class="o">.</span><span class="n">factor</span><span class="o">.</span><span class="n">weight</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="p">(</span><span class="n">input</span><span class="o">.</span><span class="n">factor</span><span class="o">.</span><span class="n">delta</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">learningRate</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="p">(</span><span class="n">input</span><span class="o">.</span><span class="n">factor</span><span class="o">.</span><span class="n">weight</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">momentum</span><span class="p">);</span>
<span class="w">            </span><span class="n">input</span><span class="o">.</span><span class="n">factor</span><span class="o">.</span><span class="n">delta</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span>
<span class="w">        </span><span class="p">})</span>
<span class="w">    </span><span class="p">})</span>
<span class="p">}</span>
</pre></div>

<p>I've had good results changing the learning rate to 1.5 (which is pretty high)
and momentum to 0.000001 (which is pretty small).</p>
<p>(Incidentally, have you tried running the .NET implementation with a few
different seeds? It can take <em>quite</em> a while to converge too!)</p>
<p><br></p>
<h3>Suggest</h3>
<p>This system uses fuzzy logic. As it says in the article don't use integers
instead use "close" real numbers as the article suggests -- try</p>
<div class="code"><pre class="code literal-block">UseNet(0.1,0.1) =&gt; 
UseNet(0.1,0.9) =&gt; 
UseNet(0.9,0.1) =&gt; 
UseNet(0.9,0.9) =&gt;
</pre></div>

<p>For the results anything above 0.5 is a 1 and below is 0</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/how-to-align-two-different-pictures-in-such-a-way-that-they-match-as-close-as-possible/" class="u-url">How to align two different pictures in such a way, that they match as close as possible?</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="posts/how-to-align-two-different-pictures-in-such-a-way-that-they-match-as-close-as-possible/" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T03:22:19+08:00" itemprop="datePublished" title="2023-02-28 03:22">2023-02-28 03:22</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>I need to automatically align an image <strong>B</strong> on top of another image <strong>A</strong> in
such a way, that the contents of the image match as good as possible.</p>
<p>The images can be shifted in x/y directions and rotated up to 5 degrees on z,
but they won't be distorted (i.e. scaled or keystoned).</p>
<p>Maybe someone can recommend some good links or books on this topic, or share
some thoughts how such an alignment of images could be done.</p>
<p>If there wasn't the rotation problem, then I could simply try to compare rows
of pixels with a brute-force method until I find a match, and then I know the
offset and can align the image.</p>
<p>Do I need AI for this?</p>
<p>I'm having a hard time finding resources on image processing which go into
detail how these alignment-algorithms work.</p>
<p><br><br></p>
<h2>Answer</h2>
<p>So what people often do in this case is first find points in the images that
match then compute the best transformation matrix with least squares. The
point matching is not particularly simple and often times you just use human
input for this task, you have to do it all the time for calibrating cameras.
Anyway, if you want to fully automate this process you can use feature
extraction techniques to find matching points, there are volumes of research
papers written on this topic and any standard computer vision text will have a
chapter on this. Once you have N matching points, solving for the least
squares transformation matrix is pretty straightforward and, again, can be
found in any computer vision text, so I'll assume you got that covered.</p>
<p>If you don't want to find point correspondences you could directly optimize
the rotation and translation using steepest descent, trouble is this is non-
convex so there are no guarantees you will find the correct transformation.
You could do random restarts or simulated annealing or any other global
optimization tricks on top of this, that would most likely work. I can't find
any references to this problem, but it's basically a digital image
stabilization algorithm I had to implement it when I took computer vision but
that was many years ago, here are the relevant slides though, look at
"stabilization revisited". Yes, I know those slides are terrible, I didn't
make them :) However, the method for determining the gradient is quite an
elegant one, since finite difference is clearly intractable.</p>
<p>Edit: I finally found the paper that went over how to do this here, it's a
really great paper and it explains the Lucas-Kanade algorithm very nicely.
Also, this site has a whole lot of material and source code on image alignment
that will probably be useful.</p>
    </div>
    </article>
</div>

        <nav class="postindexpager"><ul class="pager">
<li class="previous">
                <a href="index-1411.html" rel="prev">Newer posts</a>
            </li>
            <li class="next">
                <a href="index-1409.html" rel="next">Older posts</a>
            </li>
        </ul></nav>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2023         Go to StackOverflow Chinese Site  <a href="http://stackoverflow.ink">StackOverflow中文网</a>  
            
        </footer>
</div>
</div>


            <script src="assets/js/all-nocdn.js"></script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script><script src="assets/js/search.js"></script>
</body>
</html>
