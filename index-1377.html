<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="This is a snapshot site for StackOverflow">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>StackOverflow Snapshot (old posts, page 1377) | StackOverflow Snapshot</title>
<link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="canonical" href="https://ohstackoverflow.netlify.app/index-1377.html">
<link rel="prev" href="index-1378.html" type="text/html">
<link rel="next" href="index-1376.html" type="text/html">
<!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]-->
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://ohstackoverflow.netlify.app/">

                <span id="blog-title">StackOverflow Snapshot</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="archive.html">Archive</a>
                </li>
<li>
<a href="categories/">Tags</a>

                
            </li>
</ul>
<ul class="nav navbar-nav navbar-right">
<div style="display:table;min-height:5rem;min-width:27rem;">
					<div class="input-group" style="display: table-cell;vertical-align: middle;">
						<input id="words" type="text" class="form-control" style="max-width:22rem;" onkeydown="if(event.keyCode==13){btn.click()}"><span class="input-group-btn" style="float:left">
							<button id="btn" class="btn btn-default" type="button" data-toggle="modal" data-target="#myModal">
								<span class="glyphicon glyphicon-search">
							</span></button>
						</span>
					</div>
<!-- /input-group -->
				</div>

				
                
                
                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><!-- 模态框（Modal） --><div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true">
	<div class="modal-dialog">
		<div class="modal-content">
			<div class="modal-header">
				<button type="button" class="close" data-dismiss="modal" aria-hidden="true">×
				</button>
				<h4 class="modal-title" id="myModalLabel">
					查找结果
				</h4>
			</div>
			<div class="modal-body">
				<div id="search-count" style="min-height:4rem;">
				查找中，请稍后...
				</div>
				<div id="search-result">
				</div>

				
			</div>
			<div class="modal-footer">
				<button type="button" class="btn btn-default" data-dismiss="modal">
					关闭
				</button>
			</div>
		</div>
<!-- /.modal-content -->
	</div>
<!-- /.modal-dialog -->
</div>
<!-- /.modal -->

<div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            

    


    
<div class="postindex">
    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/should-there-be-one-bias-per-layer-or-one-bias-for-each-node/" class="u-url">Should there be one bias per layer or one bias for each node?</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="posts/should-there-be-one-bias-per-layer-or-one-bias-for-each-node/" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T02:48:17+08:00" itemprop="datePublished" title="2023-02-28 02:48">2023-02-28 02:48</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>I am looking to implement a generic neural network, with 1 input layer
consisting of input nodes, 1 output layer consisting of output nodes, and N
hidden layers consisting of hidden nodes. Nodes are organized into layers,
with the rule that nodes in the same layer cannot be connected.</p>
<p>I mostly understand the concept of the bias, but I have a question.</p>
<p>Should there be one bias value per layer (shared by all nodes in that layer)
or should each node (except nodes in the input layer) have their own bias
value?</p>
<p>I have a feeling it could be done both ways, and would like to understand the
trade-offs of each approach, and also know what implementation is most
commonly used.</p>
<p><br><br></p>
<h2>Answer</h2>
<h4>Intuitive View</h4>
<p>To answer this question properly, we should first establish exactly what we
mean when we say "Bias value" as done in the question. Neural Networks are
typically intuitively viewed (and explained to beginners) as a network of
nodes (neurons) and weighted, directed connections between nodes. In this
view, Biases are very frequently drawn as additional ''input'' nodes, which
always have an activation level of exactly <code>1.0</code>. This value of <code>1.0</code> may be
what some people think of when they hear "Bias Value". Such a Bias Node would
have connections to other nodes, with trainable weights. Other people may
think of those weights as "Bias Values". Since the question was tagged with
the <code>bias-neuron</code> tag, I'll answer the question under the assumption that we
use the first definition, e.g. Bias Value = <code>1.0</code> for some Bias Node / neuron.</p>
<p>From this point of view... it absolutely does not matter at all mathematically
how many Bias nodes/values we put in our network, as long as we make sure to
connect them to the correct nodes. You could intuitively think of the entire
network as having only a single bias node with a value of <code>1.0</code> that does not
belong to any particular layer, and has connections to all nodes other than
the input nodes. This may be difficult to draw though, if you want to make a
drawing of your neural network it may be more convenient to place a separate
bias node (each with a value of <code>1.0</code>) in every layer except for the output
layer, and connect each of those bias nodes to all the nodes in the layer
directly after it. Mathematically, these two interpretations are equivalent,
since in both cases every non-input node has an incoming weighted connection
from a node that always has an activation level of <code>1.0</code>.</p>
<h4>Programming View</h4>
<p>When Neural Networks are programmed, there typically aren't any explicit node
''objects'' at all (at least in efficient implementations). There will
generally just be matrices for the weights. From this point of view, there is
no longer any choice. We'll (almost) always want one ''bias-weight'' (a weight
being multiplied by a constant activation level of <code>1.0</code>) going to every non-
input node, and we'll have to make sure all those weights appear in the
correct spots in our weight matrices.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/tensorflow-typeerror-fetch-argument-none-has-invalid-type-type-nonetype/" class="u-url">Tensorflow TypeError: Fetch argument None has invalid type &lt;type 'NoneType'&gt;?</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="posts/tensorflow-typeerror-fetch-argument-none-has-invalid-type-type-nonetype/" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T02:47:57+08:00" itemprop="datePublished" title="2023-02-28 02:47">2023-02-28 02:47</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>I'm building a RNN loosely based on the TensorFlow tutorial.</p>
<p>The relevant parts of my model are as follows:</p>
<div class="code"><pre class="code literal-block"><span class="n">input_sequence</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">,</span><span class="w"> </span><span class="o">[</span><span class="n">BATCH_SIZE, TIME_STEPS, PIXEL_COUNT + AUX_INPUTS</span><span class="o">]</span><span class="p">)</span>
<span class="n">output_actual</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">,</span><span class="w"> </span><span class="o">[</span><span class="n">BATCH_SIZE, OUTPUT_SIZE</span><span class="o">]</span><span class="p">)</span>

<span class="n">lstm_cell</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">rnn_cell</span><span class="p">.</span><span class="n">BasicLSTMCell</span><span class="p">(</span><span class="n">CELL_SIZE</span><span class="p">,</span><span class="w"> </span><span class="n">state_is_tuple</span><span class="o">=</span><span class="k">False</span><span class="p">)</span>
<span class="n">stacked_lstm</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">rnn_cell</span><span class="p">.</span><span class="n">MultiRNNCell</span><span class="p">(</span><span class="o">[</span><span class="n">lstm_cell</span><span class="o">]</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">CELL_LAYERS</span><span class="p">,</span><span class="w"> </span><span class="n">state_is_tuple</span><span class="o">=</span><span class="k">False</span><span class="p">)</span>

<span class="n">initial_state</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">state</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">stacked_lstm</span><span class="p">.</span><span class="n">zero_state</span><span class="p">(</span><span class="n">BATCH_SIZE</span><span class="p">,</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">outputs</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="err">[]</span>

<span class="k">with</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="ss">"LSTM"</span><span class="p">)</span><span class="err">:</span>
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">xrange</span><span class="p">(</span><span class="n">TIME_STEPS</span><span class="p">)</span><span class="err">:</span>
<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">step</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="err">:</span>
<span class="w">            </span><span class="n">tf</span><span class="p">.</span><span class="n">get_variable_scope</span><span class="p">().</span><span class="n">reuse_variables</span><span class="p">()</span>
<span class="w">        </span><span class="n">cell_output</span><span class="p">,</span><span class="w"> </span><span class="k">state</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">stacked_lstm</span><span class="p">(</span><span class="n">input_sequence</span><span class="o">[</span><span class="n">:, step, :</span><span class="o">]</span><span class="p">,</span><span class="w"> </span><span class="k">state</span><span class="p">)</span>
<span class="w">        </span><span class="n">outputs</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">cell_output</span><span class="p">)</span>

<span class="n">final_state</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="k">state</span>
</pre></div>

<p>And the feeding:</p>
<div class="code"><pre class="code literal-block"><span class="n">cross_entropy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="o">-</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">output_actual</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">prediction</span><span class="p">),</span><span class="w"> </span><span class="n">reduction_indices</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">train_step</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="n">LEARNING_RATE</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cross_entropy</span><span class="p">)</span>
<span class="n">correct_prediction</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">),</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">output_actual</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">))</span>
<span class="n">accuracy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">correct_prediction</span><span class="p">,</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

<span class="n">with</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">sess</span><span class="p">:</span>
<span class="w">    </span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">initialize_all_variables</span><span class="p">())</span>
<span class="w">    </span><span class="n">numpy_state</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">initial_state</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">xrange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="n">ITERATIONS</span><span class="p">):</span>
<span class="w">        </span><span class="n">batch</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">DI</span><span class="o">.</span><span class="n">next_batch</span><span class="p">()</span>

<span class="w">        </span><span class="nb">print</span><span class="w"> </span><span class="n">i</span><span class="p">,</span><span class="w"> </span><span class="n">type</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span><span class="w"> </span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">batch</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span><span class="w"> </span><span class="n">numpy_state</span><span class="o">.</span><span class="n">shape</span>

<span class="w">        </span><span class="k">if</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">LOG_STEP</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mi">0</span><span class="p">:</span>
<span class="w">            </span><span class="n">train_accuracy</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">accuracy</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
<span class="w">                </span><span class="n">initial_state</span><span class="p">:</span><span class="w"> </span><span class="n">numpy_state</span><span class="p">,</span>
<span class="w">                </span><span class="n">input_sequence</span><span class="p">:</span><span class="w"> </span><span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
<span class="w">                </span><span class="n">output_actual</span><span class="p">:</span><span class="w"> </span><span class="n">batch</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="w">            </span><span class="p">})</span>

<span class="w">            </span><span class="nb">print</span><span class="w"> </span><span class="s2">"Iteration "</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">)</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="s2">" Training Accuracy "</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="nb">str</span><span class="p">(</span><span class="n">train_accuracy</span><span class="p">)</span>

<span class="w">        </span><span class="n">numpy_state</span><span class="p">,</span><span class="w"> </span><span class="n">train_step</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">final_state</span><span class="p">,</span><span class="w"> </span><span class="n">train_step</span><span class="p">],</span><span class="w"> </span><span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
<span class="w">            </span><span class="n">initial_state</span><span class="p">:</span><span class="w"> </span><span class="n">numpy_state</span><span class="p">,</span>
<span class="w">            </span><span class="n">input_sequence</span><span class="p">:</span><span class="w"> </span><span class="n">batch</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
<span class="w">            </span><span class="n">output_actual</span><span class="p">:</span><span class="w"> </span><span class="n">batch</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="w">            </span><span class="p">})</span>
</pre></div>

<p>When I run this, I get the following error:</p>
<div class="code"><pre class="code literal-block"><span class="nv">Traceback</span><span class="w"> </span><span class="ss">(</span><span class="nv">most</span><span class="w"> </span><span class="nv">recent</span><span class="w"> </span><span class="k">call</span><span class="w"> </span><span class="nl">last</span><span class="ss">)</span>:
<span class="w">  </span><span class="nv">File</span><span class="w"> </span><span class="s2">"/home/agupta/Documents/Projects/Image-Recognition-with-LSTM/RNN/feature_tracking/model.py"</span>,<span class="w"> </span><span class="nv">line</span><span class="w"> </span><span class="mi">109</span>,<span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="o">&lt;</span><span class="nv">module</span><span class="o">&gt;</span>
<span class="w">    </span><span class="nv">output_actual</span>:<span class="w"> </span><span class="nv">batch</span>[<span class="mi">1</span>]
<span class="w">  </span><span class="nv">File</span><span class="w"> </span><span class="s2">"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"</span>,<span class="w"> </span><span class="nv">line</span><span class="w"> </span><span class="mi">698</span>,<span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">run</span>
<span class="w">    </span><span class="nv">run_metadata_ptr</span><span class="ss">)</span>
<span class="w">  </span><span class="nv">File</span><span class="w"> </span><span class="s2">"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"</span>,<span class="w"> </span><span class="nv">line</span><span class="w"> </span><span class="mi">838</span>,<span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">_run</span>
<span class="w">    </span><span class="nv">fetch_handler</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">_FetchHandler</span><span class="ss">(</span><span class="nv">self</span>.<span class="nv">_graph</span>,<span class="w"> </span><span class="nv">fetches</span><span class="ss">)</span>
<span class="w">  </span><span class="nv">File</span><span class="w"> </span><span class="s2">"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"</span>,<span class="w"> </span><span class="nv">line</span><span class="w"> </span><span class="mi">355</span>,<span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">__init__</span>
<span class="w">    </span><span class="nv">self</span>.<span class="nv">_fetch_mapper</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">_FetchMapper</span>.<span class="nv">for_fetch</span><span class="ss">(</span><span class="nv">fetches</span><span class="ss">)</span>
<span class="w">  </span><span class="nv">File</span><span class="w"> </span><span class="s2">"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"</span>,<span class="w"> </span><span class="nv">line</span><span class="w"> </span><span class="mi">181</span>,<span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">for_fetch</span>
<span class="w">    </span><span class="k">return</span><span class="w"> </span><span class="nv">_ListFetchMapper</span><span class="ss">(</span><span class="nv">fetch</span><span class="ss">)</span>
<span class="w">  </span><span class="nv">File</span><span class="w"> </span><span class="s2">"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"</span>,<span class="w"> </span><span class="nv">line</span><span class="w"> </span><span class="mi">288</span>,<span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">__init__</span>
<span class="w">    </span><span class="nv">self</span>.<span class="nv">_mappers</span><span class="w"> </span><span class="o">=</span><span class="w"> </span>[<span class="nv">_FetchMapper</span>.<span class="nv">for_fetch</span><span class="ss">(</span><span class="nv">fetch</span><span class="ss">)</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="nv">fetch</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">fetches</span>]
<span class="w">  </span><span class="nv">File</span><span class="w"> </span><span class="s2">"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py"</span>,<span class="w"> </span><span class="nv">line</span><span class="w"> </span><span class="mi">178</span>,<span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">for_fetch</span>
<span class="w">    </span><span class="ss">(</span><span class="nv">fetch</span>,<span class="w"> </span><span class="nv">type</span><span class="ss">(</span><span class="nv">fetch</span><span class="ss">)))</span>
<span class="nv">TypeError</span>:<span class="w"> </span><span class="nv">Fetch</span><span class="w"> </span><span class="nv">argument</span><span class="w"> </span><span class="nv">None</span><span class="w"> </span><span class="nv">has</span><span class="w"> </span><span class="nv">invalid</span><span class="w"> </span><span class="nv">type</span><span class="w"> </span><span class="o">&lt;</span><span class="nv">type</span><span class="w"> </span><span class="s1">'NoneType'</span><span class="o">&gt;</span>
</pre></div>

<p>Perhaps the weirdest part is that this error gets thrown the <strong>second</strong>
iteration, and the first works completely fine. I'm ripping my hair trying to
fix this, so any help would be greatly appreciated.</p>
<p><br><br></p>
<h2>Answer</h2>
<p>You are re-assigning the <code>train_step</code> variable to the second element of the
result of <code>sess.run()</code> (which happens to be <code>None</code>). Hence, on the second
iteration, <code>train_step</code> is <code>None</code>, which leads to the error.</p>
<p>The fix is fortunately simple:</p>
<div class="code"><pre class="code literal-block"><span class="k">for</span><span class="w"> </span><span class="nv">i</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">xrange</span><span class="ss">(</span><span class="mi">1</span>,<span class="w"> </span><span class="nv">ITERATIONS</span><span class="ss">)</span>:

<span class="w">    </span>#<span class="w"> </span>...

<span class="w">    </span>#<span class="w"> </span><span class="nv">Discard</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nv">second</span><span class="w"> </span><span class="nv">element</span><span class="w"> </span><span class="nv">of</span><span class="w"> </span><span class="nv">the</span><span class="w"> </span><span class="nb">result</span>.
<span class="w">    </span><span class="nv">numpy_state</span>,<span class="w"> </span><span class="nv">_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">sess</span>.<span class="nv">run</span><span class="ss">(</span>[<span class="nv">final_state</span>,<span class="w"> </span><span class="nv">train_step</span>],<span class="w"> </span><span class="nv">feed_dict</span><span class="o">=</span>{
<span class="w">        </span><span class="nv">initial_state</span>:<span class="w"> </span><span class="nv">numpy_state</span>,
<span class="w">        </span><span class="nv">input_sequence</span>:<span class="w"> </span><span class="nv">batch</span>[<span class="mi">0</span>],
<span class="w">        </span><span class="nv">output_actual</span>:<span class="w"> </span><span class="nv">batch</span>[<span class="mi">1</span>]
<span class="w">        </span>}<span class="ss">)</span>
</pre></div>

<p><br></p>
<h3>Suggest</h3>
<p>Another common reason to get this error is if you include the summary fetch
operation but have not written any summaries.</p>
<p>Example:</p>
<div class="code"><pre class="code literal-block"><span class="c1"># tf.summary.scalar("loss", loss) # &lt;- uncomment this line and it will work fine</span>
<span class="n">summary_op</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">tf.summary.merge_all</span><span class="p">()</span>
<span class="n">sess</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">tf.Session</span><span class="p">()</span>
<span class="c1"># ...</span>
<span class="n">summary</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">sess.run</span><span class="p">([</span><span class="n">summary_op</span><span class="p">,</span><span class="w"> </span><span class="kc">...</span><span class="p">],</span><span class="w"> </span><span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="kc">...</span><span class="p">})</span><span class="w"> </span><span class="c1"># TypeError, summary_op is "None"!</span>
</pre></div>

<p>What's extra confusing is that <code>summary_op</code> is not itself None, that's just
the error that bubbles up from inside the session's run method.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/how-does-a-system-like-wolfram-alpha-or-mathematica-solve-equations/" class="u-url">How does a system like Wolfram Alpha or Mathematica solve equations?</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="posts/how-does-a-system-like-wolfram-alpha-or-mathematica-solve-equations/" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T02:47:36+08:00" itemprop="datePublished" title="2023-02-28 02:47">2023-02-28 02:47</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>I'm building a web-based programming language partially inspired by Prolog and
Haskell (don't laugh).</p>
<p>It already has quite a bit of functionality, you can check out the prototype
at http://www.lastcalc.com/. You can see the source here and read about the
architecture here. Remember it's a prototype.</p>
<p>Currently LastCalc cannot simplify expressions or solve equations. Rather than
hard-coding this in Java, I would like to enhance the fundamental language
such that it can be extended to do these things using nothing but the language
itself (as with Prolog). Unlike Prolog, LastCalc has a more powerful search
algorithm, Prolog is "depth-first search with backtracking", LastCalc
currently uses a heuristic best-first search.</p>
<p>Before delving into this I want to understand more about how other systems
solve this problem, particularly Mathematica / Wolfram Alpha.</p>
<p>I assume the idea, at least in the general case, is that you give the system a
bunch of rules for manipulation of equations (like <code>a*(b+c) = a*b + a+c</code>)
specify the goal (eg. isolate variable x) and then let it loose.</p>
<p>So, my questions are:</p>
<ul>
<li>Is my assumption correct?</li>
<li>What is the search strategy for applying rules? eg. depth first, breadth first, depth first with iterative deepening, some kind of best first?</li>
<li>If it is "best first", what heuristics are used to determine whether it is likely that a particular rule application has got us closer to our goal?</li>
</ul>
<p>I'd also appreciate any other advice (except for "give up" - I regularly
ignore that piece of advice and doing so has served me well ;).</p>
<p><br><br></p>
<h2>Answer</h2>
<p>I dealt with such questions myself some time ago. I then found this document
about simplification of expressions. It is titled <em>Rule-based Simplification
of Expressions</em> and shows some details about simplification in Mupad, which
later became a part of Matlab.</p>
<p>According to this document, your assumption is correct. There is a set of
rules for manipulation of expressions. A heuristic quality metric is is used
as a target function for simplification.</p>
<p><br></p>
<h3>Suggest</h3>
<p>Wolfram alpha is developed by Mathematica</p>
<ul>
<li>mathematica is stephen wolphram's brainchild. Mathematica 1.0 was released in 1988. mathematica is much like maple and they both rely heavily on older software libraries like LaPack. </li>
<li>The libraries that these programs are, based on, and often simply, legacy software. They've been around, and modified, for a very long time. </li>
</ul>
<p>If you would like to know about the background programs running, sagemath is a
free open source alternative; you could possible reverse engineer the
solutions to your questions:</p>
<p>SageMath.org</p>
    </div>
    </article>
</div>

        <nav class="postindexpager"><ul class="pager">
<li class="previous">
                <a href="index-1378.html" rel="prev">Newer posts</a>
            </li>
            <li class="next">
                <a href="index-1376.html" rel="next">Older posts</a>
            </li>
        </ul></nav>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2023         Go to StackOverflow Chinese Site  <a href="http://stackoverflow.ink">StackOverflow中文网</a>  
            
        </footer>
</div>
</div>


            <script src="assets/js/all-nocdn.js"></script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script><script src="assets/js/search.js"></script>
</body>
</html>
