<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="This is a snapshot site for StackOverflow">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>StackOverflow Snapshot (old posts, page 1374) | StackOverflow Snapshot</title>
<link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="canonical" href="https://ohstackoverflow.netlify.app/index-1374.html">
<link rel="prev" href="index-1375.html" type="text/html">
<link rel="next" href="index-1373.html" type="text/html">
<!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]-->
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://ohstackoverflow.netlify.app/">

                <span id="blog-title">StackOverflow Snapshot</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="archive.html">Archive</a>
                </li>
<li>
<a href="categories/">Tags</a>

                
            </li>
</ul>
<ul class="nav navbar-nav navbar-right">
<div style="display:table;min-height:5rem;min-width:27rem;">
					<div class="input-group" style="display: table-cell;vertical-align: middle;">
						<input id="words" type="text" class="form-control" style="max-width:22rem;" onkeydown="if(event.keyCode==13){btn.click()}"><span class="input-group-btn" style="float:left">
							<button id="btn" class="btn btn-default" type="button" data-toggle="modal" data-target="#myModal">
								<span class="glyphicon glyphicon-search">
							</span></button>
						</span>
					</div>
<!-- /input-group -->
				</div>

				
                
                
                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><!-- 模态框（Modal） --><div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true">
	<div class="modal-dialog">
		<div class="modal-content">
			<div class="modal-header">
				<button type="button" class="close" data-dismiss="modal" aria-hidden="true">×
				</button>
				<h4 class="modal-title" id="myModalLabel">
					查找结果
				</h4>
			</div>
			<div class="modal-body">
				<div id="search-count" style="min-height:4rem;">
				查找中，请稍后...
				</div>
				<div id="search-result">
				</div>

				
			</div>
			<div class="modal-footer">
				<button type="button" class="btn btn-default" data-dismiss="modal">
					关闭
				</button>
			</div>
		</div>
<!-- /.modal-content -->
	</div>
<!-- /.modal-dialog -->
</div>
<!-- /.modal -->

<div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            

    


    
<div class="postindex">
    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/how-can-i-split-a-text-into-sentences-using-the-stanford-parser/" class="u-url">How can I split a text into sentences using the Stanford parser?</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="posts/how-can-i-split-a-text-into-sentences-using-the-stanford-parser/" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T02:41:36+08:00" itemprop="datePublished" title="2023-02-28 02:41">2023-02-28 02:41</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>How can I split a text or paragraph into sentences using Stanford parser?</p>
<p>Is there any method that can extract sentences, such as
<code>getSentencesFromString()</code> as it's provided for Ruby?</p>
<p><br><br></p>
<h2>Answer</h2>
<p>You can check the DocumentPreprocessor class. Below is a short snippet. I
think there may be other ways to do what you want.</p>
<div class="code"><pre class="code literal-block"><span class="nv">String</span><span class="w"> </span><span class="nv">paragraph</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s2">"My 1st sentence. “Does it work for questions?” My third sentence."</span><span class="c1">;</span>
<span class="nv">Reader</span><span class="w"> </span><span class="nv">reader</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">new</span><span class="w"> </span><span class="nv">StringReader</span><span class="ss">(</span><span class="nv">paragraph</span><span class="ss">)</span><span class="c1">;</span>
<span class="nv">DocumentPreprocessor</span><span class="w"> </span><span class="nv">dp</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">new</span><span class="w"> </span><span class="nv">DocumentPreprocessor</span><span class="ss">(</span><span class="nv">reader</span><span class="ss">)</span><span class="c1">;</span>
<span class="nv">List</span><span class="o">&lt;</span><span class="nv">String</span><span class="o">&gt;</span><span class="w"> </span><span class="nv">sentenceList</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">new</span><span class="w"> </span><span class="nv">ArrayList</span><span class="o">&lt;</span><span class="nv">String</span><span class="o">&gt;</span><span class="ss">()</span><span class="c1">;</span>

<span class="k">for</span><span class="w"> </span><span class="ss">(</span><span class="nv">List</span><span class="o">&lt;</span><span class="nv">HasWord</span><span class="o">&gt;</span><span class="w"> </span><span class="nv">sentence</span><span class="w"> </span>:<span class="w"> </span><span class="nv">dp</span><span class="ss">)</span><span class="w"> </span>{
<span class="w">   </span><span class="o">//</span><span class="w"> </span><span class="nv">SentenceUtils</span><span class="w"> </span><span class="nv">not</span><span class="w"> </span><span class="nv">Sentence</span>
<span class="w">   </span><span class="nv">String</span><span class="w"> </span><span class="nv">sentenceString</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">SentenceUtils</span>.<span class="nv">listToString</span><span class="ss">(</span><span class="nv">sentence</span><span class="ss">)</span><span class="c1">;</span>
<span class="w">   </span><span class="nv">sentenceList</span>.<span class="nv">add</span><span class="ss">(</span><span class="nv">sentenceString</span><span class="ss">)</span><span class="c1">;</span>
}

<span class="k">for</span><span class="w"> </span><span class="ss">(</span><span class="nv">String</span><span class="w"> </span><span class="nv">sentence</span><span class="w"> </span>:<span class="w"> </span><span class="nv">sentenceList</span><span class="ss">)</span><span class="w"> </span>{
<span class="w">   </span><span class="nv">System</span>.<span class="nv">out</span>.<span class="nv">println</span><span class="ss">(</span><span class="nv">sentence</span><span class="ss">)</span><span class="c1">;</span>
}
</pre></div>

<p><br></p>
<h3>Suggest</h3>
<p>I know there is already an accepted answer...but typically you'd just grab the
SentenceAnnotations from an annotated doc.</p>
<div class="code"><pre class="code literal-block"><span class="o">//</span><span class="w"> </span><span class="n">creates</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">StanfordCoreNLP</span><span class="w"> </span><span class="n">object</span><span class="p">,</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">POS</span><span class="w"> </span><span class="n">tagging</span><span class="p">,</span><span class="w"> </span><span class="n">lemmatization</span><span class="p">,</span><span class="w"> </span><span class="n">NER</span><span class="p">,</span><span class="w"> </span><span class="n">parsing</span><span class="p">,</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">coreference</span><span class="w"> </span><span class="n">resolution</span><span class="w"> </span>
<span class="n">Properties</span><span class="w"> </span><span class="n">props</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">new</span><span class="w"> </span><span class="n">Properties</span><span class="p">();</span>
<span class="n">props</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="s2">"annotators"</span><span class="p">,</span><span class="w"> </span><span class="s2">"tokenize, ssplit, pos, lemma, ner, parse, dcoref"</span><span class="p">);</span>
<span class="n">StanfordCoreNLP</span><span class="w"> </span><span class="n">pipeline</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">new</span><span class="w"> </span><span class="n">StanfordCoreNLP</span><span class="p">(</span><span class="n">props</span><span class="p">);</span>

<span class="o">//</span><span class="w"> </span><span class="n">read</span><span class="w"> </span><span class="n">some</span><span class="w"> </span><span class="n">text</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">text</span><span class="w"> </span><span class="n">variable</span>
<span class="nb nb-Type">String</span><span class="w"> </span><span class="n">text</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="o">...</span><span class="w"> </span><span class="o">//</span><span class="w"> </span><span class="n">Add</span><span class="w"> </span><span class="n">your</span><span class="w"> </span><span class="n">text</span><span class="w"> </span><span class="n">here</span><span class="o">!</span>

<span class="o">//</span><span class="w"> </span><span class="n">create</span><span class="w"> </span><span class="n">an</span><span class="w"> </span><span class="n">empty</span><span class="w"> </span><span class="n">Annotation</span><span class="w"> </span><span class="n">just</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">given</span><span class="w"> </span><span class="n">text</span>
<span class="n">Annotation</span><span class="w"> </span><span class="n">document</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">new</span><span class="w"> </span><span class="n">Annotation</span><span class="p">(</span><span class="n">text</span><span class="p">);</span>

<span class="o">//</span><span class="w"> </span><span class="n">run</span><span class="w"> </span><span class="n">all</span><span class="w"> </span><span class="n">Annotators</span><span class="w"> </span><span class="n">on</span><span class="w"> </span><span class="n">this</span><span class="w"> </span><span class="n">text</span>
<span class="n">pipeline</span><span class="o">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">document</span><span class="p">);</span>

<span class="o">//</span><span class="w"> </span><span class="n">these</span><span class="w"> </span><span class="n">are</span><span class="w"> </span><span class="n">all</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">sentences</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">this</span><span class="w"> </span><span class="n">document</span>
<span class="o">//</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">CoreMap</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">essentially</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">Map</span><span class="w"> </span><span class="n">that</span><span class="w"> </span><span class="n">uses</span><span class="w"> </span><span class="k">class</span><span class="w"> </span><span class="n">objects</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">keys</span><span class="w"> </span><span class="ow">and</span><span class="w"> </span><span class="n">has</span><span class="w"> </span><span class="n">values</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">custom</span><span class="w"> </span><span class="n">types</span>
<span class="n">List</span><span class="o">&lt;</span><span class="n">CoreMap</span><span class="o">&gt;</span><span class="w"> </span><span class="n">sentences</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">document</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">SentencesAnnotation</span><span class="o">.</span><span class="k">class</span><span class="p">);</span>

<span class="k">for</span><span class="p">(</span><span class="n">CoreMap</span><span class="w"> </span><span class="n">sentence</span><span class="p">:</span><span class="w"> </span><span class="n">sentences</span><span class="p">)</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="o">//</span><span class="w"> </span><span class="n">traversing</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">words</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">current</span><span class="w"> </span><span class="n">sentence</span>
<span class="w">  </span><span class="o">//</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">CoreLabel</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">a</span><span class="w"> </span><span class="n">CoreMap</span><span class="w"> </span><span class="n">with</span><span class="w"> </span><span class="n">additional</span><span class="w"> </span><span class="n">token</span><span class="o">-</span><span class="n">specific</span><span class="w"> </span><span class="n">methods</span>
<span class="w">  </span><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">CoreLabel</span><span class="w"> </span><span class="n">token</span><span class="p">:</span><span class="w"> </span><span class="n">sentence</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">TokensAnnotation</span><span class="o">.</span><span class="k">class</span><span class="p">))</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="o">//</span><span class="w"> </span><span class="n">this</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">text</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">token</span>
<span class="w">    </span><span class="nb nb-Type">String</span><span class="w"> </span><span class="n">word</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">token</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">TextAnnotation</span><span class="o">.</span><span class="k">class</span><span class="p">);</span>
<span class="w">    </span><span class="o">//</span><span class="w"> </span><span class="n">this</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">POS</span><span class="w"> </span><span class="n">tag</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">token</span>
<span class="w">    </span><span class="nb nb-Type">String</span><span class="w"> </span><span class="n">pos</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">token</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">PartOfSpeechAnnotation</span><span class="o">.</span><span class="k">class</span><span class="p">);</span>
<span class="w">    </span><span class="o">//</span><span class="w"> </span><span class="n">this</span><span class="w"> </span><span class="k">is</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">NER</span><span class="w"> </span><span class="n">label</span><span class="w"> </span><span class="n">of</span><span class="w"> </span><span class="n">the</span><span class="w"> </span><span class="n">token</span>
<span class="w">    </span><span class="nb nb-Type">String</span><span class="w"> </span><span class="n">ne</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">token</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">NamedEntityTagAnnotation</span><span class="o">.</span><span class="k">class</span><span class="p">);</span><span class="w">       </span>
<span class="w">  </span><span class="p">}</span>

<span class="p">}</span>
</pre></div>

<p>Source - http://nlp.stanford.edu/software/corenlp.shtml (half way down)</p>
<p>And if you're only looking for sentences, you can drop the later steps like
"parse" and "dcoref" from the pipeline initialization, it'll save you some
load and processing time. Rock and roll. ~K</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/object-oriented-bayesian-spam-filtering/" class="u-url">Object Oriented Bayesian Spam Filtering?</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="posts/object-oriented-bayesian-spam-filtering/" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T02:41:15+08:00" itemprop="datePublished" title="2023-02-28 02:41">2023-02-28 02:41</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>I was wondering if there is any good and clean object-oriented programming
(OOP) implementation of Bayesian filtering for spam and text classification?
This is just for learning purposes.</p>
<p><br><br></p>
<h2>Answer</h2>
<p>I definitely recommend Weka which is an <em>Open Source Data Mining Software</em>
written in Java:</p>
<blockquote>
<p>Weka is a collection of machine learning algorithms for data mining tasks.
The algorithms can either be applied directly to a dataset or called from
your own Java code. Weka contains tools for data pre-processing,
classification, regression, clustering, association rules, and
visualization. It is also well-suited for developing new machine learning
schemes.</p>
</blockquote>
<p>As mentioned above, it ships with a bunch of different classifiers like SVM,
Winnow, C4.5, Naive Bayes (of course) and many more (see the API doc). Note
that a lot of classifiers are known to have <strong>much better perfomance than
Naive Bayes</strong> in the field of spam detection or text classification.</p>
<p>Furthermore Weka brings you a very powerful GUI…</p>
<p><br></p>
<h3>Suggest</h3>
<p>Check out Chapter 6 of Programming Collective Intelligence</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/how-to-cluster-similar-sentences-using-bert/" class="u-url">How to cluster similar sentences using BERT</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="posts/how-to-cluster-similar-sentences-using-bert/" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T02:40:53+08:00" itemprop="datePublished" title="2023-02-28 02:40">2023-02-28 02:40</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>For ElMo, FastText and Word2Vec, I'm averaging the word embeddings within a
sentence and using HDBSCAN/KMeans clustering to group similar sentences.</p>
<p>A good example of the implementation can be seen in this short article:
http://ai.intelligentonlinetools.com/ml/text-clustering-word-embedding-
machine-learning/</p>
<p>I would like to do the same thing using BERT (using the BERT python package
from hugging face), however I am rather unfamiliar with how to extract the raw
word/sentence vectors in order to input them into a clustering algorithm. I
know that BERT can output sentence representations - so how would I actually
extract the raw vectors from a sentence?</p>
<p>Any information would be helpful.</p>
<p><br><br></p>
<h2>Answer</h2>
<p>As Subham Kumar mentioned, one can use this Python 3 library to compute
sentence similarity: https://github.com/UKPLab/sentence-transformers</p>
<p>The library has a few code examples to perform clustering:</p>
<p><code>fast_clustering.py</code>:</p>
<div class="code"><pre class="code literal-block"><span class="sd">"""</span>
<span class="sd">This is a more complex example on performing clustering on large scale dataset.</span>

<span class="sd">This examples find in a large set of sentences local communities, i.e., groups of sentences that are highly</span>
<span class="sd">similar. You can freely configure the threshold what is considered as similar. A high threshold will</span>
<span class="sd">only find extremely similar sentences, a lower threshold will find more sentence that are less similar.</span>

<span class="sd">A second parameter is 'min_community_size': Only communities with at least a certain number of sentences will be returned.</span>

<span class="sd">The method for finding the communities is extremely fast, for clustering 50k sentences it requires only 5 seconds (plus embedding comuptation).</span>

<span class="sd">In this example, we download a large set of questions from Quora and then find similar questions in this set.</span>
<span class="sd">"""</span>
<span class="kn">from</span> <span class="nn">sentence_transformers</span> <span class="kn">import</span> <span class="n">SentenceTransformer</span><span class="p">,</span> <span class="n">util</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">csv</span>
<span class="kn">import</span> <span class="nn">time</span>


<span class="c1"># Model for computing sentence embeddings. We use one trained for similar questions detection</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="s1">'paraphrase-MiniLM-L6-v2'</span><span class="p">)</span>

<span class="c1"># We donwload the Quora Duplicate Questions Dataset (https://www.quora.com/q/quoradata/First-Quora-Dataset-Release-Question-Pairs)</span>
<span class="c1"># and find similar question in it</span>
<span class="n">url</span> <span class="o">=</span> <span class="s2">"http://qim.fs.quoracdn.net/quora_duplicate_questions.tsv"</span>
<span class="n">dataset_path</span> <span class="o">=</span> <span class="s2">"quora_duplicate_questions.tsv"</span>
<span class="n">max_corpus_size</span> <span class="o">=</span> <span class="mi">50000</span> <span class="c1"># We limit our corpus to only the first 50k questions</span>


<span class="c1"># Check if the dataset exists. If not, download and extract</span>
<span class="c1"># Download dataset if needed</span>
<span class="k">if</span> <span class="ow">not</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">exists</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Download dataset"</span><span class="p">)</span>
    <span class="n">util</span><span class="o">.</span><span class="n">http_get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">dataset_path</span><span class="p">)</span>

<span class="c1"># Get all unique sentences from the file</span>
<span class="n">corpus_sentences</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">dataset_path</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s1">'utf8'</span><span class="p">)</span> <span class="k">as</span> <span class="n">fIn</span><span class="p">:</span>
    <span class="n">reader</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictReader</span><span class="p">(</span><span class="n">fIn</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s1">'</span><span class="se">\t</span><span class="s1">'</span><span class="p">,</span> <span class="n">quoting</span><span class="o">=</span><span class="n">csv</span><span class="o">.</span><span class="n">QUOTE_MINIMAL</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">reader</span><span class="p">:</span>
        <span class="n">corpus_sentences</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">'question1'</span><span class="p">])</span>
        <span class="n">corpus_sentences</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s1">'question2'</span><span class="p">])</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">corpus_sentences</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">max_corpus_size</span><span class="p">:</span>
            <span class="k">break</span>

<span class="n">corpus_sentences</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">corpus_sentences</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Encode the corpus. This might take a while"</span><span class="p">)</span>
<span class="n">corpus_embeddings</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">corpus_sentences</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">show_progress_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">convert_to_tensor</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>


<span class="nb">print</span><span class="p">(</span><span class="s2">"Start clustering"</span><span class="p">)</span>
<span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

<span class="c1">#Two parameters to tune:</span>
<span class="c1">#min_cluster_size: Only consider cluster that have at least 25 elements</span>
<span class="c1">#threshold: Consider sentence pairs with a cosine-similarity larger than threshold as similar</span>
<span class="n">clusters</span> <span class="o">=</span> <span class="n">util</span><span class="o">.</span><span class="n">community_detection</span><span class="p">(</span><span class="n">corpus_embeddings</span><span class="p">,</span> <span class="n">min_community_size</span><span class="o">=</span><span class="mi">25</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">"Clustering done after </span><span class="si">{:.2f}</span><span class="s2"> sec"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">))</span>

<span class="c1">#Print for all clusters the top 3 and bottom 3 elements</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">cluster</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">clusters</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\n</span><span class="s2">Cluster </span><span class="si">{}</span><span class="s2">, #</span><span class="si">{}</span><span class="s2"> Elements "</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">cluster</span><span class="p">)))</span>
    <span class="k">for</span> <span class="n">sentence_id</span> <span class="ow">in</span> <span class="n">cluster</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">3</span><span class="p">]:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\t</span><span class="s2">"</span><span class="p">,</span> <span class="n">corpus_sentences</span><span class="p">[</span><span class="n">sentence_id</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\t</span><span class="s2">"</span><span class="p">,</span> <span class="s2">"..."</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">sentence_id</span> <span class="ow">in</span> <span class="n">cluster</span><span class="p">[</span><span class="o">-</span><span class="mi">3</span><span class="p">:]:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"</span><span class="se">\t</span><span class="s2">"</span><span class="p">,</span> <span class="n">corpus_sentences</span><span class="p">[</span><span class="n">sentence_id</span><span class="p">])</span>
</pre></div>

<p><code>kmeans.py</code>:</p>
<div class="code"><pre class="code literal-block"><span class="sd">"""</span>
<span class="sd">This is a simple application for sentence embeddings: clustering</span>

<span class="sd">Sentences are mapped to sentence embeddings and then k-mean clustering is applied.</span>
<span class="sd">"""</span>
<span class="kn">from</span> <span class="nn">sentence_transformers</span> <span class="kn">import</span> <span class="n">SentenceTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">KMeans</span>

<span class="n">embedder</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="s1">'paraphrase-MiniLM-L6-v2'</span><span class="p">)</span>

<span class="c1"># Corpus with example sentences</span>
<span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'A man is eating food.'</span><span class="p">,</span>
          <span class="s1">'A man is eating a piece of bread.'</span><span class="p">,</span>
          <span class="s1">'A man is eating pasta.'</span><span class="p">,</span>
          <span class="s1">'The girl is carrying a baby.'</span><span class="p">,</span>
          <span class="s1">'The baby is carried by the woman'</span><span class="p">,</span>
          <span class="s1">'A man is riding a horse.'</span><span class="p">,</span>
          <span class="s1">'A man is riding a white horse on an enclosed ground.'</span><span class="p">,</span>
          <span class="s1">'A monkey is playing drums.'</span><span class="p">,</span>
          <span class="s1">'Someone in a gorilla costume is playing a set of drums.'</span><span class="p">,</span>
          <span class="s1">'A cheetah is running behind its prey.'</span><span class="p">,</span>
          <span class="s1">'A cheetah chases prey on across a field.'</span>
          <span class="p">]</span>
<span class="n">corpus_embeddings</span> <span class="o">=</span> <span class="n">embedder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>

<span class="c1"># Perform kmean clustering</span>
<span class="n">num_clusters</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">clustering_model</span> <span class="o">=</span> <span class="n">KMeans</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="n">num_clusters</span><span class="p">)</span>
<span class="n">clustering_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">corpus_embeddings</span><span class="p">)</span>
<span class="n">cluster_assignment</span> <span class="o">=</span> <span class="n">clustering_model</span><span class="o">.</span><span class="n">labels_</span>

<span class="n">clustered_sentences</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_clusters</span><span class="p">)]</span>
<span class="k">for</span> <span class="n">sentence_id</span><span class="p">,</span> <span class="n">cluster_id</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cluster_assignment</span><span class="p">):</span>
    <span class="n">clustered_sentences</span><span class="p">[</span><span class="n">cluster_id</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">corpus</span><span class="p">[</span><span class="n">sentence_id</span><span class="p">])</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">cluster</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">clustered_sentences</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Cluster "</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">cluster</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">""</span><span class="p">)</span>
</pre></div>

<p><code>agglomerative.py</code>:</p>
<div class="code"><pre class="code literal-block"><span class="sd">"""</span>
<span class="sd">This is a simple application for sentence embeddings: clustering</span>

<span class="sd">Sentences are mapped to sentence embeddings and then agglomerative clustering with a threshold is applied.</span>
<span class="sd">"""</span>
<span class="kn">from</span> <span class="nn">sentence_transformers</span> <span class="kn">import</span> <span class="n">SentenceTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.cluster</span> <span class="kn">import</span> <span class="n">AgglomerativeClustering</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">embedder</span> <span class="o">=</span> <span class="n">SentenceTransformer</span><span class="p">(</span><span class="s1">'paraphrase-MiniLM-L6-v2'</span><span class="p">)</span>

<span class="c1"># Corpus with example sentences</span>
<span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'A man is eating food.'</span><span class="p">,</span>
          <span class="s1">'A man is eating a piece of bread.'</span><span class="p">,</span>
          <span class="s1">'A man is eating pasta.'</span><span class="p">,</span>
          <span class="s1">'The girl is carrying a baby.'</span><span class="p">,</span>
          <span class="s1">'The baby is carried by the woman'</span><span class="p">,</span>
          <span class="s1">'A man is riding a horse.'</span><span class="p">,</span>
          <span class="s1">'A man is riding a white horse on an enclosed ground.'</span><span class="p">,</span>
          <span class="s1">'A monkey is playing drums.'</span><span class="p">,</span>
          <span class="s1">'Someone in a gorilla costume is playing a set of drums.'</span><span class="p">,</span>
          <span class="s1">'A cheetah is running behind its prey.'</span><span class="p">,</span>
          <span class="s1">'A cheetah chases prey on across a field.'</span>
          <span class="p">]</span>
<span class="n">corpus_embeddings</span> <span class="o">=</span> <span class="n">embedder</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>

<span class="c1"># Normalize the embeddings to unit length</span>
<span class="n">corpus_embeddings</span> <span class="o">=</span> <span class="n">corpus_embeddings</span> <span class="o">/</span>  <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">corpus_embeddings</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Perform kmean clustering</span>
<span class="n">clustering_model</span> <span class="o">=</span> <span class="n">AgglomerativeClustering</span><span class="p">(</span><span class="n">n_clusters</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">distance_threshold</span><span class="o">=</span><span class="mf">1.5</span><span class="p">)</span> <span class="c1">#, affinity='cosine', linkage='average', distance_threshold=0.4)</span>
<span class="n">clustering_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">corpus_embeddings</span><span class="p">)</span>
<span class="n">cluster_assignment</span> <span class="o">=</span> <span class="n">clustering_model</span><span class="o">.</span><span class="n">labels_</span>

<span class="n">clustered_sentences</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">sentence_id</span><span class="p">,</span> <span class="n">cluster_id</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cluster_assignment</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">cluster_id</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">clustered_sentences</span><span class="p">:</span>
        <span class="n">clustered_sentences</span><span class="p">[</span><span class="n">cluster_id</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">clustered_sentences</span><span class="p">[</span><span class="n">cluster_id</span><span class="p">]</span><span class="o">.</span><span class="kp">append</span><span class="p">(</span><span class="n">corpus</span><span class="p">[</span><span class="n">sentence_id</span><span class="p">])</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">cluster</span> <span class="ow">in</span> <span class="n">clustered_sentences</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Cluster "</span><span class="p">,</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">cluster</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">""</span><span class="p">)</span>
</pre></div>

<p><br></p>
<h3>Suggest</h3>
<p>You will need to generate bert embeddidngs for the sentences first. bert-as-
service provides a very easy way to generate embeddings for sentences.</p>
<p>This is how you can geberate bert vectors for a list of sentences you need to
cluster. It is explained very well in the bert-as-service repository:
https://github.com/hanxiao/bert-as-service</p>
<p>Installations:</p>
<div class="code"><pre class="code literal-block">pip install bert-serving-server  # server
pip install bert-serving-client  # client, independent of `bert-serving-server`
</pre></div>

<p>Download one of the pre-trained models available at https://github.com/google-
research/bert</p>
<p>Start the service:</p>
<div class="code"><pre class="code literal-block">bert-serving-start -model_dir /your_model_directory/ -num_worker=4
</pre></div>

<p>Generate the vectors for the list of sentences:</p>
<div class="code"><pre class="code literal-block"><span class="kn">from</span> <span class="nn">bert_serving.client</span> <span class="kn">import</span> <span class="n">BertClient</span>
<span class="n">bc</span> <span class="o">=</span> <span class="n">BertClient</span><span class="p">()</span>
<span class="n">vectors</span><span class="o">=</span><span class="n">bc</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">your_list_of_sentences</span><span class="p">)</span>
</pre></div>

<p>This would give you a list of vectors, you could write them into a csv and use
any clustering algorithm as the sentences are reduced to numbers.</p>
    </div>
    </article>
</div>

        <nav class="postindexpager"><ul class="pager">
<li class="previous">
                <a href="index-1375.html" rel="prev">Newer posts</a>
            </li>
            <li class="next">
                <a href="index-1373.html" rel="next">Older posts</a>
            </li>
        </ul></nav>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2023         Go to StackOverflow Chinese Site  <a href="http://stackoverflow.ink">StackOverflow-ZH</a>  
            
        </footer>
</div>
</div>


            <script src="assets/js/all-nocdn.js"></script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script><script src="assets/js/search.js"></script>
</body>
</html>
