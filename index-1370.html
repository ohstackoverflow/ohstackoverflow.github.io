<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="This is a snapshot site for StackOverflow">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>StackOverflow Snapshot (old posts, page 1370) | StackOverflow Snapshot</title>
<link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="canonical" href="https://ohstackoverflow.netlify.app/index-1370.html">
<link rel="prev" href="index-1371.html" type="text/html">
<link rel="next" href="index-1369.html" type="text/html">
<!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]-->
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://ohstackoverflow.netlify.app/">

                <span id="blog-title">StackOverflow Snapshot</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="archive.html">Archive</a>
                </li>
<li>
<a href="categories/">Tags</a>

                
            </li>
</ul>
<ul class="nav navbar-nav navbar-right">
<div style="display:table;min-height:5rem;min-width:27rem;">
					<div class="input-group" style="display: table-cell;vertical-align: middle;">
						<input id="words" type="text" class="form-control" style="max-width:22rem;" onkeydown="if(event.keyCode==13){btn.click()}"><span class="input-group-btn" style="float:left">
							<button id="btn" class="btn btn-default" type="button" data-toggle="modal" data-target="#myModal">
								<span class="glyphicon glyphicon-search">
							</span></button>
						</span>
					</div>
<!-- /input-group -->
				</div>

				
                
                
                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><!-- 模态框（Modal） --><div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true">
	<div class="modal-dialog">
		<div class="modal-content">
			<div class="modal-header">
				<button type="button" class="close" data-dismiss="modal" aria-hidden="true">×
				</button>
				<h4 class="modal-title" id="myModalLabel">
					查找结果
				</h4>
			</div>
			<div class="modal-body">
				<div id="search-count" style="min-height:4rem;">
				查找中，请稍后...
				</div>
				<div id="search-result">
				</div>

				
			</div>
			<div class="modal-footer">
				<button type="button" class="btn btn-default" data-dismiss="modal">
					关闭
				</button>
			</div>
		</div>
<!-- /.modal-content -->
	</div>
<!-- /.modal-dialog -->
</div>
<!-- /.modal -->

<div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            

    


    
<div class="postindex">
    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/how-to-program-a-neural-network-for-chess/" class="u-url">How to program a neural network for chess?</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="posts/how-to-program-a-neural-network-for-chess/" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T02:40:31+08:00" itemprop="datePublished" title="2023-02-28 02:40">2023-02-28 02:40</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>I want to program a chess engine which learns to make good moves and win
against other players. I've already coded a representation of the chess board
and a function which outputs all possible moves. So I only need an evaluation
function which says how good a given situation of the board is. Therefore, I
would like to use an artificial neural network which should then evaluate a
given position. The output should be a numerical value. The higher the value
is, the better is the position for the white player.</p>
<p>My approach is to build a network of 385 neurons: There are six unique chess
pieces and 64 fields on the board. So for every field we take 6 neurons (1 for
every piece). If there is a white piece, the input value is 1. If there is a
black piece, the value is -1. And if there is no piece of that sort on that
field, the value is 0. In addition to that there should be 1 neuron for the
player to move. If it is White's turn, the input value is 1 and if it's
Black's turn, the value is -1.</p>
<p>I think that configuration of the neural network is quite good. But the main
part is missing: How can I implement this neural network into a coding
language (e.g. Delphi)? I think the weights for each neuron should be the same
in the beginning. Depending on the result of a match, the weights should then
be adjusted. But how? I think I should let 2 computer players (both using my
engine) play against each other. If White wins, Black gets the feedback that
its weights aren't good.</p>
<p>So it would be great if you could help me implementing the neural network into
a coding language (best would be Delphi, otherwise pseudo-code). Thanks in
advance!</p>
<p><br><br></p>
<h2>Answer</h2>
<p>Been there, done that. Since there is no continuity in your problem (the value
of a position is not closely related to an other position with only 1 change
in the value of one input), there is very little chance a NN would work. And
it never did in my experiments.</p>
<p>I would rather see a simulated annealing system with an ad-hoc heuristic (of
which there are plenty out there) to evaluate the value of the position...</p>
<p>However, if you are set on using a NN, is is relatively easy to represent. A
general NN is simply a graph, with each node being a neuron. Each neuron has a
current activation value, and a transition formula to compute the next
activation value, based on input values, i.e. activation values of all the
nodes that have a link to it.</p>
<p>A more classical NN, that is with an input layer, an output layer, identical
neurons for each layer, and no time-dependency, can thus be represented by an
array of input nodes, an array of output nodes, and a linked graph of nodes
connecting those. Each node possesses a current activation value, and a list
of nodes it forwards to. Computing the output value is simply setting the
activations of the input neurons to the input values, and iterating through
each subsequent layer in turn, computing the activation values from the
previous layer using the transition formula. When you have reached the last
(output) layer, you have your result.</p>
<p><br></p>
<h3>Suggest</h3>
<p>I don't see why you can't have a neural net for a static evaluator if you also
do some classic mini-max lookahead with alpha-beta pruning. Lots of Chess
engines use minimax with a braindead static evaluator that just adds up the
pieces or something; it doesn't matter so much if you have enough levels of
minimax. I don't know how much of an improvement the net would make but
there's little to lose. Training it would be tricky though. I'd suggest using
an engine that looks ahead many moves (and takes loads of CPU etc) to train
the evaluator for an engine that looks ahead fewer moves. That way you end up
with an engine that doesn't take as much CPU (hopefully).</p>
<p>Edit: I wrote the above in 2010, and now in 2020 Stockfish NNUE has done it.
"The network is optimized and trained on the [classical Stockfish] evaluations
of millions of positions at moderate search depth" and then used as a static
evaluator, and in their initial tests they got an 80-elo improvement when
using this static evaluator instead of their previous one (or, equivalently,
the same elo with a little less CPU time). So yes it does work, and you don't
even have to train the network at high search depth as I originally suggested:
moderate search depth is enough, but the key is to use many millions of
positions.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/convolutional-neural-networks-multiple-channels/" class="u-url">Convolutional Neural Networks - Multiple Channels</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="posts/convolutional-neural-networks-multiple-channels/" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T02:40:10+08:00" itemprop="datePublished" title="2023-02-28 02:40">2023-02-28 02:40</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>How is the convolution operation carried out when multiple channels are
present at the input layer? (e.g. RGB)</p>
<p>After doing some reading on the architecture/implementation of a CNN I
understand that each neuron in a feature map references NxM pixels of an image
as defined by the kernel size. Each pixel is then factored by the feature maps
learned NxM weight set (the kernel/filter), summed, and input into an
activation function. For a simple grey scale image, I imagine the operation
would be something adhere to the following pseudo code:</p>
<div class="code"><pre class="code literal-block"><span class="k">for</span><span class="w"> </span><span class="nv">i</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">range</span><span class="ss">(</span><span class="mi">0</span>,<span class="w"> </span><span class="nv">image_width</span><span class="o">-</span><span class="nv">kernel_width</span><span class="o">+</span><span class="mi">1</span><span class="ss">)</span>:
<span class="w">    </span><span class="k">for</span><span class="w"> </span><span class="nv">j</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">range</span><span class="ss">(</span><span class="mi">0</span>,<span class="w"> </span><span class="nv">image_height</span><span class="o">-</span><span class="nv">kernel_height</span><span class="o">+</span><span class="mi">1</span><span class="ss">)</span>:
<span class="w">        </span><span class="k">for</span><span class="w"> </span><span class="nv">x</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">range</span><span class="ss">(</span><span class="mi">0</span>,<span class="w"> </span><span class="nv">kernel_width</span><span class="ss">)</span>:
<span class="w">            </span><span class="k">for</span><span class="w"> </span><span class="nv">y</span><span class="w"> </span><span class="nv">in</span><span class="w"> </span><span class="nv">range</span><span class="ss">(</span><span class="mi">0</span>,<span class="w"> </span><span class="nv">kernel_height</span><span class="ss">)</span>:
<span class="w">                </span><span class="nv">sum</span><span class="w"> </span><span class="o">+=</span><span class="w"> </span><span class="nv">kernel</span>[<span class="nv">x</span>,<span class="nv">y</span>]<span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nv">image</span>[<span class="nv">i</span><span class="o">+</span><span class="nv">x</span>,<span class="nv">j</span><span class="o">+</span><span class="nv">y</span>]

<span class="w">        </span><span class="nv">feature_map</span>[<span class="nv">i</span>,<span class="nv">j</span>]<span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nv">act_func</span><span class="ss">(</span><span class="nv">sum</span><span class="ss">)</span>
<span class="w">        </span><span class="nv">sum</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="mi">0</span>.<span class="mi">0</span>
</pre></div>

<p>However I don't understand how to extend this model to handle multiple
channels. Are three separate weight sets required per feature map, shared
between each colour?</p>
<p>Referencing this tutorial's 'Shared Weights' section:
http://deeplearning.net/tutorial/lenet.html Each neuron in a feature map
references layer m-1 with colours being referenced from separate neurons. I
don't understand the relationship they are expressing here. Are the neurons
kernels or pixels and why do they reference separate parts of the image?</p>
<p>Based on my example, it would seem that a single neurons kernel is exclusive
to a particular region in an image. Why have they split the RGB component over
several regions?</p>
<p><br><br></p>
<h2>Answer</h2>
<blockquote>
<p>How is the convolution operation carried out when multiple channels are
present at the input layer? (e.g. RGB)</p>
</blockquote>
<p>In such a case you have <strong>one 2D kernel per input channel</strong> (a.k.a plane).</p>
<p>So you perform each convolution (2D Input, 2D kernel) separately and <strong>you sum
the contributions</strong> which gives the final output feature map.</p>
<p>Please refer to the slide 64 of this CVPR 2014 tutorial by Marc'Aurelio
Ranzato:</p>
<p><img alt="enter image description here" src="images/n3amu.png"></p>
<blockquote>
<p>Are three separate weight sets required per feature map, shared between each
colour?</p>
</blockquote>
<p>If you consider a given output feature map, you have 3 x 2D kernels (i.e one
kernel per input channel). Each 2D kernel shares the same weights along the
whole input channel (R, G, or B here).</p>
<p>So the whole convolutional layer is a 4D-tensor (nb. input planes x nb. output
planes x kernel width x kernel height).</p>
<blockquote>
<p>Why have they split the RGB component over several regions?</p>
</blockquote>
<p>As detailed above think of each R, G and B channel as a <strong>separate</strong> input
plane with its dedicated 2D kernel.</p>
<p><br></p>
<h3>Suggest</h3>
<p>For example, if your input image is of size W x H x C where W, H, and C
represent the length of width, height, and the size of channels. The dimension
of the filter (aka kernel) would be K x K x C where K denotes the length of
the dimension of the kernel. Using <code>max</code> to aggregate the results of different
channels fails to distinguish the nuances across channels, which is not what
we want. As illustrated in the figure below (source), the input data is of
size 6 x 6 x 3. The number of units (filters) is 2, each of which has the
dimensions 3 x 3 x 3. The output is 4 x 4 x 2. So in general channels need to
be treated <strong>separately</strong> under each filter.</p>
<p><img alt="enter image description here" src="images/rsKBz.png"></p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/locating-text-within-image/" class="u-url">Locating Text within image</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="posts/locating-text-within-image/" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T02:39:49+08:00" itemprop="datePublished" title="2023-02-28 02:39">2023-02-28 02:39</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>I am currently working on a project and my goal is to locate text in an image.
OCR'ing the text is not my intention as of yet. I want to basically obtain the
bounds of text within an image. I am using the AForge.Net imaging component
for manipulation. Any assistance in some sense or another?</p>
<p>Update 2/5/09: I've since went along another route in my project. However I
did attempt to obtain text using MODI (Microsoft Office Document Imaging). It
allows you to OCR an image and pull text from it with some ease.</p>
<p><br><br></p>
<h2>Answer</h2>
<p>This is an active area of research. There are literally oodles of academic
papers on the subject. It's going to be difficult to give you assistance
especially w/o more deatails. Are you looking for specific types of text?
Fonts? English-only? Are you familiar with the academic literature?</p>
<p>"Text detection" is a standard problem in any OCR (optical character
recognition) system and consequently there are lots of bits of code on the
interwebs that deal with it.</p>
<p>I could start listing piles of links from google but I suggest you just do a
search for "text detection" and start reading :). There is ample example code
available as well.</p>
<p><br></p>
<h3>Suggest</h3>
<p>recognizing text inside an image is indeed a hot topic for researchers in that
field, but only begun to grow out of control when captcha's became the "norm"
in terms of defense against spam bots. Why use captcha's as protection? well
because it is/was very hard to locate (and read) text inside an image!</p>
<p>The reason why I mention captcha's is because the most advancement* is made
within that tiny area, and I think that your solution could be best found
there. especially because captcha's are indeed about locating text (or
something that resembles text) inside a cluttered image and afterwards trying
to read the letters correctly.</p>
<p>so if you can find yourself a good open source captcha breaking tool you
probably have all you need to continue your quest...<br>
You could probably even throw away the most dificult code that handles the
character recognition itself, because those OCR's are used to read distorted
text, something you don't have to do.</p>
<p><em>: advancement in terms of visible, usable, and </em><em>practical</em>* information for a "non-researcher"</p>
    </div>
    </article>
</div>

        <nav class="postindexpager"><ul class="pager">
<li class="previous">
                <a href="index-1371.html" rel="prev">Newer posts</a>
            </li>
            <li class="next">
                <a href="index-1369.html" rel="next">Older posts</a>
            </li>
        </ul></nav>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2023         Go to StackOverflow Chinese Site  <a href="http://stackoverflow.ink">StackOverflow中文网</a>  
            
        </footer>
</div>
</div>


            <script src="assets/js/all-nocdn.js"></script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script><script src="assets/js/search.js"></script>
</body>
</html>
