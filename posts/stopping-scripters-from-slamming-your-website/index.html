<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Stopping scripters from slamming your website | StackOverflow Snapshot</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="canonical" href="https://ohstackoverflow.netlify.app/posts/stopping-scripters-from-slamming-your-website/">
<!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><meta name="author" content="Arya">
<link rel="prev" href="../simple-tool-to-accept-theirs-or-accept-mine-on-a-whole-file-using-git/" title="Simple tool to 'accept theirs' or 'accept mine' on a whole file using git" type="text/html">
<link rel="next" href="../how-do-i-get-the-value-of-a-textbox-using-jquery/" title="How do I get the value of a textbox using jQuery?" type="text/html">
<meta property="og:site_name" content="StackOverflow Snapshot">
<meta property="og:title" content="Stopping scripters from slamming your website">
<meta property="og:url" content="https://ohstackoverflow.netlify.app/posts/stopping-scripters-from-slamming-your-website/">
<meta property="og:description" content="I've accepted an answer, but sadly, I believe we're stuck with our original
worst case scenario: CAPTCHA everyone on purchase attempts of the crap.
Short explanation: caching / web farms make it impos">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2023-03-03T05:15:33+08:00">
<meta property="article:tag" content="bots">
<meta property="article:tag" content="detection">
<meta property="article:tag" content="e-commerce">
<meta property="article:tag" content="scripting">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://ohstackoverflow.netlify.app/">

                <span id="blog-title">StackOverflow Snapshot</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="../../archive.html">Archive</a>
                </li>
<li>
<a href="../../categories/">Tags</a>

                
            </li>
</ul>
<ul class="nav navbar-nav navbar-right">
<div style="display:table;min-height:5rem;min-width:27rem;">
					<div class="input-group" style="display: table-cell;vertical-align: middle;">
						<input id="words" type="text" class="form-control" style="max-width:22rem;" onkeydown="if(event.keyCode==13){btn.click()}"><span class="input-group-btn" style="float:left">
							<button id="btn" class="btn btn-default" type="button" data-toggle="modal" data-target="#myModal">
								<span class="glyphicon glyphicon-search">
							</span></button>
						</span>
					</div>
<!-- /input-group -->
				</div>

				
                
                
                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><!-- 模态框（Modal） --><div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true">
	<div class="modal-dialog">
		<div class="modal-content">
			<div class="modal-header">
				<button type="button" class="close" data-dismiss="modal" aria-hidden="true">×
				</button>
				<h4 class="modal-title" id="myModalLabel">
					查找结果
				</h4>
			</div>
			<div class="modal-body">
				<div id="search-count" style="min-height:4rem;">
				查找中，请稍后...
				</div>
				<div id="search-result">
				</div>

				
			</div>
			<div class="modal-footer">
				<button type="button" class="btn btn-default" data-dismiss="modal">
					关闭
				</button>
			</div>
		</div>
<!-- /.modal-content -->
	</div>
<!-- /.modal-dialog -->
</div>
<!-- /.modal -->

<div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">Stopping scripters from slamming your website</a></h1>

        <div class="metadata">
            <p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">
                    <a class="u-url" href="../../authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="." rel="bookmark">
            <time class="published dt-published" datetime="2023-03-03T05:15:33+08:00" itemprop="datePublished" title="2023-03-03 05:15">2023-03-03 05:15</time></a>
            </p>
            

        </div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <blockquote>
<p>I've accepted an answer, but sadly, I believe we're stuck with our original
worst case scenario: <strong>CAPTCHA everyone on purchase attempts of the crap</strong>.
Short explanation: caching / web farms make it impossible to track hits, and
any workaround (sending a non-cached web-beacon, writing to a unified table,
etc.) slows the site down worse than the bots would. There is likely some
pricey hardware from Cisco or the like that can help at a high level, but
it's hard to justify the cost if CAPTCHA-ing everyone is an alternative.
I'll attempt a more full explanation later, as well as cleaning this up for
future searchers (though others are welcome to try, as it's community wiki).</p>
</blockquote>
<h3>Situation</h3>
<p>This is about the bag o' crap sales on woot.com. I'm the president of Woot
Workshop, the subsidiary of Woot that does the design, writes the product
descriptions, podcasts, blog posts, and moderates the forums. I work with
CSS/HTML and am only barely familiar with other technologies. I work closely
with the developers and have talked through all of the answers here (and many
other ideas we've had).</p>
<p>Usability is a massive part of my job, and making the site exciting and fun is
most of the rest of it. That's where the three goals below derive. CAPTCHA
harms usability, and bots steal the fun and excitement out of our crap sales.</p>
<p>Bots are slamming our front page tens of times a second screen scraping
(and/or scanning our RSS) for the Random Crap sale. The moment they see that,
it triggers a second stage of the program that logs in, clicks I want One,
fills out the form, and buys the crap.</p>
<h3>Evaluation</h3>
<blockquote>
<p>lc: On stackoverflow and other sites that use this method, they're almost
always dealing with authenticated (logged in) users, because the task being
attempted requires that.</p>
</blockquote>
<p>On Woot, anonymous (non-logged) users can view our home page. In other words,
the slamming bots can be non-authenticated (and essentially non-trackable
except by IP address).</p>
<p>So we're back to scanning for IPs, which a) is fairly useless in this age of
cloud networking and spambot zombies and b) catches too many innocents given
the number of businesses that come from one IP address (not to mention the
issues with non-static IP ISPs and potential performance hits to trying to
track this).</p>
<p>Oh, and having people call us would be the worst possible scenario. Can we
have them call you?</p>
<blockquote>
<p>BradC: Ned Batchelder's methods look pretty cool, but they're pretty firmly
designed to defeat bots built for a network of sites. Our problem is bots
are built specifically to defeat our site. Some of these methods could
likely work for a short time until the scripters evolved their bots to
ignore the honeypot, screen-scrape for nearby label names instead of form
ids, and use a javascript-capable browser control.</p>
<p>lc again: "Unless, of course, the hype is part of your marketing scheme."
Yes, it definitely is. The surprise of when the item appears, as well as the
excitement if you manage to get one is probably as much or more important
than the crap you actually end up getting. Anything that eliminates first-
come/first-serve is detrimental to the thrill of 'winning' the crap.</p>
<p>novatrust: And I, for one, welcome our new bot overlords. We actually do
offer RSSfeeds to allow 3rd party apps to scan our site for product info,
but not ahead of the main site HTML. If I'm interpreting it right, your
solution does help goal 2 (performance issues) by completely sacrificing
goal 1, and just resigning the fact that bots will be buying most of the
crap. I up-voted your response, because your last paragraph pessimism feels
accurate to me. There seems to be no silver bullet here.</p>
</blockquote>
<p>The rest of the responses generally rely on IP tracking, which, again, seems
to both be useless (with botnets/zombies/cloud networking) and detrimental
(catching many innocents who come from same-IP destinations).</p>
<p>Any other approaches / ideas? My developers keep saying "let's just do
CAPTCHA" but I'm hoping there's less intrusive methods to all actual humans
wanting some of our crap.</p>
<h3>Original question</h3>
<p>Say you're selling something cheap that has a very high perceived value, and
you have a very limited amount. No one knows exactly when you will sell this
item. And over a million people regularly come by to see what you're selling.</p>
<p>You end up with scripters and bots attempting to programmatically [a] figure
out when you're selling said item, and [b] make sure they're among the first
to buy it. This sucks for two reasons:</p>
<ol>
<li>Your site is slammed by non-humans, slowing everything down for everyone.</li>
<li>The scripters end up 'winning' the product, causing the regulars to feel cheated.</li>
</ol>
<p>A seemingly obvious solution is to create some hoops for your users to jump
through before placing their order, but there are at least three problems with
this:</p>
<ul>
<li>The user experience sucks for humans, as they have to decipher CAPTCHA, pick out the cat, or solve a math problem.</li>
<li>If the perceived benefit is high enough, and the crowd large enough, some group will find their way around any tweak, leading to an arms race. (This is especially true the simpler the tweak is; hidden 'comments' form, re-arranging the form elements, mis-labeling them, hidden 'gotcha' text all will work once and then need to be changed to fight targeting this specific form.)</li>
<li>Even if the scripters can't 'solve' your tweak it doesn't prevent them from slamming your front page, and then sounding an alarm for the scripter to fill out the order, manually. Given they get the advantage from solving [a], they will likely still win [b] since they'll be the first humans reaching the order page. Additionally, 1. still happens, causing server errors and a decreased performance for everyone.</li>
</ul>
<p>Another solution is to watch for IPs hitting too often, block them from the
firewall, or otherwise prevent them from ordering. This could solve 2. and
prevent [b] but the performance hit from scanning for IPs is massive and would
likely cause more problems like 1. than the scripters were causing on their
own. Additionally, the possibility of cloud networking and spambot zombies
makes IP checking fairly useless.</p>
<p>A third idea, forcing the order form to be loaded for some time (say, half a
second) would potentially slow the progress of the speedy orders, but again,
the scripters would still be the first people in, at any speed not detrimental
to actual users.</p>
<h3>Goals</h3>
<ol>
<li>Sell the item to non-scripting humans.</li>
<li>Keep the site running at a speed not slowed by bots.</li>
<li>Don't hassle the 'normal' users with any tasks to complete to prove they're human.</li>
</ol>
<p><br><br></p>
<h2>Answer</h2>
<p>How about implementing something like SO does with the CAPTCHAs?</p>
<p>If you're using the site normally, you'll probably never see one. If you
happen to reload the same page too often, post successive comments too
quickly, or something else that triggers an alarm, make them prove they're
human. In your case, this would probably be constant reloads of the same page,
following every link on a page quickly, or filling in an order form too fast
to be human.</p>
<p>If they fail the check x times in a row (say, 2 or 3), give that IP a timeout
or other such measure. Then at the end of the timeout, dump them back to the
check again.</p>
<hr>
<p>Since you have unregistered users accessing the site, you do have only IPs to
go on. You can issue sessions to each browser and track that way if you wish.
And, of course, throw up a human-check if too many sessions are being
(re-)created in succession (in case a bot keeps deleting the cookie).</p>
<p>As far as catching too many innocents, you can put up a disclaimer on the
human-check page: "This page may also appear if too many anonymous users are
viewing our site from the same location. We encourage you to register or login
to avoid this." (Adjust the wording appropriately.)</p>
<p>Besides, what are the odds that X people are loading the same page(s) at the
same time from one IP? If they're high, maybe you need a different trigger
mechanism for your bot alarm.</p>
<hr>
<p>Edit: Another option is if they fail too many times, and you're confident
about the product's demand, to block them and make them personally CALL you to
remove the block.</p>
<p>Having people call does seem like an asinine measure, but it <em>makes sure
there's a human somewhere behind the computer</em>. The key is to have the block
only be in place for a condition which should almost never happen unless it's
a bot (e.g. fail the check multiple times in a row). Then it FORCES human
interaction - to pick up the phone.</p>
<p>In response to the comment of having them call me, there's obviously that
tradeoff here. Are you worried enough about ensuring your users are human to
accept a couple phone calls when they go on sale? If I were so concerned about
a product getting to human users, I'd have to make this decision, perhaps
sacrificing a (small) bit of my time in the process.</p>
<p>Since it seems like you're determined to not let bots get the upper hand/slam
your site, I believe the phone may be a good option. Since I don't make a
profit off your product, I have no interest in receiving these calls. Were you
to share some of that profit, however, I may become interested. As this is
your product, you have to decide how much you care and implement accordingly.</p>
<hr>
<p>The other ways of releasing the block just aren't as effective: a timeout (but
they'd get to slam your site again after, rinse-repeat), a long timeout (if it
was really a human trying to buy your product, they'd be SOL and punished for
failing the check), email (easily done by bots), fax (same), or snail mail
(takes too long).</p>
<p>You could, of course, instead have the timeout period increase per IP for each
time they get a timeout. Just make sure you're not punishing true humans
inadvertently.</p>
<p><br></p>
<h3>Suggest</h3>
<p>You need to figure a way to make the bots buy stuff that is massively
overpriced: 12mm wingnut: $20. See how many bots snap up before the script-
writers decide you're gaming them.</p>
<p>Use the profits to buy more servers and pay for bandwidth.</p>
    </div>
    <aside class="postpromonav"><nav><ul itemprop="keywords" class="tags">
<li><a class="tag p-category" href="../../categories/bots/" rel="tag">bots</a></li>
            <li><a class="tag p-category" href="../../categories/detection/" rel="tag">detection</a></li>
            <li><a class="tag p-category" href="../../categories/e-commerce/" rel="tag">e-commerce</a></li>
            <li><a class="tag p-category" href="../../categories/scripting/" rel="tag">scripting</a></li>
        </ul>
<ul class="pager hidden-print">
<li class="previous">
                <a href="../simple-tool-to-accept-theirs-or-accept-mine-on-a-whole-file-using-git/" rel="prev" title="Simple tool to 'accept theirs' or 'accept mine' on a whole file using git">Previous post</a>
            </li>
            <li class="next">
                <a href="../how-do-i-get-the-value-of-a-textbox-using-jquery/" rel="next" title="How do I get the value of a textbox using jQuery?">Next post</a>
            </li>
        </ul></nav></aside></article>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2023         Go to StackOverflow Chinese Site  <a href="http://stackoverflow.ink">StackOverflow中文网</a>  
            
        </footer>
</div>
</div>


            <script src="../../assets/js/all-nocdn.js"></script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script><script src="../../assets/js/search.js"></script>
</body>
</html>
