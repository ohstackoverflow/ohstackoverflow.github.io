<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>What are the uses of recurrent neural networks when using them with Reinforcement Learning? | StackOverflow Snapshot</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="canonical" href="https://ohstackoverflow.netlify.app/posts/what-are-the-uses-of-recurrent-neural-networks-when-using-them-with-reinforcement-learning/">
<!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><meta name="author" content="Arya">
<link rel="prev" href="../how-does-a-back-propagation-training-algorithm-work/" title="How does a back-propagation training algorithm work?" type="text/html">
<link rel="next" href="../structured-factored-and-atomic-representation/" title="Structured, factored and atomic representation?" type="text/html">
<meta property="og:site_name" content="StackOverflow Snapshot">
<meta property="og:title" content="What are the uses of recurrent neural networks when using them with Re">
<meta property="og:url" content="https://ohstackoverflow.netlify.app/posts/what-are-the-uses-of-recurrent-neural-networks-when-using-them-with-reinforcement-learning/">
<meta property="og:description" content="I do know that feedforward multi-layer neural networks with backprop are used
with Reinforcement Learning as to help it generalize the actions our agent
does. This is, if we have a big state space, we">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2023-02-28T03:29:34+08:00">
<meta property="article:tag" content="artificial-intelligence">
<meta property="article:tag" content="language-agnostic">
<meta property="article:tag" content="neural-network">
<meta property="article:tag" content="reinforcement-learning">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://ohstackoverflow.netlify.app/">

                <span id="blog-title">StackOverflow Snapshot</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="../../archive.html">Archive</a>
                </li>
<li>
<a href="../../categories/">Tags</a>

                
            </li>
</ul>
<ul class="nav navbar-nav navbar-right">
<div style="display:table;min-height:5rem;min-width:27rem;">
					<div class="input-group" style="display: table-cell;vertical-align: middle;">
						<input id="words" type="text" class="form-control" style="max-width:22rem;" onkeydown="if(event.keyCode==13){btn.click()}"><span class="input-group-btn" style="float:left">
							<button id="btn" class="btn btn-default" type="button" data-toggle="modal" data-target="#myModal">
								<span class="glyphicon glyphicon-search">
							</span></button>
						</span>
					</div>
<!-- /input-group -->
				</div>

				
                
                
                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><!-- 模态框（Modal） --><div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true">
	<div class="modal-dialog">
		<div class="modal-content">
			<div class="modal-header">
				<button type="button" class="close" data-dismiss="modal" aria-hidden="true">×
				</button>
				<h4 class="modal-title" id="myModalLabel">
					查找结果
				</h4>
			</div>
			<div class="modal-body">
				<div id="search-count" style="min-height:4rem;">
				查找中，请稍后...
				</div>
				<div id="search-result">
				</div>

				
			</div>
			<div class="modal-footer">
				<button type="button" class="btn btn-default" data-dismiss="modal">
					关闭
				</button>
			</div>
		</div>
<!-- /.modal-content -->
	</div>
<!-- /.modal-dialog -->
</div>
<!-- /.modal -->

<div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">What are the uses of recurrent neural networks when using them with Reinforcement Learning?</a></h1>

        <div class="metadata">
            <p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">
                    <a class="u-url" href="../../authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="." rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T03:29:34+08:00" itemprop="datePublished" title="2023-02-28 03:29">2023-02-28 03:29</time></a>
            </p>
            

        </div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <p>I do know that feedforward multi-layer neural networks with backprop are used
with Reinforcement Learning as to help it generalize the actions our agent
does. This is, if we have a big state space, we can do some actions, and they
will help generalize over the whole state space.</p>
<p>What do recurrent neural networks do, instead? To what tasks are they used
for, in general?</p>
<p><br><br></p>
<h2>Answer</h2>
<p>Recurrent Neural Networks, RNN for short (although beware that <em>RNN</em> is often
used in the literature to designate <em>Random Neural Networks</em> , which
effectively are a special case of Recurrent NN), come in very different
"flavors" which causes them to exhibit various behaviors and characteristics.
In general, however these many shades of behaviors and characteristics are
<strong>rooted in the availability of [feedback] input to individual neurons</strong>. Such
feedback comes from other parts of the network, be it local or distant, from
the same layer (including in some cases "self"), or even on different layers
(*). Feedback information it treated as "normal" input the neuron and can then
influence, at least in part, its output.</p>
<p>Unlike <strong>back propagation</strong> which is used <em>during the learning phase</em> of a
Feed-forward Network for the purpose of fine-tuning the relative weights of
the various [Feedfoward-only] connections, FeedBack in RNNs constitute true a
input to the neurons they connect to.</p>
<p>One of the uses of feedback is <strong>to make the network more resilient to noise
and other imperfections in the input</strong> (i.e. <em>input</em> to the network as a
whole). The reason for this is that in addition to inputs "directly"
pertaining to the network input (the types of input that would have been
present in a Feedforward Network), neurons have the information about what
other neurons are "thinking". This extra info then leads to <strong>Hebbian
learning</strong> , i.e. the idea that neurons that [usually] fire together should
"encourage" each other to fire. In practical terms this extra input from
"like-firing" neighbor neurons (or no-so neighbors) may prompt a neuron to
fire even though its non-feedback inputs may have been such that it would have
not fired (or fired less strongly, depending on type of network).</p>
<p>An example of this resilience to input imperfections is with <strong>associative
memory</strong> , a common employ of RNNs. The idea is to use the feeback info to
"fill-in the blanks".</p>
<p>Another related but distinct use of feedback is with <strong>inhibitory signals</strong> ,
whereby a given neuron may learn that while all its other inputs would prompt
it to fire, a particular feedback input from some other part of the network
typically indicative that somehow the other inputs are not to be trusted (in
this particular context).</p>
<p>Another extremely important use of feedback, is that in some architectures it
can <strong>introduce a temporal element to the system</strong>. A particular [feedback]
input may not so much instruct the neuron of what it "thinks" [now], but
instead "remind" the neuron that say, two cycles ago (whatever cycles may
represent), the network's state (or one of its a sub-states) was "X". Such
ability to "remember" the [typically] recent past is another factor of
resilience to noise in the input, but its main interest may be in introducing
"prediction" into the learning process. These time-delayed input may be seen
as predictions from other parts of the network: "I've heard footsteps in the
hallway, expect to hear the door bell [or keys shuffling]".</p>
<p>(<em>) BTW such a broad freedom in the "rules" that dictate the allowed
connections, whether feedback or feed-forward, explains </em><em>why there are so
many different RNN architectures</em>* and variations thereof). Another reason for
these many different architectures is that one of the characteristics of RNN
is that they are not readily as tractable, mathematically or otherwise,
compared with the feed-forward model. As a result, driven by mathematical
insight or plain trial-and-error approach, many different possibilities are
being tried.</p>
<p>This is not to say that feedback network are total black boxes, in fact some
of the RNNs such as the <strong>Hopfield Networks</strong> are rather well understood. It's
just that the math is typically more complicated (at least to me ;-) )</p>
<p>I think the above, generally (too generally!), addresses <em>devoured elysium</em> 's
(the OP) questions of " <em>what do RNN do instead</em> ", and the " <em>general tasks
they are used for</em> ". To many complement this information, here's an
incomplete and informal survey of applications of RNNs. The difficulties in
gathering such a list are multiple:</p>
<ul>
<li>the overlap of applications between Feed-forward Networks and RNNs (as a result this hides the specificity of RNNs)</li>
<li>the often highly specialized nature of applications (we either stay in with too borad concepts such as "classification" or we dive into "Prediction of Carbon shifts in series of saturated benzenes" ;-) )</li>
<li>the hype often associated with neural networks, when described in vulgarization texts</li>
</ul>
<p>Anyway, here's the list</p>
<ul>
<li>modeling, in particular the learning of [oft' non-linear] dynamic systems</li>
<li>Classification (now, FF Net are also used for that...)</li>
<li>Combinatorial optimization</li>
</ul>
<p>Also there are a lots of applications associated with the temporal dimension
of the RNNs (another area where FF networks would typically not be found)</p>
<ul>
<li>Motion detection </li>
<li>load forecasting (as with utilities or services: predicting the load in the short term)</li>
<li>signal processing : filtering and control</li>
</ul>
<p><br></p>
<h3>Suggest</h3>
<p>There is an assumption in the basic Reinforcement Learning framework that your
state/action/reward sequence is a Markov Decision Process. That basically
means that you do not need to remember any information about previous states
from this episode to make decisions.</p>
<p>But this is obviously not true for all problems. Sometimes you do need to
remember some recent things to make informed decisions. Sometimes you can
explicitly build the things that need to be remembered into the state signal,
but in general we'd like our system to learn what it needs to remember. This
is called a Partially Observable Markov Decision Process (POMDP), and there
are a variety of methods used to deal with it. One possibly solution is to use
a recurrent neural network, since they incorporate details from previous time
steps into the current decision.</p>
    </div>
    <aside class="postpromonav"><nav><ul itemprop="keywords" class="tags">
<li><a class="tag p-category" href="../../categories/artificial-intelligence/" rel="tag">artificial-intelligence</a></li>
            <li><a class="tag p-category" href="../../categories/language-agnostic/" rel="tag">language-agnostic</a></li>
            <li><a class="tag p-category" href="../../categories/neural-network/" rel="tag">neural-network</a></li>
            <li><a class="tag p-category" href="../../categories/reinforcement-learning/" rel="tag">reinforcement-learning</a></li>
        </ul>
<ul class="pager hidden-print">
<li class="previous">
                <a href="../how-does-a-back-propagation-training-algorithm-work/" rel="prev" title="How does a back-propagation training algorithm work?">Previous post</a>
            </li>
            <li class="next">
                <a href="../structured-factored-and-atomic-representation/" rel="next" title="Structured, factored and atomic representation?">Next post</a>
            </li>
        </ul></nav></aside></article>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2023         Go to StackOverflow Chinese Site  <a href="http://stackoverflow.ink">StackOverflow-ZH</a>  
            
        </footer>
</div>
</div>


            <script src="../../assets/js/all-nocdn.js"></script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script><script src="../../assets/js/search.js"></script>
</body>
</html>
