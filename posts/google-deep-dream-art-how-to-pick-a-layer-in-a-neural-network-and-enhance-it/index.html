<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Google Deep Dream art: how to pick a layer in a neural network and enhance it | StackOverflow Snapshot</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="canonical" href="https://ohstackoverflow.netlify.app/posts/google-deep-dream-art-how-to-pick-a-layer-in-a-neural-network-and-enhance-it/">
<!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><meta name="author" content="Arya">
<link rel="prev" href="../what-is-the-difference-between-naive-and-semi-naive-evaluation/" title="What is the difference between naive and semi naive evaluation?" type="text/html">
<link rel="next" href="../similarity-in-data-mining/" title="'Similarity' in Data Mining" type="text/html">
<meta property="og:site_name" content="StackOverflow Snapshot">
<meta property="og:title" content="Google Deep Dream art: how to pick a layer in a neural network and enh">
<meta property="og:url" content="https://ohstackoverflow.netlify.app/posts/google-deep-dream-art-how-to-pick-a-layer-in-a-neural-network-and-enhance-it/">
<meta property="og:description" content="I am interested in a recent blog post by Google that describes the use of nn
to make art.
I am particularly interested in one technique:

'In this case we simply feed the network an arbitrary image or">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2023-02-28T03:51:12+08:00">
<meta property="article:tag" content="artificial-intelligence">
<meta property="article:tag" content="caffe">
<meta property="article:tag" content="deep-dream">
<meta property="article:tag" content="deep-learning">
<meta property="article:tag" content="neural-network">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://ohstackoverflow.netlify.app/">

                <span id="blog-title">StackOverflow Snapshot</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="../../archive.html">Archive</a>
                </li>
<li>
<a href="../../categories/">Tags</a>

                
            </li>
</ul>
<ul class="nav navbar-nav navbar-right">
<div style="display:table;min-height:5rem;min-width:27rem;">
					<div class="input-group" style="display: table-cell;vertical-align: middle;">
						<input id="words" type="text" class="form-control" style="max-width:22rem;" onkeydown="if(event.keyCode==13){btn.click()}"><span class="input-group-btn" style="float:left">
							<button id="btn" class="btn btn-default" type="button" data-toggle="modal" data-target="#myModal">
								<span class="glyphicon glyphicon-search">
							</span></button>
						</span>
					</div>
<!-- /input-group -->
				</div>

				
                
                
                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><!-- 模态框（Modal） --><div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true">
	<div class="modal-dialog">
		<div class="modal-content">
			<div class="modal-header">
				<button type="button" class="close" data-dismiss="modal" aria-hidden="true">×
				</button>
				<h4 class="modal-title" id="myModalLabel">
					查找结果
				</h4>
			</div>
			<div class="modal-body">
				<div id="search-count" style="min-height:4rem;">
				查找中，请稍后...
				</div>
				<div id="search-result">
				</div>

				
			</div>
			<div class="modal-footer">
				<button type="button" class="btn btn-default" data-dismiss="modal">
					关闭
				</button>
			</div>
		</div>
<!-- /.modal-content -->
	</div>
<!-- /.modal-dialog -->
</div>
<!-- /.modal -->

<div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">Google Deep Dream art: how to pick a layer in a neural network and enhance it</a></h1>

        <div class="metadata">
            <p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">
                    <a class="u-url" href="../../authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="." rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T03:51:12+08:00" itemprop="datePublished" title="2023-02-28 03:51">2023-02-28 03:51</time></a>
            </p>
            

        </div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <p>I am interested in a recent blog post by Google that describes the use of <code>nn</code>
to make art.</p>
<p>I am particularly interested in one technique:</p>
<blockquote>
<p>'In this case we simply feed the network an arbitrary image or photo and let
the network analyze the picture. We then pick a layer and ask the network to
enhance whatever it detected. Each layer of the network deals with features
at a different level of abstraction, so the complexity of features we
generate depends on which layer we choose to enhance. For example, lower
layers tend to produce strokes or simple ornament-like patterns, because
those layers are sensitive to basic features such as edges and their
orientations.'</p>
</blockquote>
<p>The post is http://googleresearch.blogspot.co.uk/2015/06/inceptionism-going-
deeper-into-neural.html?m=1.</p>
<p><strong>My question</strong> : the post describes this as a 'simple' case--is there an
open-source implementation of a nn that could be used for this purpose in a
relatively plug-and-play process? For just the technique described, does the
network need to be trained?</p>
<p>No doubt for other techniques mentioned in the paper one needs a network
already trained on a large number of images, but for the one I've described is
there already some kind of open-source network layer visualization package?</p>
<p><br><br></p>
<h2>Answer</h2>
<p>UPD: Google posted more detail instructions how they implemented it:
https://github.com/google/deepdream/blob/master/dream.ipynb</p>
<p>There's also another project: https://317070.github.io/Dream/</p>
<p>If you read 1,[2],[3],[4] from your link, you'll see that they used Caffe.
This framework already contains the trained networks to play with. You don't
need to train anything manually, just download the models using .sh scripts in
the <code>models/</code> folder.</p>
<p>You want "plug-and-play process", it's not so easy because besides the
framework, we need the code of the scripts they used and, probably, patch
Caffe. I tried to make something using their description. Caffe has Python and
Matlab interface but there's more in its internals.</p>
<p>The text below describes my thoughts on how it could be possibly implemented.
I'm not sure about my words so it's more like an invitation to research with
me than the "plug-and-play process". But as no one still answered, let me put
it here. Maybe someone will fix me.</p>
<p>So</p>
<p>As far as I understand, they run optimization</p>
<p><code>[sum((net.forwardTo(X, n) - enchanced_layer).^2) + lambda * R(X)] -&gt; min</code></p>
<p>I.e. look for such input <code>X</code> so that the particular layer of the netword would
produce the "enchanced" data instead of the "original" data.</p>
<p>There's a regularization constraint <code>R(X)</code>: <code>X</code> should look like "natural
image" (without high-frequency noise).</p>
<p><code>X</code> is our target image. The initial point <code>X0</code> is the original image.
<code>forwardTo(X, n)</code> is what our network produces in the layer <code>n</code> when we feed
the input with X. If speak about Caffe, you can make full-forward pass
(<code>net.forward</code>) and look at the blob you are interested in
(<code>net.blob_vec(n).get_data()</code>).</p>
<p><code>enchanced_layer</code> - we take the original layer blob and "enchance" signals in
it. What does it mean, I don't know. Maybe they just multiply the values by
coefficient, maybe something else.</p>
<p>Thus <code>sum((forwardTo(X, n) - enchanced_net).^2)</code> will become zero when your
input image produces exactly what you want in the layer <code>n</code>.</p>
<p><code>lambda</code> is the regularization parameter and <code>R(X)</code> is how <code>X</code> looks natural.
I didn't implement it and my results look very noisy. As for it's formula, you
can look for it at [2].</p>
<p>I used Matlab and <code>fminlbfgs</code> to optimize.</p>
<p>The key part was to find the gradient of the formula above because the problem
has too many dimensions to calculate the gradient numerically.</p>
<p>As I said, I didn't manage to find the gradient of <code>R(X)</code>. As for the main
part of the formula, I managed to find it this way:</p>
<ul>
<li>Set diff blob at the layer <code>n</code> to <code>forwardTo(X, n) - enchanced_net</code>. (see caffe documentation for <code>set_diff</code> and <code>set_data</code>, <code>set_data</code> is used for forward and waits for data and <code>set_diff</code> is used for backward propagation and waits for data errors).</li>
<li>Perform <em>partial</em> backpropagation from layer <code>n-1</code> to the input.</li>
<li>Input diff blob would contain the gradient we need.</li>
</ul>
<p>Python and Matlab interfaces do NOT contain partial backward propagation but
Caffe C++ internals contain it. I added a patch below to make it available in
Matlab.</p>
<p>Result of enhancing the 4th layer:</p>
<p><img alt="Result of enhancing the 4th layer" src="../../images/6NRkY.jpg"></p>
<p>I'm not happy with the results but I think there's something in common with
the article.</p>
<ul>
<li>Here's the code that produces the picture above "as is". The entry point is "run2.m", "fit2.m" contains the fitness function: https://github.com/galchinsky/caf</li>
<li>Here's caffe patch to Matlab interface to make partial backpropagation available: https://gist.github.com/anonymous/53d7cb44c072ae6320ff</li>
</ul>
<p><br></p>
<h3>Suggest</h3>
<p>In the link to Ipython notebook Dmitry provided, it says that it does
<strong>gradient</strong> <strong>ascent</strong> with <strong>maximizing</strong> L2 normalization. I believe this
is what Google means to be enhance the feature from a algorithmic perspective.</p>
<p>If you think about it, it's really the case, minimizing L2 would prevent over-
fitting, i.e. make the curve looks smoother. If you do the opposite, you are
making the feature more obvious.</p>
<p>Here is a great link to understand gradient ascent, though it talks about
gradient descent mainly.</p>
<p>I don't know much about implementation details in caffe, since I use theano
mostly. Hope it helps!</p>
<p><strong>Update</strong></p>
<p>So I read about the detailed articles [1],[2],[3],[4] today and find out that
[3] actually talks about the algorithm in details</p>
<blockquote>
<p>A locally-optimal <em>I</em> can be found by the back-propagation method. The
procedure is related to the ConvNet training procedure, where the back-
propagation is used to optimise the layer weights. The difference is that in
our case the optimisation is performed with respect to the input image,
while the weights are fixed to those found during the training stage. We
initialised the optimisation with the zero image (in our case, the ConvNet
was trained on the zero-centred image data), and then added the training set
mean image to the result.</p>
</blockquote>
<p>Therefore, after training the network on classification, you train it again
w.r.t to the input image, using gradient ascent in order to get higher score
for the class.</p>
    </div>
    <aside class="postpromonav"><nav><ul itemprop="keywords" class="tags">
<li><a class="tag p-category" href="../../categories/artificial-intelligence/" rel="tag">artificial-intelligence</a></li>
            <li><a class="tag p-category" href="../../categories/caffe/" rel="tag">caffe</a></li>
            <li><a class="tag p-category" href="../../categories/deep-dream/" rel="tag">deep-dream</a></li>
            <li><a class="tag p-category" href="../../categories/deep-learning/" rel="tag">deep-learning</a></li>
            <li><a class="tag p-category" href="../../categories/neural-network/" rel="tag">neural-network</a></li>
        </ul>
<ul class="pager hidden-print">
<li class="previous">
                <a href="../what-is-the-difference-between-naive-and-semi-naive-evaluation/" rel="prev" title="What is the difference between naive and semi naive evaluation?">Previous post</a>
            </li>
            <li class="next">
                <a href="../similarity-in-data-mining/" rel="next" title="'Similarity' in Data Mining">Next post</a>
            </li>
        </ul></nav></aside></article>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2023         Go to StackOverflow Chinese Site  <a href="http://stackoverflow.ink">StackOverflow中文网</a>  
            
        </footer>
</div>
</div>


            <script src="../../assets/js/all-nocdn.js"></script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script><script src="../../assets/js/search.js"></script>
</body>
</html>
