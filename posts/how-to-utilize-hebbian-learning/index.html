<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>How to utilize Hebbian learning? | StackOverflow Snapshot</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="canonical" href="https://ohstackoverflow.netlify.app/posts/how-to-utilize-hebbian-learning/">
<!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><meta name="author" content="Arya">
<link rel="prev" href="../good-implementations-of-reinforcement-learning/" title="Good implementations of reinforcement learning?" type="text/html">
<link rel="next" href="../a-heuristic-overestimation-underestimation/" title="A* heuristic, overestimation/underestimation?" type="text/html">
<meta property="og:site_name" content="StackOverflow Snapshot">
<meta property="og:title" content="How to utilize Hebbian learning?">
<meta property="og:url" content="https://ohstackoverflow.netlify.app/posts/how-to-utilize-hebbian-learning/">
<meta property="og:description" content="I want to upgrade my evolution simulator to use Hebb learning, like this one.
I basically want small creatures to be able to learn how to find food. I
achieved that with the basic feedforward networks">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2023-02-28T02:46:07+08:00">
<meta property="article:tag" content="artificial-intelligence">
<meta property="article:tag" content="evolutionary-algorithm">
<meta property="article:tag" content="machine-learning">
<meta property="article:tag" content="neural-network">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://ohstackoverflow.netlify.app/">

                <span id="blog-title">StackOverflow Snapshot</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="../../archive.html">Archive</a>
                </li>
<li>
<a href="../../categories/">Tags</a>

                
            </li>
</ul>
<ul class="nav navbar-nav navbar-right">
<div style="display:table;min-height:5rem;min-width:27rem;">
					<div class="input-group" style="display: table-cell;vertical-align: middle;">
						<input id="words" type="text" class="form-control" style="max-width:22rem;" onkeydown="if(event.keyCode==13){btn.click()}"><span class="input-group-btn" style="float:left">
							<button id="btn" class="btn btn-default" type="button" data-toggle="modal" data-target="#myModal">
								<span class="glyphicon glyphicon-search">
							</span></button>
						</span>
					</div>
<!-- /input-group -->
				</div>

				
                
                
                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><!-- 模态框（Modal） --><div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true">
	<div class="modal-dialog">
		<div class="modal-content">
			<div class="modal-header">
				<button type="button" class="close" data-dismiss="modal" aria-hidden="true">×
				</button>
				<h4 class="modal-title" id="myModalLabel">
					查找结果
				</h4>
			</div>
			<div class="modal-body">
				<div id="search-count" style="min-height:4rem;">
				查找中，请稍后...
				</div>
				<div id="search-result">
				</div>

				
			</div>
			<div class="modal-footer">
				<button type="button" class="btn btn-default" data-dismiss="modal">
					关闭
				</button>
			</div>
		</div>
<!-- /.modal-content -->
	</div>
<!-- /.modal-dialog -->
</div>
<!-- /.modal -->

<div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">How to utilize Hebbian learning?</a></h1>

        <div class="metadata">
            <p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">
                    <a class="u-url" href="../../authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="." rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T02:46:07+08:00" itemprop="datePublished" title="2023-02-28 02:46">2023-02-28 02:46</time></a>
            </p>
            

        </div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <p>I want to upgrade my evolution simulator to use Hebb learning, like this one.
I basically want small creatures to be able to learn how to find food. I
achieved that with the basic feedforward networks, but I'm stuck at
understanding how to do it with Hebb learning. The basic principle of Hebb
learning is that, if two neurons fire together, they wire together.</p>
<p>So, the weights are updated like this:</p>
<div class="code"><pre class="code literal-block">weight_change = learning_rate * input * output
</pre></div>

<p>The information I've found on how this can be useful is pretty scarce, and I
don't get it.</p>
<p>In my current version of the simulator, the weights between an action and an
input (movement, eyes) are increased when a creature eats a piece of food, and
I fail to see how that can translate into this new model. There simply is no
room to tell if it did something right or wrong here, because the only
parameters are input and output! Basically, if one input activates movement in
one direction, the weight would just keep on increasing, no matter if the
creature is eating something or not!</p>
<p>Am I applying Hebb learning in a wrong way? Just for reference, I'm using
Python.</p>
<p><br><br></p>
<h2>Answer</h2>
<p><code>Hebbs law</code> is a brilliant insight for <code>associative learning</code>, but its only
part of the picture. And you are right, implemented as you have done, and left
unchecked a weight will just keep on increasing. The key is to add in some
form of normalisation or limiting process. This is illustrated quite well of
the wiki page for Oja's rule. What I suggest you do is add in a <code>post-synaptic
divisive normalisation</code> step, what this means is that you divide through a
weight by the sum of all the weights converging on the same post-synaptic
neuron (i.e. the sum of all weights converging on a neuron is fixed at <code>1</code>).</p>
<p>What you want to do can be done by building a network that utilises <code>Hebbian
learning</code>. I'm not quite sure on what you are passing in as input into your
system, or how you've set things up. But you could look at <code>LISSOM</code> which is
an Hebbian extension to SOM, (self-organising map).</p>
<p>In a layer of this kind typically all the neurons may be interconnected. You
pass in the input vector, and allow the activity in the network to settle,
this is some number of settling steps. Then you update the weights. You do
this during the training phase, at the end of which associated items in the
input space will tend to form grouped activity patches in the output map.</p>
<p>It's also worth noting that the brain is massively interconnected, and highly
recursive (i.e. there is feedforward, feedback, lateral interconnectivity,
microcircuits, and a lot of other stuff too..).</p>
<p><br></p>
<h3>Suggest</h3>
<p>Although Hebbian learning, as a general concept, forms the basis for many
learning algorithms, including backpropagation, the simple, linear formula
which you use is very limited. Not only do weights rise infinitely, even when
the network has learned all the patterns, but the network can perfectly learn
only orthogonal (linearly independent) patterns.</p>
<p>Linear Hebbian learning is not even biologically plausible. Biological neural
networks are much bigger than yours and are highly non-linear, both the
neurons and the synapses between them. In big, non-linear networks, the
chances that your patterns are close to orthogonal are higher.</p>
<p>So, if you insist on using a neural network, I suggest adding hidden layers of
neurons and introducing non-linearities, both in the weights, e.g. as fraxel
proposed, and in firing of neurons---here you might use a sigmoid function,
like <code>tanh</code> (yes, using negative values for "non-firing" is good since it can
lead to reducing weights). In its generalized form, Hebbian rule can be
expressed as</p>
<div class="code"><pre class="code literal-block">weight_change = learning_rate * f1(input, weight) * f2(output, target_output)
</pre></div>

<p>where <code>f1</code> and <code>f2</code> are some functions. In your case, there is no
<code>target_output</code>, so <code>f2</code> is free to ignore it.</p>
<p>In order to have neurons in your hidden layers fire, and thus to get a
connection between input and output, you can initialize the weights to random
values.</p>
<p>But is a neural network really necessary, or even suitable for your problem?
Have you considered simple correlation? I mean, Hebb derived his rule to
explain how learning might function in biological systems, not as the best
possible machine learning algorithm.</p>
    </div>
    <aside class="postpromonav"><nav><ul itemprop="keywords" class="tags">
<li><a class="tag p-category" href="../../categories/artificial-intelligence/" rel="tag">artificial-intelligence</a></li>
            <li><a class="tag p-category" href="../../categories/evolutionary-algorithm/" rel="tag">evolutionary-algorithm</a></li>
            <li><a class="tag p-category" href="../../categories/machine-learning/" rel="tag">machine-learning</a></li>
            <li><a class="tag p-category" href="../../categories/neural-network/" rel="tag">neural-network</a></li>
        </ul>
<ul class="pager hidden-print">
<li class="previous">
                <a href="../good-implementations-of-reinforcement-learning/" rel="prev" title="Good implementations of reinforcement learning?">Previous post</a>
            </li>
            <li class="next">
                <a href="../a-heuristic-overestimation-underestimation/" rel="next" title="A* heuristic, overestimation/underestimation?">Next post</a>
            </li>
        </ul></nav></aside></article>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2023         Go to StackOverflow Chinese Site  <a href="http://stackoverflow.ink">StackOverflow中文网</a>  
            
        </footer>
</div>
</div>


            <script src="../../assets/js/all-nocdn.js"></script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script><script src="../../assets/js/search.js"></script>
</body>
</html>
