<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Unsupervised clustering with unknown number of clusters | StackOverflow Snapshot</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="canonical" href="https://ohstackoverflow.netlify.app/posts/unsupervised-clustering-with-unknown-number-of-clusters/">
<!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><meta name="author" content="Arya">
<link rel="prev" href="../how-to-create-a-new-gym-environment-in-openai/" title="How to create a new gym environment in OpenAI?" type="text/html">
<link rel="next" href="../comparison-between-luis-ai-vs-api-ai-vs-wit-ai/" title="Comparison between luis.ai vs api.ai vs wit.ai?" type="text/html">
<meta property="og:site_name" content="StackOverflow Snapshot">
<meta property="og:title" content="Unsupervised clustering with unknown number of clusters">
<meta property="og:url" content="https://ohstackoverflow.netlify.app/posts/unsupervised-clustering-with-unknown-number-of-clusters/">
<meta property="og:description" content="I have a large set of vectors in 3 dimensions. I need to cluster these based
on Euclidean distance such that all the vectors in any particular cluster have
a Euclidean distance between each other less">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2023-02-28T02:26:03+08:00">
<meta property="article:tag" content="algorithm">
<meta property="article:tag" content="artificial-intelligence">
<meta property="article:tag" content="cluster-analysis">
<meta property="article:tag" content="machine-learning">
<meta property="article:tag" content="math">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://ohstackoverflow.netlify.app/">

                <span id="blog-title">StackOverflow Snapshot</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="../../archive.html">Archive</a>
                </li>
<li>
<a href="../../categories/">Tags</a>

                
            </li>
</ul>
<ul class="nav navbar-nav navbar-right">
<div style="display:table;min-height:5rem;min-width:27rem;">
					<div class="input-group" style="display: table-cell;vertical-align: middle;">
						<input id="words" type="text" class="form-control" style="max-width:22rem;" onkeydown="if(event.keyCode==13){btn.click()}"><span class="input-group-btn" style="float:left">
							<button id="btn" class="btn btn-default" type="button" data-toggle="modal" data-target="#myModal">
								<span class="glyphicon glyphicon-search">
							</span></button>
						</span>
					</div>
<!-- /input-group -->
				</div>

				
                
                
                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><!-- 模态框（Modal） --><div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true">
	<div class="modal-dialog">
		<div class="modal-content">
			<div class="modal-header">
				<button type="button" class="close" data-dismiss="modal" aria-hidden="true">×
				</button>
				<h4 class="modal-title" id="myModalLabel">
					查找结果
				</h4>
			</div>
			<div class="modal-body">
				<div id="search-count" style="min-height:4rem;">
				查找中，请稍后...
				</div>
				<div id="search-result">
				</div>

				
			</div>
			<div class="modal-footer">
				<button type="button" class="btn btn-default" data-dismiss="modal">
					关闭
				</button>
			</div>
		</div>
<!-- /.modal-content -->
	</div>
<!-- /.modal-dialog -->
</div>
<!-- /.modal -->

<div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">Unsupervised clustering with unknown number of clusters</a></h1>

        <div class="metadata">
            <p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">
                    <a class="u-url" href="../../authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="." rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T02:26:03+08:00" itemprop="datePublished" title="2023-02-28 02:26">2023-02-28 02:26</time></a>
            </p>
            

        </div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <p>I have a large set of vectors in 3 dimensions. I need to cluster these based
on Euclidean distance such that all the vectors in any particular cluster have
a Euclidean distance between each other less than a threshold "T".</p>
<p>I do not know how many clusters exist. At the end, there may be individual
vectors existing that are not part of any cluster because its euclidean
distance is not less than "T" with any of the vectors in the space.</p>
<p>What existing algorithms / approach should be used here?</p>
<p><br><br></p>
<h2>Answer</h2>
<p>You can use hierarchical clustering. It is a rather basic approach, so there
are lots of implementations available. It is for example included in Python's
scipy.</p>
<p>See for example the following script:</p>
<div class="code"><pre class="code literal-block"><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">scipy.cluster.hierarchy</span> <span class="k">as</span> <span class="nn">hcluster</span>

<span class="c1"># generate 3 clusters of each around 100 points and one orphan point</span>
<span class="n">N</span><span class="o">=</span><span class="mi">100</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="o">*</span><span class="n">N</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">data</span><span class="p">[:</span><span class="n">N</span><span class="p">]</span> <span class="o">+=</span> <span class="mi">5</span>
<span class="n">data</span><span class="p">[</span><span class="o">-</span><span class="n">N</span><span class="p">:]</span> <span class="o">+=</span> <span class="mi">10</span>
<span class="n">data</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">:]</span> <span class="o">-=</span> <span class="mi">20</span>

<span class="c1"># clustering</span>
<span class="n">thresh</span> <span class="o">=</span> <span class="mf">1.5</span>
<span class="n">clusters</span> <span class="o">=</span> <span class="n">hcluster</span><span class="o">.</span><span class="n">fclusterdata</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">thresh</span><span class="p">,</span> <span class="n">criterion</span><span class="o">=</span><span class="s2">"distance"</span><span class="p">)</span>

<span class="c1"># plotting</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="o">*</span><span class="n">numpy</span><span class="o">.</span><span class="kp">transpose</span><span class="p">(</span><span class="n">data</span><span class="p">),</span> <span class="n">c</span><span class="o">=</span><span class="n">clusters</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">"equal"</span><span class="p">)</span>
<span class="n">title</span> <span class="o">=</span> <span class="s2">"threshold: </span><span class="si">%f</span><span class="s2">, number of clusters: </span><span class="si">%d</span><span class="s2">"</span> <span class="o">%</span> <span class="p">(</span><span class="n">thresh</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">clusters</span><span class="p">)))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

<p>Which produces a result similar to the following image.
<img alt="clusters" src="../../images/2jgjf.png"></p>
<p>The threshold given as a parameter is a distance value on which basis the
decision is made whether points/clusters will be merged into another cluster.
The distance metric being used can also be specified.</p>
<p>Note that there are various methods for how to compute the intra-/inter-
cluster similarity, e.g. distance between the closest points, distance between
the furthest points, distance to the cluster centers and so on. Some of these
methods are also supported by scipys hierarchical clustering module
(single/complete/average... linkage). According to your post I think you would
want to use complete linkage.</p>
<p>Note that this approach also allows small (single point) clusters if they
don't meet the similarity criterion of the other clusters, i.e. the distance
threshold.</p>
<hr>
<p>There are other algorithms that will perform better, which will become
relevant in situations with lots of data points. As other answers/comments
suggest you might also want to have a look at the DBSCAN algorithm:</p>
<ul>
<li>https://en.wikipedia.org/wiki/DBSCAN</li>
<li>http://scikit-learn.org/stable/auto_examples/cluster/plot_dbscan.html</li>
<li>http://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN</li>
</ul>
<hr>
<p>For a nice overview on these and other clustering algorithms, also have a look
at this demo page (of Python's scikit-learn library):</p>
<ul>
<li>http://scikit-learn.org/stable/modules/clustering.html</li>
</ul>
<p>Image copied from that place:</p>
<p><img alt="http://scikit-
learn.org/stable/auto_examples/cluster/plot_cluster_comparison.html" src="../../images/us6N2.jpg"></p>
<p>As you can see, each algorithm makes some assumptions about the number and
shape of the clusters that need to be taken into account. Be it implicit
assumptions imposed by the algorithm or explicit assumptions specified by
parameterization.</p>
<p><br></p>
<h3>Suggest</h3>
<p>The answer by moooeeeep recommended using hierarchical clustering. I wanted to
elaborate on how to <em>choose</em> the treshold of the clustering.</p>
<p>One way is to compute clusterings based on different thresholds <em>t1</em> , <em>t2</em> ,
<em>t3</em> ,... and then compute a metric for the "quality" of the clustering. The
premise is that the quality of a clustering with the <em>optimal</em> number of
clusters will have the maximum value of the quality metric.</p>
<p>An example of a good quality metric I've used in the past is Calinski-
Harabasz. Briefly: you compute the average inter-cluster distances and divide
them by the within-cluster distances. The optimal clustering assignment will
have clusters that are separated from each other the most, and clusters that
are "tightest".</p>
<p>By the way, you don't have to use hierarchical clustering. You can also use
something like <em>k</em> -means, precompute it for each <em>k</em> , and then pick the <em>k</em>
that has the highest Calinski-Harabasz score.</p>
<p>Let me know if you need more references, and I'll scour my hard disk for some
papers.</p>
    </div>
    <aside class="postpromonav"><nav><ul itemprop="keywords" class="tags">
<li><a class="tag p-category" href="../../categories/algorithm/" rel="tag">algorithm</a></li>
            <li><a class="tag p-category" href="../../categories/artificial-intelligence/" rel="tag">artificial-intelligence</a></li>
            <li><a class="tag p-category" href="../../categories/cluster-analysis/" rel="tag">cluster-analysis</a></li>
            <li><a class="tag p-category" href="../../categories/machine-learning/" rel="tag">machine-learning</a></li>
            <li><a class="tag p-category" href="../../categories/math/" rel="tag">math</a></li>
        </ul>
<ul class="pager hidden-print">
<li class="previous">
                <a href="../how-to-create-a-new-gym-environment-in-openai/" rel="prev" title="How to create a new gym environment in OpenAI?">Previous post</a>
            </li>
            <li class="next">
                <a href="../comparison-between-luis-ai-vs-api-ai-vs-wit-ai/" rel="next" title="Comparison between luis.ai vs api.ai vs wit.ai?">Next post</a>
            </li>
        </ul></nav></aside></article>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2023         Go to StackOverflow Chinese Site  <a href="http://stackoverflow.ink">StackOverflow中文网</a>  
            
        </footer>
</div>
</div>


            <script src="../../assets/js/all-nocdn.js"></script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script><script src="../../assets/js/search.js"></script>
</body>
</html>
