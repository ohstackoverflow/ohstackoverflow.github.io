<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>How do I profile C++ code running on Linux? | StackOverflow Snapshot</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="canonical" href="https://ohstackoverflow.netlify.app/posts/how-do-i-profile-c-code-running-on-linux/">
<!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><meta name="author" content="Arya">
<link rel="prev" href="../how-do-you-merge-two-git-repositories/" title="How do you merge two Git repositories?" type="text/html">
<link rel="next" href="../short-circuit-array-foreach-like-calling-break/" title="Short circuit Array.forEach like calling break" type="text/html">
<meta property="og:site_name" content="StackOverflow Snapshot">
<meta property="og:title" content="How do I profile C++ code running on Linux?">
<meta property="og:url" content="https://ohstackoverflow.netlify.app/posts/how-do-i-profile-c-code-running-on-linux/">
<meta property="og:description" content="How do I find areas of my code that run slowly in a C++ application running on
Linux?

Answer
If your goal is to use a profiler, use one of the suggested ones.
However, if you're in a hurry and you ca">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2023-02-16T22:41:01+08:00">
<meta property="article:tag" content="c++">
<meta property="article:tag" content="linux">
<meta property="article:tag" content="profiling">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://ohstackoverflow.netlify.app/">

                <span id="blog-title">StackOverflow Snapshot</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="../../archive.html">Archive</a>
                </li>
<li>
<a href="../../categories/">Tags</a>

                
            </li>
</ul>
<ul class="nav navbar-nav navbar-right">
<div style="display:table;min-height:5rem;min-width:27rem;">
					<div class="input-group" style="display: table-cell;vertical-align: middle;">
						<input id="words" type="text" class="form-control" style="max-width:22rem;" onkeydown="if(event.keyCode==13){btn.click()}"><span class="input-group-btn" style="float:left">
							<button id="btn" class="btn btn-default" type="button" data-toggle="modal" data-target="#myModal">
								<span class="glyphicon glyphicon-search">
							</span></button>
						</span>
					</div>
<!-- /input-group -->
				</div>

				
                
                
                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><!-- 模态框（Modal） --><div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true">
	<div class="modal-dialog">
		<div class="modal-content">
			<div class="modal-header">
				<button type="button" class="close" data-dismiss="modal" aria-hidden="true">×
				</button>
				<h4 class="modal-title" id="myModalLabel">
					查找结果
				</h4>
			</div>
			<div class="modal-body">
				<div id="search-count" style="min-height:4rem;">
				查找中，请稍后...
				</div>
				<div id="search-result">
				</div>

				
			</div>
			<div class="modal-footer">
				<button type="button" class="btn btn-default" data-dismiss="modal">
					关闭
				</button>
			</div>
		</div>
<!-- /.modal-content -->
	</div>
<!-- /.modal-dialog -->
</div>
<!-- /.modal -->

<div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">How do I profile C++ code running on Linux?</a></h1>

        <div class="metadata">
            <p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">
                    <a class="u-url" href="../../authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="." rel="bookmark">
            <time class="published dt-published" datetime="2023-02-16T22:41:01+08:00" itemprop="datePublished" title="2023-02-16 22:41">2023-02-16 22:41</time></a>
            </p>
            

        </div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <p>How do I find areas of my code that run slowly in a C++ application running on
Linux?</p>
<p><br><br></p>
<h2>Answer</h2>
<p>If your goal is to use a profiler, use one of the suggested ones.</p>
<p>However, if you're in a hurry and you can manually interrupt your program
under the debugger while it's being subjectively slow, there's a simple way to
find performance problems.</p>
<p>Just halt it several times, and each time look at the call stack. If there is
some code that is wasting some percentage of the time, 20% or 50% or whatever,
that is the probability that you will catch it in the act on each sample. So,
that is roughly the percentage of samples on which you will see it. There is
no educated guesswork required. If you do have a guess as to what the problem
is, this will prove or disprove it.</p>
<p>You may have multiple performance problems of different sizes. If you clean
out any one of them, the remaining ones will take a larger percentage, and be
easier to spot, on subsequent passes. This <em>magnification effect</em> , when
compounded over multiple problems, can lead to truly massive speedup factors.</p>
<p><strong>Caveat</strong> : Programmers tend to be skeptical of this technique unless they've
used it themselves. They will say that profilers give you this information,
but that is only true if they sample the entire call stack, and then let you
examine a random set of samples. (The summaries are where the insight is
lost.) Call graphs don't give you the same information, because</p>
<ol>
<li>They don't summarize at the instruction level, and</li>
<li>They give confusing summaries in the presence of recursion.</li>
</ol>
<p>They will also say it only works on toy programs, when actually it works on
any program, and it seems to work better on bigger programs, because they tend
to have more problems to find. They will say it sometimes finds things that
aren't problems, but that is only true if you see something <em>once</em>. If you see
a problem on more than one sample, it is real.</p>
<p><strong>P.S.</strong> This can also be done on multi-thread programs if there is a way to
collect call-stack samples of the thread pool at a point in time, as there is
in Java.</p>
<p><strong>P.P.S</strong> As a rough generality, the more layers of abstraction you have in
your software, the more likely you are to find that that is the cause of
performance problems (and the opportunity to get speedup).</p>
<p><strong>Added</strong> : It might not be obvious, but the stack sampling technique works
equally well in the presence of recursion. The reason is that the time that
would be saved by removal of an instruction is approximated by the fraction of
samples containing it, regardless of the number of times it may occur within a
sample.</p>
<p>Another objection I often hear is: " <em>It will stop someplace random, and it
will miss the real problem</em> ". This comes from having a prior concept of what
the real problem is. A key property of performance problems is that they defy
expectations. Sampling tells you something is a problem, and your first
reaction is disbelief. That is natural, but you can be sure if it finds a
problem it is real, and vice-versa.</p>
<p><strong>Added</strong> : Let me make a Bayesian explanation of how it works. Suppose there
is some instruction <code>I</code> (call or otherwise) which is on the call stack some
fraction <code>f</code> of the time (and thus costs that much). For simplicity, suppose
we don't know what <code>f</code> is, but assume it is either 0.1, 0.2, 0.3, ... 0.9,
1.0, and the prior probability of each of these possibilities is 0.1, so all
of these costs are equally likely a-priori.</p>
<p>Then suppose we take just 2 stack samples, and we see instruction <code>I</code> on both
samples, designated observation <code>o=2/2</code>. This gives us new estimates of the
frequency <code>f</code> of <code>I</code>, according to this:</p>
<div class="code"><pre class="code literal-block">Prior                                    
P(f=x) x  P(o=2/2|f=x) P(o=2/2&amp;&amp;f=x)  P(o=2/2&amp;&amp;f &gt;= x)  P(f &gt;= x | o=2/2)

0.1    1     1             0.1          0.1            0.25974026
0.1    0.9   0.81          0.081        0.181          0.47012987
0.1    0.8   0.64          0.064        0.245          0.636363636
0.1    0.7   0.49          0.049        0.294          0.763636364
0.1    0.6   0.36          0.036        0.33           0.857142857
0.1    0.5   0.25          0.025        0.355          0.922077922
0.1    0.4   0.16          0.016        0.371          0.963636364
0.1    0.3   0.09          0.009        0.38           0.987012987
0.1    0.2   0.04          0.004        0.384          0.997402597
0.1    0.1   0.01          0.001        0.385          1

                  P(o=2/2) 0.385
</pre></div>

<p>The last column says that, for example, the probability that <code>f</code> &gt;= 0.5 is
92%, up from the prior assumption of 60%.</p>
<p>Suppose the prior assumptions are different. Suppose we assume <code>P(f=0.1)</code> is
.991 (nearly certain), and all the other possibilities are almost impossible
(0.001). In other words, our prior certainty is that <code>I</code> is cheap. Then we
get:</p>
<div class="code"><pre class="code literal-block">Prior                                    
P(f=x) x  P(o=2/2|f=x) P(o=2/2&amp;&amp; f=x)  P(o=2/2&amp;&amp;f &gt;= x)  P(f &gt;= x | o=2/2)

0.001  1    1              0.001        0.001          0.072727273
0.001  0.9  0.81           0.00081      0.00181        0.131636364
0.001  0.8  0.64           0.00064      0.00245        0.178181818
0.001  0.7  0.49           0.00049      0.00294        0.213818182
0.001  0.6  0.36           0.00036      0.0033         0.24
0.001  0.5  0.25           0.00025      0.00355        0.258181818
0.001  0.4  0.16           0.00016      0.00371        0.269818182
0.001  0.3  0.09           0.00009      0.0038         0.276363636
0.001  0.2  0.04           0.00004      0.00384        0.279272727
0.991  0.1  0.01           0.00991      0.01375        1

                  P(o=2/2) 0.01375
</pre></div>

<p>Now it says <code>P(f &gt;= 0.5)</code> is 26%, up from the prior assumption of 0.6%. So
Bayes allows us to update our estimate of the probable cost of <code>I</code>. If the
amount of data is small, it doesn't tell us accurately what the cost is, only
that it is big enough to be worth fixing.</p>
<p>Yet another way to look at it is called the Rule Of Succession. If you flip a
coin 2 times, and it comes up heads both times, what does that tell you about
the probable weighting of the coin? The respected way to answer is to say that
it's a Beta distribution, with average value <code>(number of hits + 1) / (number
of tries + 2) = (2+1)/(2+2) = 75%</code>.</p>
<p>(The key is that we see <code>I</code> more than once. If we only see it once, that
doesn't tell us much except that <code>f</code> &gt; 0.)</p>
<p>So, even a very small number of samples can tell us a lot about the cost of
instructions that it sees. (And it will see them with a frequency, on average,
proportional to their cost. If <code>n</code> samples are taken, and <code>f</code> is the cost,
then <code>I</code> will appear on <code>nf+/-sqrt(nf(1-f))</code> samples. Example, <code>n=10</code>,
<code>f=0.3</code>, that is <code>3+/-1.4</code> samples.)</p>
<hr>
<p><strong>Added</strong> : To give an intuitive feel for the difference between measuring and
random stack sampling:<br>
There are profilers now that sample the stack, even on wall-clock time, but
<em>what comes out</em> is measurements (or hot path, or hot spot, from which a
"bottleneck" can easily hide). What they don't show you (and they easily
could) is the actual samples themselves. And if your goal is to <em>find</em> the
bottleneck, the number of them you need to see is, <em>on average</em> , 2 divided by
the fraction of time it takes. So if it takes 30% of time, 2/.3 = 6.7 samples,
on average, will show it, and the chance that 20 samples will show it is
99.2%.</p>
<p>Here is an off-the-cuff illustration of the difference between examining
measurements and examining stack samples. The bottleneck could be one big blob
like this, or numerous small ones, it makes no difference.</p>
<p><img alt="enter image description here" src="../../images/FpWuS.png"></p>
<p>Measurement is horizontal; it tells you what fraction of time specific
routines take. Sampling is vertical. If there is any way to avoid what the
whole program is doing at that moment, <em>and if you see it on a second sample</em>
, you've found the bottleneck. That's what makes the difference - seeing the
whole reason for the time being spent, not just how much.</p>
<p><br></p>
<h3>Suggest</h3>
<p>Use Valgrind with the following options:</p>
<div class="code"><pre class="code literal-block"><span class="n">valgrind</span><span class="w"> </span><span class="o">--</span><span class="k">tool</span><span class="o">=</span><span class="n">callgrind</span><span class="w"> </span><span class="o">./</span><span class="p">(</span><span class="n">Your</span><span class="w"> </span><span class="n">binary</span><span class="p">)</span>
</pre></div>

<p>This generates a file called <code>callgrind.out.x</code>. Use the <code>kcachegrind</code> tool to
read this file. It will give you a graphical analysis of things with results
like which lines cost how much.</p>
    </div>
    <aside class="postpromonav"><nav><ul itemprop="keywords" class="tags">
<li><a class="tag p-category" href="../../categories/c%2B%2B/" rel="tag">c++</a></li>
            <li><a class="tag p-category" href="../../categories/linux/" rel="tag">linux</a></li>
            <li><a class="tag p-category" href="../../categories/profiling/" rel="tag">profiling</a></li>
        </ul>
<ul class="pager hidden-print">
<li class="previous">
                <a href="../how-do-you-merge-two-git-repositories/" rel="prev" title="How do you merge two Git repositories?">Previous post</a>
            </li>
            <li class="next">
                <a href="../short-circuit-array-foreach-like-calling-break/" rel="next" title="Short circuit Array.forEach like calling break">Next post</a>
            </li>
        </ul></nav></aside></article>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2023         Go to StackOverflow Chinese Site  <a href="http://stackoverflow.ink">StackOverflow中文网</a>  
            
        </footer>
</div>
</div>


            <script src="../../assets/js/all-nocdn.js"></script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script><script src="../../assets/js/search.js"></script>
</body>
</html>
