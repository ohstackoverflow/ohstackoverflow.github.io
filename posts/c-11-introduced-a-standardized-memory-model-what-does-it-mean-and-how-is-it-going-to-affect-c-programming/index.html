<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>C++11 introduced a standardized memory model. What does it mean? And how is it going to affect C++ programming? | StackOverflow Snapshot</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="canonical" href="https://ohstackoverflow.netlify.app/posts/c-11-introduced-a-standardized-memory-model-what-does-it-mean-and-how-is-it-going-to-affect-c-programming/">
<!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><meta name="author" content="Arya">
<link rel="prev" href="../how-can-i-see-the-changes-in-a-git-commit/" title="How can I see the changes in a Git commit?" type="text/html">
<link rel="next" href="../how-to-remove-an-element-from-a-list-by-index/" title="How to remove an element from a list by index" type="text/html">
<meta property="og:site_name" content="StackOverflow Snapshot">
<meta property="og:title" content="C++11 introduced a standardized memory model. What does it mean? And h">
<meta property="og:url" content="https://ohstackoverflow.netlify.app/posts/c-11-introduced-a-standardized-memory-model-what-does-it-mean-and-how-is-it-going-to-affect-c-programming/">
<meta property="og:description" content="C++11 introduced a standardized memory model, but what exactly does that mean?
And how is it going to affect C++ programming?
This article (by Gavin Clarke who quotes Herb Sutter ) says that,

The mem">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2023-02-16T22:28:52+08:00">
<meta property="article:tag" content="c++">
<meta property="article:tag" content="c++11">
<meta property="article:tag" content="language-lawyer">
<meta property="article:tag" content="memory-model">
<meta property="article:tag" content="multithreading">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://ohstackoverflow.netlify.app/">

                <span id="blog-title">StackOverflow Snapshot</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="../../archive.html">Archive</a>
                </li>
<li>
<a href="../../categories/">Tags</a>

                
            </li>
</ul>
<ul class="nav navbar-nav navbar-right">
<div style="display:table;min-height:5rem;min-width:27rem;">
					<div class="input-group" style="display: table-cell;vertical-align: middle;">
						<input id="words" type="text" class="form-control" style="max-width:22rem;" onkeydown="if(event.keyCode==13){btn.click()}"><span class="input-group-btn" style="float:left">
							<button id="btn" class="btn btn-default" type="button" data-toggle="modal" data-target="#myModal">
								<span class="glyphicon glyphicon-search">
							</span></button>
						</span>
					</div>
<!-- /input-group -->
				</div>

				
                
                
                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><!-- 模态框（Modal） --><div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true">
	<div class="modal-dialog">
		<div class="modal-content">
			<div class="modal-header">
				<button type="button" class="close" data-dismiss="modal" aria-hidden="true">×
				</button>
				<h4 class="modal-title" id="myModalLabel">
					查找结果
				</h4>
			</div>
			<div class="modal-body">
				<div id="search-count" style="min-height:4rem;">
				查找中，请稍后...
				</div>
				<div id="search-result">
				</div>

				
			</div>
			<div class="modal-footer">
				<button type="button" class="btn btn-default" data-dismiss="modal">
					关闭
				</button>
			</div>
		</div>
<!-- /.modal-content -->
	</div>
<!-- /.modal-dialog -->
</div>
<!-- /.modal -->

<div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">C++11 introduced a standardized memory model. What does it mean? And how is it going to affect C++ programming?</a></h1>

        <div class="metadata">
            <p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">
                    <a class="u-url" href="../../authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="." rel="bookmark">
            <time class="published dt-published" datetime="2023-02-16T22:28:52+08:00" itemprop="datePublished" title="2023-02-16 22:28">2023-02-16 22:28</time></a>
            </p>
            

        </div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <p>C++11 introduced a standardized memory model, but what exactly does that mean?
And how is it going to affect C++ programming?</p>
<p>This article (by <strong>Gavin Clarke</strong> who quotes <strong>Herb Sutter</strong> ) says that,</p>
<blockquote>
<p>The memory model means that C++ code now has a standardized library to call
regardless of who made the compiler and on what platform it's running.
There's a standard way to control how different threads talk to the
processor's memory.</p>
<p>"When you are talking about splitting [code] across different cores that's
in the standard, we are talking about the memory model. We are going to
optimize it without breaking the following assumptions people are going to
make in the code," <strong>Sutter</strong> said.</p>
</blockquote>
<p>Well, I can <em>memorize</em> this and similar paragraphs available online (as I've
had my own memory model since birth :P) and can even post as an answer to
questions asked by others, but to be honest, I don't exactly understand this.</p>
<p>C++ programmers used to develop multi-threaded applications even before, so
how does it matter if it's POSIX threads, or Windows threads, or C++11
threads? What are the benefits? I want to understand the low-level details.</p>
<p>I also get this feeling that the C++11 memory model is somehow related to
C++11 multi-threading support, as I often see these two together. If it is,
how exactly? Why should they be related?</p>
<p>I don't know how the internals of multi-threading work, and what memory model
means in general.</p>
<p><br><br></p>
<h2>Answer</h2>
<p>First, you have to learn to think like a Language Lawyer.</p>
<p>The C++ specification does not make reference to any particular compiler,
operating system, or CPU. It makes reference to an <em>abstract machine</em> that is
a generalization of actual systems. In the Language Lawyer world, the job of
the programmer is to write code for the abstract machine; the job of the
compiler is to actualize that code on a concrete machine. By coding rigidly to
the spec, you can be certain that your code will compile and run without
modification on any system with a compliant C++ compiler, whether today or 50
years from now.</p>
<p>The abstract machine in the C++98/C++03 specification is fundamentally single-
threaded. So it is not possible to write multi-threaded C++ code that is
"fully portable" with respect to the spec. The spec does not even say anything
about the <em>atomicity</em> of memory loads and stores or the <em>order</em> in which loads
and stores might happen, never mind things like mutexes.</p>
<p>Of course, you can write multi-threaded code in practice for particular
concrete systems – like pthreads or Windows. But there is no <em>standard</em> way to
write multi-threaded code for C++98/C++03.</p>
<p>The abstract machine in C++11 is multi-threaded by design. It also has a well-
defined <em>memory model</em> ; that is, it says what the compiler may and may not do
when it comes to accessing memory.</p>
<p>Consider the following example, where a pair of global variables are accessed
concurrently by two threads:</p>
<div class="code"><pre class="code literal-block">           Global
           int x, y;

Thread 1            Thread 2
x = 17;             cout &lt;&lt; y &lt;&lt; " ";
y = 37;             cout &lt;&lt; x &lt;&lt; endl;
</pre></div>

<p>What might Thread 2 output?</p>
<p>Under C++98/C++03, this is not even Undefined Behavior; the question itself is
<em>meaningless</em> because the standard does not contemplate anything called a
"thread".</p>
<p>Under C++11, the result is Undefined Behavior, because loads and stores need
not be atomic in general. Which may not seem like much of an improvement...
And by itself, it's not.</p>
<p>But with C++11, you can write this:</p>
<div class="code"><pre class="code literal-block"><span class="w">           </span><span class="n">Global</span>
<span class="w">           </span><span class="n">atomic</span><span class="o">&lt;</span><span class="nb nb-Type">int</span><span class="o">&gt;</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">;</span>

<span class="n">Thread</span><span class="w"> </span><span class="mi">1</span><span class="w">                 </span><span class="n">Thread</span><span class="w"> </span><span class="mi">2</span>
<span class="n">x</span><span class="o">.</span><span class="n">store</span><span class="p">(</span><span class="mi">17</span><span class="p">);</span><span class="w">             </span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">y</span><span class="o">.</span><span class="n">load</span><span class="p">()</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s2">" "</span><span class="p">;</span>
<span class="n">y</span><span class="o">.</span><span class="n">store</span><span class="p">(</span><span class="mi">37</span><span class="p">);</span><span class="w">             </span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">x</span><span class="o">.</span><span class="n">load</span><span class="p">()</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">endl</span><span class="p">;</span>
</pre></div>

<p>Now things get much more interesting. First of all, the behavior here is
<em>defined</em>. Thread 2 could now print <code>0 0</code> (if it runs before Thread 1), <code>37
17</code> (if it runs after Thread 1), or <code>0 17</code> (if it runs after Thread 1 assigns
to x but before it assigns to y).</p>
<p>What it cannot print is <code>37 0</code>, because the default mode for atomic
loads/stores in C++11 is to enforce <em>sequential consistency</em>. This just means
all loads and stores must be "as if" they happened in the order you wrote them
within each thread, while operations among threads can be interleaved however
the system likes. So the default behavior of atomics provides both <em>atomicity</em>
and <em>ordering</em> for loads and stores.</p>
<p>Now, on a modern CPU, ensuring sequential consistency can be expensive. In
particular, the compiler is likely to emit full-blown memory barriers between
every access here. But if your algorithm can tolerate out-of-order loads and
stores; i.e., if it requires atomicity but not ordering; i.e., if it can
tolerate <code>37 0</code> as output from this program, then you can write this:</p>
<div class="code"><pre class="code literal-block"><span class="w">           </span><span class="n">Global</span>
<span class="w">           </span><span class="n">atomic</span><span class="o">&lt;</span><span class="nb nb-Type">int</span><span class="o">&gt;</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">;</span>

<span class="n">Thread</span><span class="w"> </span><span class="mi">1</span><span class="w">                            </span><span class="n">Thread</span><span class="w"> </span><span class="mi">2</span>
<span class="n">x</span><span class="o">.</span><span class="n">store</span><span class="p">(</span><span class="mi">17</span><span class="p">,</span><span class="n">memory_order_relaxed</span><span class="p">);</span><span class="w">   </span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">y</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">memory_order_relaxed</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s2">" "</span><span class="p">;</span>
<span class="n">y</span><span class="o">.</span><span class="n">store</span><span class="p">(</span><span class="mi">37</span><span class="p">,</span><span class="n">memory_order_relaxed</span><span class="p">);</span><span class="w">   </span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">x</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">memory_order_relaxed</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">endl</span><span class="p">;</span>
</pre></div>

<p>The more modern the CPU, the more likely this is to be faster than the
previous example.</p>
<p>Finally, if you just need to keep particular loads and stores in order, you
can write:</p>
<div class="code"><pre class="code literal-block"><span class="w">           </span><span class="n">Global</span>
<span class="w">           </span><span class="n">atomic</span><span class="o">&lt;</span><span class="nb nb-Type">int</span><span class="o">&gt;</span><span class="w"> </span><span class="n">x</span><span class="p">,</span><span class="w"> </span><span class="n">y</span><span class="p">;</span>

<span class="n">Thread</span><span class="w"> </span><span class="mi">1</span><span class="w">                            </span><span class="n">Thread</span><span class="w"> </span><span class="mi">2</span>
<span class="n">x</span><span class="o">.</span><span class="n">store</span><span class="p">(</span><span class="mi">17</span><span class="p">,</span><span class="n">memory_order_release</span><span class="p">);</span><span class="w">   </span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">y</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">memory_order_acquire</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="s2">" "</span><span class="p">;</span>
<span class="n">y</span><span class="o">.</span><span class="n">store</span><span class="p">(</span><span class="mi">37</span><span class="p">,</span><span class="n">memory_order_release</span><span class="p">);</span><span class="w">   </span><span class="n">cout</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">x</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">memory_order_acquire</span><span class="p">)</span><span class="w"> </span><span class="o">&lt;&lt;</span><span class="w"> </span><span class="n">endl</span><span class="p">;</span>
</pre></div>

<p>This takes us back to the ordered loads and stores – so <code>37 0</code> is no longer a
possible output – but it does so with minimal overhead. (In this trivial
example, the result is the same as full-blown sequential consistency; in a
larger program, it would not be.)</p>
<p>Of course, if the only outputs you want to see are <code>0 0</code> or <code>37 17</code>, you can
just wrap a mutex around the original code. But if you have read this far, I
bet you already know how that works, and this answer is already longer than I
intended :-).</p>
<p>So, bottom line. Mutexes are great, and C++11 standardizes them. But sometimes
for performance reasons you want lower-level primitives (e.g., the classic
double-checked locking pattern). The new standard provides high-level gadgets
like mutexes and condition variables, and it also provides low-level gadgets
like atomic types and the various flavors of memory barrier. So now you can
write sophisticated, high-performance concurrent routines entirely within the
language specified by the standard, and you can be certain your code will
compile and run unchanged on both today's systems and tomorrow's.</p>
<p>Although to be frank, unless you are an expert and working on some serious
low-level code, you should probably stick to mutexes and condition variables.
That's what I intend to do.</p>
<p>For more on this stuff, see this blog post.</p>
<p><br></p>
<h3>Suggest</h3>
<p>I will just give the analogy with which I understand memory consistency models
(or memory models, for short). It is inspired by Leslie Lamport's seminal
paper "Time, Clocks, and the Ordering of Events in a Distributed System". The
analogy is apt and has fundamental significance, but may be overkill for many
people. However, I hope it provides a mental image (a pictorial
representation) that facilitates reasoning about memory consistency models.</p>
<p>Let’s view the histories of all memory locations in a space-time diagram in
which the horizontal axis represents the address space (i.e., each memory
location is represented by a point on that axis) and the vertical axis
represents time (we will see that, in general, there is not a universal notion
of time). The history of values held by each memory location is, therefore,
represented by a vertical column at that memory address. Each value change is
due to one of the threads writing a new value to that location. By a <em><strong>memory
image</strong></em> , we will mean the aggregate/combination of values of all memory
locations observable <em><strong>at a particular time</strong></em> by <em><strong>a particular thread</strong></em>.</p>
<p>Quoting from "A Primer on Memory Consistency and Cache Coherence"</p>
<blockquote>
<p>The intuitive (and most restrictive) memory model is sequential consistency
(SC) in which a multithreaded execution should look like an interleaving of
the sequential executions of each constituent thread, as if the threads were
time-multiplexed on a single-core processor.</p>
</blockquote>
<p>That global memory order can vary from one run of the program to another and
may not be known beforehand. The characteristic feature of SC is the set of
horizontal slices in the address-space-time diagram representing <em><strong>planes of
simultaneity</strong></em> (i.e., memory images). On a given plane, all of its events (or
memory values) are simultaneous. There is a notion of <em>Absolute Time</em> , in
which all threads agree on which memory values are simultaneous. In SC, at
every time instant, there is only one memory image shared by all threads.
That's, at every instant of time, all processors agree on the memory image
(i.e., the aggregate content of memory). Not only does this imply that all
threads view the same sequence of values for all memory locations, but also
that all processors observe the same <em>combinations of values</em> of all
variables. This is the same as saying all memory operations (on all memory
locations) are observed in the same total order by all threads.</p>
<p>In relaxed memory models, each thread will slice up address-space-time in its
own way, the only restriction being that slices of each thread shall not cross
each other because all threads must agree on the history of every individual
memory location (of course, slices of different threads may, and will, cross
each other). There is no universal way to slice it up (no privileged foliation
of address-space-time). Slices do not have to be planar (or linear). They can
be curved and this is what can make a thread read values written by another
thread out of the order they were written in. Histories of different memory
locations may slide (or get stretched) arbitrarily relative to each other
<em><strong>when viewed by any particular thread</strong></em>. Each thread will have a different
sense of which events (or, equivalently, memory values) are simultaneous. The
set of events (or memory values) that are simultaneous to one thread are not
simultaneous to another. Thus, in a relaxed memory model, all threads still
observe the same history (i.e., sequence of values) for each memory location.
But they may observe different memory images (i.e., combinations of values of
all memory locations). Even if two different memory locations are written by
the same thread in sequence, the two newly written values may be observed in
different order by other threads.</p>
<p>[Picture from Wikipedia] <img alt="Picture from
Wikipedia" src="https://upload.wikimedia.org/wikipedia/commons/f/f1/Relsim2.GIF"></p>
<p>Readers familiar with Einstein’s <strong>Special Theory of Relativity</strong> will notice
what I am alluding to. Translating Minkowski’s words into the memory models
realm: address space and time are shadows of address-space-time. In this case,
each observer (i.e., thread) will project shadows of events (i.e., memory
stores/loads) onto his own world-line (i.e., his time axis) and his own plane
of simultaneity (his address-space axis). Threads in the C++11 memory model
correspond to <em><strong>observers</strong></em> that are moving relative to each other in
special relativity. Sequential consistency corresponds to the <strong>Galilean
space-time</strong> (i.e., all observers agree on one absolute order of events and a
global sense of simultaneity).</p>
<p>The resemblance between memory models and special relativity stems from the
fact that both define a partially-ordered set of events, often called a causal
set. Some events (i.e., memory stores) can affect (but not be affected by)
other events. A C++11 thread (or observer in physics) is no more than a chain
(i.e., a totally ordered set) of events (e.g., memory loads and stores to
possibly different addresses).</p>
<p>In relativity, some order is restored to the seemingly chaotic picture of
partially ordered events, since the only temporal ordering that all observers
agree on is the ordering among “timelike” events (i.e., those events that are
in principle connectible by any particle going slower than the speed of light
in a vacuum). Only the timelike related events are invariantly ordered. Time
in Physics, Craig Callender.</p>
<p>In C++11 memory model, a similar mechanism (the acquire-release consistency
model) is used to establish these <em><strong>local causality relations</strong></em>.</p>
<p>To provide a definition of memory consistency and a motivation for abandoning
SC, I will quote from "A Primer on Memory Consistency and Cache Coherence"</p>
<blockquote>
<p>For a shared memory machine, the memory consistency model defines the
architecturally visible behavior of its memory system. The correctness
criterion for a single processor core partitions behavior between “ <em>one
correct result</em> ” and “ <em>many incorrect alternatives</em> ”. This is because the
processor’s architecture mandates that the execution of a thread transforms
a given input state into a single well-defined output state, even on an out-
of-order core. Shared memory consistency models, however, concern the loads
and stores of multiple threads and usually allow <em>many correct executions</em>
while disallowing many (more) incorrect ones. The possibility of multiple
correct executions is due to the ISA allowing multiple threads to execute
concurrently, often with many possible legal interleavings of instructions
from different threads.</p>
<p><em><strong>Relaxed</strong></em> or <em><strong>weak</strong></em> memory consistency models are motivated by the
fact that most memory orderings in strong models are unnecessary. If a
thread updates ten data items and then a synchronization flag, programmers
usually do not care if the data items are updated in order with respect to
each other but only that all data items are updated before the flag is
updated (usually implemented using FENCE instructions). Relaxed models seek
to capture this increased ordering flexibility and preserve only the orders
that programmers “ <em>require</em> ” to get both higher performance and
correctness of SC. For example, in certain architectures, FIFO write buffers
are used by each core to hold the results of committed (retired) stores
before writing the results to the caches. This optimization enhances
performance but violates SC. The write buffer hides the latency of servicing
a store miss. Because stores are common, being able to avoid stalling on
most of them is an important benefit. For a single-core processor, a write
buffer can be made architecturally invisible by ensuring that a load to
address A returns the value of the most recent store to A even if one or
more stores to A are in the write buffer. This is typically done by either
bypassing the value of the most recent store to A to the load from A, where
“most recent” is determined by program order, or by stalling a load of A if
a store to A is in the write buffer. When multiple cores are used, each will
have its own bypassing write buffer. Without write buffers, the hardware is
SC, but with write buffers, it is not, making write buffers architecturally
visible in a multicore processor.</p>
<p>Store-store reordering may happen if a core has a non-FIFO write buffer that
lets stores depart in a different order than the order in which they
entered. This might occur if the first store misses in the cache while the
second hits or if the second store can coalesce with an earlier store (i.e.,
before the first store). Load-load reordering may also happen on
dynamically-scheduled cores that execute instructions out of program order.
That can behave the same as reordering stores on another core (Can you come
up with an example interleaving between two threads?). Reordering an earlier
load with a later store (a load-store reordering) can cause many incorrect
behaviors, such as loading a value after releasing the lock that protects it
(if the store is the unlock operation). Note that store-load reorderings may
also arise due to local bypassing in the commonly implemented FIFO write
buffer, even with a core that executes all instructions in program order.</p>
</blockquote>
<p>Because cache coherence and memory consistency are sometimes confused, it is
instructive to also have this quote:</p>
<blockquote>
<p>Unlike consistency, <em><strong>cache coherence</strong></em> is neither visible to software nor
required. Coherence seeks to make the caches of a shared-memory system as
functionally invisible as the caches in a single-core system. Correct
coherence ensures that a programmer cannot determine whether and where a
system has caches by analyzing the results of loads and stores. This is
because correct coherence ensures that the caches never enable new or
different <em><strong>functional</strong></em> behavior (programmers may still be able to infer
likely cache structure using <em><strong>timing</strong></em> information). The main purpose of
cache coherence protocols is maintaining the single-writer-multiple-readers
(SWMR) invariant for every memory location. An important distinction between
coherence and consistency is that coherence is specified on a <em><strong>per-memory
location basis</strong></em> , whereas consistency is specified with respect to
<em><strong>all</strong></em> memory locations.</p>
</blockquote>
<p>Continuing with our mental picture, the SWMR invariant corresponds to the
physical requirement that there be at most one particle located at any one
location but there can be an unlimited number of observers of any location.</p>
    </div>
    <aside class="postpromonav"><nav><ul itemprop="keywords" class="tags">
<li><a class="tag p-category" href="../../categories/c%2B%2B/" rel="tag">c++</a></li>
            <li><a class="tag p-category" href="../../categories/c%2B%2B11/" rel="tag">c++11</a></li>
            <li><a class="tag p-category" href="../../categories/language-lawyer/" rel="tag">language-lawyer</a></li>
            <li><a class="tag p-category" href="../../categories/memory-model/" rel="tag">memory-model</a></li>
            <li><a class="tag p-category" href="../../categories/multithreading/" rel="tag">multithreading</a></li>
        </ul>
<ul class="pager hidden-print">
<li class="previous">
                <a href="../how-can-i-see-the-changes-in-a-git-commit/" rel="prev" title="How can I see the changes in a Git commit?">Previous post</a>
            </li>
            <li class="next">
                <a href="../how-to-remove-an-element-from-a-list-by-index/" rel="next" title="How to remove an element from a list by index">Next post</a>
            </li>
        </ul></nav></aside></article>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2023         Go to StackOverflow Chinese Site  <a href="http://stackoverflow.ink">StackOverflow中文网</a>  
            
        </footer>
</div>
</div>


            <script src="../../assets/js/all-nocdn.js"></script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script><script src="../../assets/js/search.js"></script>
</body>
</html>
