<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Is floating point math broken? | StackOverflow Snapshot</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="canonical" href="https://ohstackoverflow.netlify.app/posts/is-floating-point-math-broken/">
<!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><meta name="author" content="Arya">
<link rel="prev" href="../why-is-char-preferred-over-string-for-passwords/" title="Why is char[] preferred over String for passwords?" type="text/html">
<link rel="next" href="../how-to-iterate-over-rows-in-a-dataframe-in-pandas/" title="How to iterate over rows in a DataFrame in Pandas" type="text/html">
<meta property="og:site_name" content="StackOverflow Snapshot">
<meta property="og:title" content="Is floating point math broken?">
<meta property="og:url" content="https://ohstackoverflow.netlify.app/posts/is-floating-point-math-broken/">
<meta property="og:description" content="Consider the following code:
0.1 + 0.2 == 0.3  -&gt;  false



0.1 + 0.2         -&gt;  0.30000000000000004


Why do these inaccuracies happen?

Answer
Binary floating point math is like this. In most progr">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2023-02-16T19:21:03+08:00">
<meta property="article:tag" content="floating-accuracy">
<meta property="article:tag" content="floating-point">
<meta property="article:tag" content="language-agnostic">
<meta property="article:tag" content="math">
<meta property="article:tag" content="precision">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://ohstackoverflow.netlify.app/">

                <span id="blog-title">StackOverflow Snapshot</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="../../archive.html">Archive</a>
                </li>
<li>
<a href="../../categories/">Tags</a>

                
            </li>
</ul>
<ul class="nav navbar-nav navbar-right">
<div style="display:table;min-height:5rem;min-width:27rem;">
					<div class="input-group" style="display: table-cell;vertical-align: middle;">
						<input id="words" type="text" class="form-control" style="max-width:22rem;" onkeydown="if(event.keyCode==13){btn.click()}"><span class="input-group-btn" style="float:left">
							<button id="btn" class="btn btn-default" type="button" data-toggle="modal" data-target="#myModal">
								<span class="glyphicon glyphicon-search">
							</span></button>
						</span>
					</div>
<!-- /input-group -->
				</div>

				
                
                
                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><!-- 模态框（Modal） --><div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true">
	<div class="modal-dialog">
		<div class="modal-content">
			<div class="modal-header">
				<button type="button" class="close" data-dismiss="modal" aria-hidden="true">×
				</button>
				<h4 class="modal-title" id="myModalLabel">
					查找结果
				</h4>
			</div>
			<div class="modal-body">
				<div id="search-count" style="min-height:4rem;">
				查找中，请稍后...
				</div>
				<div id="search-result">
				</div>

				
			</div>
			<div class="modal-footer">
				<button type="button" class="btn btn-default" data-dismiss="modal">
					关闭
				</button>
			</div>
		</div>
<!-- /.modal-content -->
	</div>
<!-- /.modal-dialog -->
</div>
<!-- /.modal -->

<div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">Is floating point math broken?</a></h1>

        <div class="metadata">
            <p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">
                    <a class="u-url" href="../../authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="." rel="bookmark">
            <time class="published dt-published" datetime="2023-02-16T19:21:03+08:00" itemprop="datePublished" title="2023-02-16 19:21">2023-02-16 19:21</time></a>
            </p>
            

        </div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <p>Consider the following code:</p>
<div class="code"><pre class="code literal-block"><span class="mf">0.1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mf">0.2</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="mf">0.3</span><span class="w">  </span><span class="o">-&gt;</span><span class="w">  </span><span class="n">false</span>



<span class="mf">0.1</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mf">0.2</span><span class="w">         </span><span class="o">-&gt;</span><span class="w">  </span><span class="mf">0.30000000000000004</span>
</pre></div>

<p>Why do these inaccuracies happen?</p>
<p><br><br></p>
<h2>Answer</h2>
<p>Binary floating point math is like this. In most programming languages, it is
based on the IEEE 754 standard. The crux of the problem is that numbers are
represented in this format as a whole number times a power of two; rational
numbers (such as <code>0.1</code>, which is <code>1/10</code>) whose denominator is not a power of
two cannot be exactly represented.</p>
<p>For <code>0.1</code> in the standard <code>binary64</code> format, the representation can be written
exactly as</p>
<ul>
<li>
<code>0.1000000000000000055511151231257827021181583404541015625</code> in decimal, or</li>
<li>
<code>0x1.999999999999ap-4</code> in C99 hexfloat notation.</li>
</ul>
<p>In contrast, the rational number <code>0.1</code>, which is <code>1/10</code>, can be written
exactly as</p>
<ul>
<li>
<code>0.1</code> in decimal, or</li>
<li>
<code>0x1.99999999999999...p-4</code> in an analogue of C99 hexfloat notation, where the <code>...</code> represents an unending sequence of 9's.</li>
</ul>
<p>The constants <code>0.2</code> and <code>0.3</code> in your program will also be approximations to
their true values. It happens that the closest <code>double</code> to <code>0.2</code> is larger
than the rational number <code>0.2</code> but that the closest <code>double</code> to <code>0.3</code> is
smaller than the rational number <code>0.3</code>. The sum of <code>0.1</code> and <code>0.2</code> winds up
being larger than the rational number <code>0.3</code> and hence disagreeing with the
constant in your code.</p>
<p>A fairly comprehensive treatment of floating-point arithmetic issues is <em>What
Every Computer Scientist Should Know About Floating-Point Arithmetic</em>. For an
easier-to-digest explanation, see floating-point-gui.de.</p>
<blockquote>
<p><strong>Side Note: All positional (base-N) number systems share this problem with
precision</strong></p>
</blockquote>
<p>Plain old decimal (base 10) numbers have the same issues, which is why numbers
like 1/3 end up as 0.333333333...</p>
<p>You've just stumbled on a number (3/10) that happens to be easy to represent
with the decimal system, but doesn't fit the binary system. It goes both ways
(to some small degree) as well: 1/16 is an ugly number in decimal (0.0625),
but in binary it looks as neat as a 10,000th does in decimal (0.0001)** - if
we were in the habit of using a base-2 number system in our daily lives, you'd
even look at that number and instinctively understand you could arrive there
by halving something, halving it again, and again and again.</p>
<p>Of course, that's not exactly how floating-point numbers are stored in memory
(they use a form of scientific notation). However, it does illustrate the
point that binary floating-point precision errors tend to crop up because the
"real world" numbers we are usually interested in working with are so often
powers of ten - but only because we use a decimal number system day-to-day.
This is also why we'll say things like 71% instead of "5 out of every 7" (71%
is an approximation, since 5/7 can't be represented exactly with any decimal
number).</p>
<p>So no: binary floating point numbers are not broken, they just happen to be as
imperfect as every other base-N number system :)</p>
<blockquote>
<p><strong>Side Side Note: Working with Floats in Programming</strong></p>
</blockquote>
<p>In practice, this problem of precision means you need to use rounding
functions to round your floating point numbers off to however many decimal
places you're interested in before you display them.</p>
<p>You also need to replace equality tests with comparisons that allow some
amount of tolerance, which means:</p>
<p>Do <strong>not</strong> do <code>if (x == y) { ... }</code></p>
<p>Instead do <code>if (abs(x - y) &lt; myToleranceValue) { ... }</code>.</p>
<p>where <code>abs</code> is the absolute value. <code>myToleranceValue</code> needs to be chosen for
your particular application - and it will have a lot to do with how much
"wiggle room" you are prepared to allow, and what the largest number you are
going to be comparing may be (due to loss of precision issues). Beware of
"epsilon" style constants in your language of choice. These <strong>can</strong> be used as
tolerance values but their effectiveness depends on the magnitude (size) of
the numbers you're working with, since calculations with large numbers may
exceed the epsilon threshold.</p>
<p><br></p>
<h3>Suggest</h3>
<h2><strong>A Hardware Designer's Perspective</strong></h2>
<p>I believe I should add a hardware designer’s perspective to this since I
design and build floating point hardware. Knowing the origin of the error may
help in understanding what is happening in the software, and ultimately, I
hope this helps explain the reasons for why floating point errors happen and
seem to accumulate over time.</p>
<h3>1. Overview</h3>
<p>From an engineering perspective, most floating point operations will have some
element of error since the hardware that does the floating point computations
is only required to have an error of less than one half of one unit in the
last place. Therefore, much hardware will stop at a precision that's only
necessary to yield an error of less than one half of one unit in the last
place for a <em>single operation</em> which is especially problematic in floating
point division. What constitutes a single operation depends upon how many
operands the unit takes. For most, it is two, but some units take 3 or more
operands. Because of this, there is no guarantee that repeated operations will
result in a desirable error since the errors add up over time.</p>
<h3>2. Standards</h3>
<p>Most processors follow the IEEE-754 standard but some use denormalized, or
different standards . For example, there is a denormalized mode in IEEE-754
which allows representation of very small floating point numbers at the
expense of precision. The following, however, will cover the normalized mode
of IEEE-754 which is the typical mode of operation.</p>
<p>In the IEEE-754 standard, hardware designers are allowed any value of
error/epsilon as long as it's less than one half of one unit in the last
place, and the result only has to be less than one half of one unit in the
last place for one operation. This explains why when there are repeated
operations, the errors add up. For IEEE-754 double precision, this is the 54th
bit, since 53 bits are used to represent the numeric part (normalized), also
called the mantissa, of the floating point number (e.g. the 5.3 in 5.3e5). The
next sections go into more detail on the causes of hardware error on various
floating point operations.</p>
<h3>3. Cause of Rounding Error in Division</h3>
<p>The main cause of the error in floating point division is the division
algorithms used to calculate the quotient. Most computer systems calculate
division using multiplication by an inverse, mainly in <code>Z=X/Y</code>, <code>Z = X *
(1/Y)</code>. A division is computed iteratively i.e. each cycle computes some bits
of the quotient until the desired precision is reached, which for IEEE-754 is
anything with an error of less than one unit in the last place. The table of
reciprocals of Y (1/Y) is known as the quotient selection table (QST) in the
slow division, and the size in bits of the quotient selection table is usually
the width of the radix, or a number of bits of the quotient computed in each
iteration, plus a few guard bits. For the IEEE-754 standard, double precision
(64-bit), it would be the size of the radix of the divider, plus a few guard
bits k, where <code>k&gt;=2</code>. So for example, a typical Quotient Selection Table for a
divider that computes 2 bits of the quotient at a time (radix 4) would be
<code>2+2= 4</code> bits (plus a few optional bits).</p>
<p><strong>3.1 Division Rounding Error: Approximation of Reciprocal</strong></p>
<p>What reciprocals are in the quotient selection table depend on the division
method: slow division such as SRT division, or fast division such as
Goldschmidt division; each entry is modified according to the division
algorithm in an attempt to yield the lowest possible error. In any case,
though, all reciprocals are <em>approximations</em> of the actual reciprocal and
introduce some element of error. Both slow division and fast division methods
calculate the quotient iteratively, i.e. some number of bits of the quotient
are calculated each step, then the result is subtracted from the dividend, and
the divider repeats the steps until the error is less than one half of one
unit in the last place. Slow division methods calculate a fixed number of
digits of the quotient in each step and are usually less expensive to build,
and fast division methods calculate a variable number of digits per step and
are usually more expensive to build. The most important part of the division
methods is that most of them rely upon repeated multiplication by an
<em>approximation</em> of a reciprocal, so they are prone to error.</p>
<h3>4. Rounding Errors in Other Operations: Truncation</h3>
<p>Another cause of the rounding errors in all operations are the different modes
of truncation of the final answer that IEEE-754 allows. There's truncate,
round-towards-zero, round-to-nearest (default), round-down, and round-up. All
methods introduce an element of error of less than one unit in the last place
for a single operation. Over time and repeated operations, truncation also
adds cumulatively to the resultant error. This truncation error is especially
problematic in exponentiation, which involves some form of repeated
multiplication.</p>
<h3>5. Repeated Operations</h3>
<p>Since the hardware that does the floating point calculations only needs to
yield a result with an error of less than one half of one unit in the last
place for a single operation, the error will grow over repeated operations if
not watched. This is the reason that in computations that require a bounded
error, mathematicians use methods such as using the round-to-nearest even
digit in the last place of IEEE-754, because, over time, the errors are more
likely to cancel each other out, and Interval Arithmetic combined with
variations of the IEEE 754 rounding modes to predict rounding errors, and
correct them. Because of its low relative error compared to other rounding
modes, round to nearest even digit (in the last place), is the default
rounding mode of IEEE-754.</p>
<p>Note that the default rounding mode, round-to-nearest even digit in the last
place, guarantees an error of less than one half of one unit in the last place
for one operation. Using the truncation, round-up, and round down alone may
result in an error that is greater than one half of one unit in the last
place, but less than one unit in the last place, so these modes are not
recommended unless they are used in Interval Arithmetic.</p>
<h3>6. Summary</h3>
<p>In short, the fundamental reason for the errors in floating point operations
is a combination of the truncation in hardware, and the truncation of a
reciprocal in the case of division. Since the IEEE-754 standard only requires
an error of less than one half of one unit in the last place for a single
operation, the floating point errors over repeated operations will add up
unless corrected.</p>
    </div>
    <aside class="postpromonav"><nav><ul itemprop="keywords" class="tags">
<li><a class="tag p-category" href="../../categories/floating-accuracy/" rel="tag">floating-accuracy</a></li>
            <li><a class="tag p-category" href="../../categories/floating-point/" rel="tag">floating-point</a></li>
            <li><a class="tag p-category" href="../../categories/language-agnostic/" rel="tag">language-agnostic</a></li>
            <li><a class="tag p-category" href="../../categories/math/" rel="tag">math</a></li>
            <li><a class="tag p-category" href="../../categories/precision/" rel="tag">precision</a></li>
        </ul>
<ul class="pager hidden-print">
<li class="previous">
                <a href="../why-is-char-preferred-over-string-for-passwords/" rel="prev" title="Why is char[] preferred over String for passwords?">Previous post</a>
            </li>
            <li class="next">
                <a href="../how-to-iterate-over-rows-in-a-dataframe-in-pandas/" rel="next" title="How to iterate over rows in a DataFrame in Pandas">Next post</a>
            </li>
        </ul></nav></aside></article>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2023         Go to StackOverflow Chinese Site  <a href="http://stackoverflow.ink">StackOverflow中文网</a>  
            
        </footer>
</div>
</div>


            <script src="../../assets/js/all-nocdn.js"></script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script><script src="../../assets/js/search.js"></script>
</body>
</html>
