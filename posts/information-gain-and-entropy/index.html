<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Information Gain and Entropy | StackOverflow Snapshot</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="canonical" href="https://ohstackoverflow.netlify.app/posts/information-gain-and-entropy/">
<!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><meta name="author" content="Arya">
<link rel="prev" href="../help-100-accuracy-with-libsvm/" title="Help--100% accuracy with LibSVM?" type="text/html">
<link rel="next" href="../what-is-the-coolest-ai-project-you-ve-heard-of/" title="What is the coolest AI project you've heard of?" type="text/html">
<meta property="og:site_name" content="StackOverflow Snapshot">
<meta property="og:title" content="Information Gain and Entropy">
<meta property="og:url" content="https://ohstackoverflow.netlify.app/posts/information-gain-and-entropy/">
<meta property="og:description" content="I recently read this question regarding information gain and entropy. I think
I have a semi-decent grasp on the main idea, but I'm curious as what to do
with situations such as follows:
If we have a b">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2023-02-28T03:20:45+08:00">
<meta property="article:tag" content="artificial-intelligence">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://ohstackoverflow.netlify.app/">

                <span id="blog-title">StackOverflow Snapshot</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="../../archive.html">Archive</a>
                </li>
<li>
<a href="../../categories/">Tags</a>

                
            </li>
</ul>
<ul class="nav navbar-nav navbar-right">
<div style="display:table;min-height:5rem;min-width:27rem;">
					<div class="input-group" style="display: table-cell;vertical-align: middle;">
						<input id="words" type="text" class="form-control" style="max-width:22rem;" onkeydown="if(event.keyCode==13){btn.click()}"><span class="input-group-btn" style="float:left">
							<button id="btn" class="btn btn-default" type="button" data-toggle="modal" data-target="#myModal">
								<span class="glyphicon glyphicon-search">
							</span></button>
						</span>
					</div>
<!-- /input-group -->
				</div>

				
                
                
                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><!-- 模态框（Modal） --><div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true">
	<div class="modal-dialog">
		<div class="modal-content">
			<div class="modal-header">
				<button type="button" class="close" data-dismiss="modal" aria-hidden="true">×
				</button>
				<h4 class="modal-title" id="myModalLabel">
					查找结果
				</h4>
			</div>
			<div class="modal-body">
				<div id="search-count" style="min-height:4rem;">
				查找中，请稍后...
				</div>
				<div id="search-result">
				</div>

				
			</div>
			<div class="modal-footer">
				<button type="button" class="btn btn-default" data-dismiss="modal">
					关闭
				</button>
			</div>
		</div>
<!-- /.modal-content -->
	</div>
<!-- /.modal-dialog -->
</div>
<!-- /.modal -->

<div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">Information Gain and Entropy</a></h1>

        <div class="metadata">
            <p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">
                    <a class="u-url" href="../../authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="." rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T03:20:45+08:00" itemprop="datePublished" title="2023-02-28 03:20">2023-02-28 03:20</time></a>
            </p>
            

        </div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <p>I recently read this question regarding information gain and entropy. I think
I have a semi-decent grasp on the main idea, but I'm curious as what to do
with situations such as follows:</p>
<p>If we have a bag of 7 coins, 1 of which is heavier than the others, and 1 of
which is lighter than the others, and we know the heavier coin + the lighter
coin is the same as 2 normal coins, what is the information gain associated
with picking two random coins and weighing them against each other?</p>
<p>Our goal here is to identify the two odd coins. I've been thinking this
problem over for a while, and can't frame it correctly in a decision tree, or
any other way for that matter. Any help?</p>
<p>EDIT: I understand the formula for entropy and the formula for information
gain. What I don't understand is how to frame this problem in a decision tree
format.</p>
<p>EDIT 2: Here is where I'm at so far:</p>
<p>Assuming we pick two coins and they both end up weighing the same, we can
assume our new chances of picking H+L come out to 1/5 * 1/4 = 1/20 , easy
enough.</p>
<p>Assuming we pick two coins and the left side is heavier. There are three
different cases where this can occur:</p>
<p>HM: Which gives us 1/2 chance of picking H and a 1/4 chance of picking L: 1/8
HL: 1/2 chance of picking high, 1/1 chance of picking low: 1/1 ML: 1/2 chance
of picking low, 1/4 chance of picking high: 1/8</p>
<p>However, the odds of us picking HM are 1/7 * 5/6 which is 5/42<br>
The odds of us picking HL are 1/7 * 1/6 which is 1/42<br>
And the odds of us picking ML are 1/7 * 5/6 which is 5/42</p>
<p>If we weight the overall probabilities with these odds, we are given:</p>
<p>(1/8) * (5/42) + (1/1) * (1/42) + (1/8) * (5/42) = 3/56.</p>
<p>The same holds true for option B.</p>
<p>option A = 3/56<br>
option B = 3/56<br>
option C = 1/20</p>
<p>However, option C should be weighted heavier because there is a 5/7 * 4/6
chance to pick two mediums. So I'm assuming from here I weight THOSE odds.</p>
<p>I am pretty sure I've messed up somewhere along the way, but I think I'm on
the right path!</p>
<p>EDIT 3: More stuff.</p>
<p>Assuming the scale is unbalanced, the odds are (10/11) that only one of the
coins is the H or L coin, and (1/11) that both coins are H/L</p>
<p>Therefore we can conclude:<br>
(10 / 11) * (1/2 * 1/5) and<br>
(1 / 11) * (1/2)</p>
<p>EDIT 4: Going to go ahead and say that it is a total 4/42 increase.</p>
<p><br><br></p>
<h2>Answer</h2>
<p>You can construct a decision tree from information-gain considerations, but
that's not the question you posted, which is only the compute the information
gain (presumably the <em>expected</em> information gain;-) from one "information
extraction move" -- picking two random coins and weighing them against each
other. To construct the decision tree, you need to know what moves are
affordable from the initial state (presumably the general rule is: you can
pick two sets of N coins, N &lt; 4, and weigh them against each other -- and
that's the only kind of move, parametric over N), the expected information
gain from each, and that gives you the first leg of the decision tree (the
move with highest expected information gain); then you do the same process for
each of the possible results of that move, and so on down.</p>
<p>So do you need help to compute that expected information gain for each of the
three allowable values of N, only for N==1, or can you try doing it yourself?
If the third possibility obtains, then that would maximize the amount of
learning you get from the exercise -- which after all IS the key purpose of
homework. So why don't you try, edit your answer to show you how you proceeded
and what you got, and we'll be happy to confirm you got it right, or try and
help correct any misunderstanding your procedure might reveal!</p>
<p><strong>Edit</strong> : trying to give some hints rather than serving the OP the ready-
cooked solution on a platter;-). Call the coins H (for heavy), L (for light),
and M (for medium -- five of those). When you pick 2 coins at random you can
get (out of <code>7 * 6 == 42</code> possibilities including order) HL, LH (one each),
HM, MH, LM, ML (5 each), MM (<code>5 * 4 == 20</code> cases) -- 2 plus 20 plus 20 is 42,
check. In the weighting you get 3 possible results, call them A (left
heavier), B (right heavier), C (equal weight). HL, HM, and ML, 11 cases, will
be A; LH, MH, and LM, 11 cases, will be B; MM, 20 cases, will be C. So A and B
aren't really distinguishable (which one is left, which one is right, is
basically arbitrary!), so we have 22 cases where the weight will be different,
20 where they will be equal -- it's a good sign that the cases giving each
results are in pretty close numbers!</p>
<p>So now consider how many (equiprobable) possibilities existed a priori, how
many a posteriori, for each of the experiment's results. You're tasked to pick
the H and L choice. If you did it at random before the experiment, what would
be you chances? 1 in 7 for the random pick of the H; given that succeeds 1 in
6 for the pick of the L -- overall 1 in 42.</p>
<p>After the experiment, how are you doing? If C, you can rule out those two
coins and you're left with a mystery H, a mystery L, and three Ms -- so if you
picked at random you'd have 1 in 5 to pick H, if successful 1 in 4 to pick L,
overall 1 in 20 -- your success chances have slightly more than doubled. It's
trickier to see "what next" for the A (and equivalently B) cases because
they're several, as listed above (and, less obviously, not equiprobable...),
but obviously you won't pick the known-lighter coin for H (and viceversa) and
if you pick one of the 5 unweighed coins for H (or L) only one of the weighed
coins is a candidate for the other role (L or H respectively). Ignoring for
simplicity the "non equiprobable" issue (which is really kind of tricky) can
you compute what your chances of guessing (with a random pick not inconsistent
with the experiment's result) would be...?</p>
    </div>
    <aside class="postpromonav"><nav><ul itemprop="keywords" class="tags">
<li><a class="tag p-category" href="../../categories/artificial-intelligence/" rel="tag">artificial-intelligence</a></li>
        </ul>
<ul class="pager hidden-print">
<li class="previous">
                <a href="../help-100-accuracy-with-libsvm/" rel="prev" title="Help--100% accuracy with LibSVM?">Previous post</a>
            </li>
            <li class="next">
                <a href="../what-is-the-coolest-ai-project-you-ve-heard-of/" rel="next" title="What is the coolest AI project you've heard of?">Next post</a>
            </li>
        </ul></nav></aside></article>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2023         Go to StackOverflow Chinese Site  <a href="http://stackoverflow.ink">StackOverflow中文网</a>  
            
        </footer>
</div>
</div>


            <script src="../../assets/js/all-nocdn.js"></script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script><script src="../../assets/js/search.js"></script>
</body>
</html>
