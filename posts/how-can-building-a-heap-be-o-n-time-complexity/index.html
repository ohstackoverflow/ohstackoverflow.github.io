<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>How can building a heap be O(n) time complexity? | StackOverflow Snapshot</title>
<link href="../../assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="canonical" href="https://ohstackoverflow.netlify.app/posts/how-can-building-a-heap-be-o-n-time-complexity/">
<!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><meta name="author" content="Arya">
<link rel="prev" href="../how-to-define-a-circle-shape-in-an-android-xml-drawable-file/" title="How to define a circle shape in an Android XML drawable file?" type="text/html">
<link rel="next" href="../how-to-truncate-a-foreign-key-constrained-table/" title="How to truncate a foreign key constrained table?" type="text/html">
<meta property="og:site_name" content="StackOverflow Snapshot">
<meta property="og:title" content="How can building a heap be O(n) time complexity?">
<meta property="og:url" content="https://ohstackoverflow.netlify.app/posts/how-can-building-a-heap-be-o-n-time-complexity/">
<meta property="og:description" content="Can someone help explain how can building a heap be O(n) complexity?
Inserting an item into a heap is O(log n) , and the insert is repeated n/2
times (the remainder are leaves, and can't violate the h">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2023-02-17T12:36:07+08:00">
<meta property="article:tag" content="algorithm">
<meta property="article:tag" content="big-o">
<meta property="article:tag" content="complexity-theory">
<meta property="article:tag" content="construction">
<meta property="article:tag" content="heap">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://ohstackoverflow.netlify.app/">

                <span id="blog-title">StackOverflow Snapshot</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="../../archive.html">Archive</a>
                </li>
<li>
<a href="../../categories/">Tags</a>

                
            </li>
</ul>
<ul class="nav navbar-nav navbar-right">
<div style="display:table;min-height:5rem;min-width:27rem;">
					<div class="input-group" style="display: table-cell;vertical-align: middle;">
						<input id="words" type="text" class="form-control" style="max-width:22rem;" onkeydown="if(event.keyCode==13){btn.click()}"><span class="input-group-btn" style="float:left">
							<button id="btn" class="btn btn-default" type="button" data-toggle="modal" data-target="#myModal">
								<span class="glyphicon glyphicon-search">
							</span></button>
						</span>
					</div>
<!-- /input-group -->
				</div>

				
                
                
                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><!-- 模态框（Modal） --><div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true">
	<div class="modal-dialog">
		<div class="modal-content">
			<div class="modal-header">
				<button type="button" class="close" data-dismiss="modal" aria-hidden="true">×
				</button>
				<h4 class="modal-title" id="myModalLabel">
					查找结果
				</h4>
			</div>
			<div class="modal-body">
				<div id="search-count" style="min-height:4rem;">
				查找中，请稍后...
				</div>
				<div id="search-result">
				</div>

				
			</div>
			<div class="modal-footer">
				<button type="button" class="btn btn-default" data-dismiss="modal">
					关闭
				</button>
			</div>
		</div>
<!-- /.modal-content -->
	</div>
<!-- /.modal-dialog -->
</div>
<!-- /.modal -->

<div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">How can building a heap be O(n) time complexity?</a></h1>

        <div class="metadata">
            <p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">
                    <a class="u-url" href="../../authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="." rel="bookmark">
            <time class="published dt-published" datetime="2023-02-17T12:36:07+08:00" itemprop="datePublished" title="2023-02-17 12:36">2023-02-17 12:36</time></a>
            </p>
            

        </div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <p>Can someone help explain how can building a heap be <em>O(n)</em> complexity?</p>
<p>Inserting an item into a heap is <em>O(log n)</em> , and the insert is repeated n/2
times (the remainder are leaves, and can't violate the heap property). So,
this means the complexity should be <em>O(n log n)</em> , I would think.</p>
<p>In other words, for each item we "heapify", it has the potential to have to
filter down (i.e., sift down) once for each level for the heap so far (which
is <em>log n</em> levels).</p>
<p>What am I missing?</p>
<p><br><br></p>
<h2>Answer</h2>
<p>I think there are several questions buried in this topic:</p>
<ul>
<li>How do you implement <code>buildHeap</code> so it runs in <em>O(n)</em> time?</li>
<li>How do you show that <code>buildHeap</code> runs in <em>O(n)</em> time when implemented correctly?</li>
<li>Why doesn't that same logic work to make heap sort run in <em>O(n)</em> time rather than <em>O(n log n)</em>?</li>
</ul>
<h3>How do you implement <code>buildHeap</code> so it runs in <em>O(n)</em> time?</h3>
<p>Often, answers to these questions focus on the difference between <code>siftUp</code> and
<code>siftDown</code>. Making the correct choice between <code>siftUp</code> and <code>siftDown</code> is
critical to get <em>O(n)</em> performance for <code>buildHeap</code>, but does nothing to help
one understand the difference between <code>buildHeap</code> and <code>heapSort</code> in general.
Indeed, proper implementations of both <code>buildHeap</code> and <code>heapSort</code> will
<strong>only</strong> use <code>siftDown</code>. The <code>siftUp</code> operation is only needed to perform
inserts into an existing heap, so it would be used to implement a priority
queue using a binary heap, for example.</p>
<p>I've written this to describe how a max heap works. This is the type of heap
typically used for heap sort or for a priority queue where higher values
indicate higher priority. A min heap is also useful; for example, when
retrieving items with integer keys in ascending order or strings in
alphabetical order. The principles are exactly the same; simply switch the
sort order.</p>
<p>The <strong>heap property</strong> specifies that each node in a binary heap must be at
least as large as both of its children. In particular, this implies that the
largest item in the heap is at the root. Sifting down and sifting up are
essentially the same operation in opposite directions: move an offending node
until it satisfies the heap property:</p>
<ul>
<li>
<code>siftDown</code> swaps a node that is too small with its largest child (thereby moving it down) until it is at least as large as both nodes below it.</li>
<li>
<code>siftUp</code> swaps a node that is too large with its parent (thereby moving it up) until it is no larger than the node above it.</li>
</ul>
<p>The number of operations required for <code>siftDown</code> and <code>siftUp</code> is proportional
to the distance the node may have to move. For <code>siftDown</code>, it is the distance
to the bottom of the tree, so <code>siftDown</code> is expensive for nodes at the top of
the tree. With <code>siftUp</code>, the work is proportional to the distance to the top
of the tree, so <code>siftUp</code> is expensive for nodes at the bottom of the tree.
Although both operations are <em>O(log n)</em> in the worst case, in a heap, only one
node is at the top whereas half the nodes lie in the bottom layer. So <strong>it
shouldn't be too surprising that if we have to apply an operation to every
node, we would prefer<code>siftDown</code> over <code>siftUp</code>.</strong></p>
<p>The <code>buildHeap</code> function takes an array of unsorted items and moves them until
they all satisfy the heap property, thereby producing a valid heap. There are
two approaches one might take for <code>buildHeap</code> using the <code>siftUp</code> and
<code>siftDown</code> operations we've described.</p>
<ol>
<li>
<p>Start at the top of the heap (the beginning of the array) and call <code>siftUp</code> on each item. At each step, the previously sifted items (the items before the current item in the array) form a valid heap, and sifting the next item up places it into a valid position in the heap. After sifting up each node, all items satisfy the heap property.</p>
</li>
<li>
<p>Or, go in the opposite direction: start at the end of the array and move backwards towards the front. At each iteration, you sift an item down until it is in the correct location.</p>
</li>
</ol>
<h3>Which implementation for <code>buildHeap</code> is more efficient?</h3>
<p>Both of these solutions will produce a valid heap. Unsurprisingly, the more
efficient one is the second operation that uses <code>siftDown</code>.</p>
<p>Let <em>h = log n</em> represent the height of the heap. The work required for the
<code>siftDown</code> approach is given by the sum</p>
<div class="code"><pre class="code literal-block">(0 * n/2) + (1 * n/4) + (2 * n/8) + ... + (h * 1).
</pre></div>

<p>Each term in the sum has the maximum distance a node at the given height will
have to move (zero for the bottom layer, h for the root) multiplied by the
number of nodes at that height. In contrast, the sum for calling <code>siftUp</code> on
each node is</p>
<div class="code"><pre class="code literal-block">(h * n/2) + ((h-1) * n/4) + ((h-2)*n/8) + ... + (0 * 1).
</pre></div>

<p>It should be clear that the second sum is larger. The first term alone is
<em>hn/2 = 1/2 n log n</em> , so this approach has complexity at best <em>O(n log n)</em>.</p>
<h3>How do we prove the sum for the <code>siftDown</code> approach is indeed <em>O(n)</em>?</h3>
<p>One method (there are other analyses that also work) is to turn the finite sum
into an infinite series and then use Taylor series. We may ignore the first
term, which is zero:</p>
<p><img alt="Taylor series for buildHeap complexity" src="../../images/959f6.png"></p>
<p>If you aren't sure why each of those steps works, here is a justification for
the process in words:</p>
<ul>
<li>The terms are all positive, so the finite sum must be smaller than the infinite sum.</li>
<li>The series is equal to a power series evaluated at <em>x=1/2</em>.</li>
<li>That power series is equal to (a constant times) the derivative of the Taylor series for <em>f(x)=1/(1-x)</em>.</li>
<li>
<em>x=1/2</em> is within the interval of convergence of that Taylor series.</li>
<li>Therefore, we can replace the Taylor series with <em>1/(1-x)</em> , differentiate, and evaluate to find the value of the infinite series.</li>
</ul>
<p>Since the infinite sum is exactly <em>n</em> , we conclude that the finite sum is no
larger, and is therefore, <em>O(n)</em>.</p>
<h3>Why does heap sort require <em>O(n log n)</em> time?</h3>
<p>If it is possible to run <code>buildHeap</code> in linear time, why does heap sort
require <em>O(n log n)</em> time? Well, heap sort consists of two stages. First, we
call <code>buildHeap</code> on the array, which requires <em>O(n)</em> time if implemented
optimally. The next stage is to repeatedly delete the largest item in the heap
and put it at the end of the array. Because we delete an item from the heap,
there is always an open spot just after the end of the heap where we can store
the item. So heap sort achieves a sorted order by successively removing the
next largest item and putting it into the array starting at the last position
and moving towards the front. It is the complexity of this last part that
dominates in heap sort. The loop looks likes this:</p>
<div class="code"><pre class="code literal-block"><span class="k">for</span><span class="w"> </span><span class="p">(</span><span class="n">i</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">n</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="mi">1</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mi">0</span><span class="p">;</span><span class="w"> </span><span class="n">i</span><span class="o">--</span><span class="p">)</span><span class="w"> </span><span class="err">{</span>
<span class="w">    </span><span class="n">arr</span><span class="o">[</span><span class="n">i</span><span class="o">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">deleteMax</span><span class="p">();</span>
<span class="err">}</span>
</pre></div>

<p>Clearly, the loop runs O(n) times ( <em>n - 1</em> to be precise, the last item is
already in place). The complexity of <code>deleteMax</code> for a heap is <em>O(log n)</em>. It
is typically implemented by removing the root (the largest item left in the
heap) and replacing it with the last item in the heap, which is a leaf, and
therefore one of the smallest items. This new root will almost certainly
violate the heap property, so you have to call <code>siftDown</code> until you move it
back into an acceptable position. This also has the effect of moving the next
largest item up to the root. Notice that, in contrast to <code>buildHeap</code> where for
most of the nodes we are calling <code>siftDown</code> from the bottom of the tree, we
are now calling <code>siftDown</code> from the top of the tree on each iteration!
<em>Although the tree is shrinking, it doesn't shrink fast enough</em> : The height
of the tree stays constant until you have removed the first half of the nodes
(when you clear out the bottom layer completely). Then for the next quarter,
the height is <em>h - 1</em>. So the total work for this second stage is</p>
<div class="code"><pre class="code literal-block">h*n/2 + (h-1)*n/4 + ... + 0 * 1.
</pre></div>

<p>Notice the switch: now the zero work case corresponds to a single node and the
<em>h</em> work case corresponds to half the nodes. This sum is <em>O(n log n)</em> just
like the inefficient version of <code>buildHeap</code> that is implemented using siftUp.
But in this case, we have no choice since we are trying to sort and we require
the next largest item be removed next.</p>
<p>In summary, the work for heap sort is the sum of the two stages: <em>O(n) time
for buildHeap and <strong>O(n log n) to remove each node in order</strong> , so the
complexity is O(n log n)</em>. You can prove (using some ideas from information
theory) that for a comparison-based sort, <em>O(n log n)</em> is the best you could
hope for anyway, so there's no reason to be disappointed by this or expect
heap sort to achieve the O(n) time bound that <code>buildHeap</code> does.</p>
<p><br></p>
<h3>Suggest</h3>
<p>Your analysis is correct. However, it is not tight.</p>
<p>It is not really easy to explain why building a heap is a linear operation,
you should better read it.</p>
<p>A <em>great analysis</em> of the algorithm can be seen here.</p>
<hr>
<p>The main idea is that in the <code>build_heap</code> algorithm the actual <code>heapify</code> cost
is not <code>O(log n)</code>for all elements.</p>
<p>When <code>heapify</code> is called, the running time depends on how far an element might
move down in the tree before the process terminates. In other words, it
depends on the height of the element in the heap. In the worst case, the
element might go down all the way to the leaf level.</p>
<p>Let us count the work done level by level.</p>
<p>At the bottommost level, there are <code>2^(h)</code>nodes, but we do not call <code>heapify</code>
on any of these, so the work is 0. At the next level there are <code>2^(h − 1)</code>
nodes, and each might move down by 1 level. At the 3rd level from the bottom,
there are <code>2^(h − 2)</code> nodes, and each might move down by 2 levels.</p>
<p>As you can see not all heapify operations are <code>O(log n)</code>, this is why you are
getting <code>O(n)</code>.</p>
    </div>
    <aside class="postpromonav"><nav><ul itemprop="keywords" class="tags">
<li><a class="tag p-category" href="../../categories/algorithm/" rel="tag">algorithm</a></li>
            <li><a class="tag p-category" href="../../categories/big-o/" rel="tag">big-o</a></li>
            <li><a class="tag p-category" href="../../categories/complexity-theory/" rel="tag">complexity-theory</a></li>
            <li><a class="tag p-category" href="../../categories/construction/" rel="tag">construction</a></li>
            <li><a class="tag p-category" href="../../categories/heap/" rel="tag">heap</a></li>
        </ul>
<ul class="pager hidden-print">
<li class="previous">
                <a href="../how-to-define-a-circle-shape-in-an-android-xml-drawable-file/" rel="prev" title="How to define a circle shape in an Android XML drawable file?">Previous post</a>
            </li>
            <li class="next">
                <a href="../how-to-truncate-a-foreign-key-constrained-table/" rel="next" title="How to truncate a foreign key constrained table?">Next post</a>
            </li>
        </ul></nav></aside></article>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2023         Go to StackOverflow Chinese Site  <a href="http://stackoverflow.ink">StackOverflow-ZH</a>  
            
        </footer>
</div>
</div>


            <script src="../../assets/js/all-nocdn.js"></script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script><script src="../../assets/js/search.js"></script>
</body>
</html>
