<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="This is a snapshot site for StackOverflow">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>StackOverflow Snapshot (old posts, page 1365) | StackOverflow Snapshot</title>
<link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="canonical" href="https://ohstackoverflow.netlify.app/index-1365.html">
<link rel="prev" href="index-1366.html" type="text/html">
<link rel="next" href="index-1364.html" type="text/html">
<!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]-->
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://ohstackoverflow.netlify.app/">

                <span id="blog-title">StackOverflow Snapshot</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="archive.html">Archive</a>
                </li>
<li>
<a href="categories/">Tags</a>

                
            </li>
</ul>
<ul class="nav navbar-nav navbar-right">
<div style="display:table;min-height:5rem;min-width:27rem;">
					<div class="input-group" style="display: table-cell;vertical-align: middle;">
						<input id="words" type="text" class="form-control" style="max-width:22rem;" onkeydown="if(event.keyCode==13){btn.click()}"><span class="input-group-btn" style="float:left">
							<button id="btn" class="btn btn-default" type="button" data-toggle="modal" data-target="#myModal">
								<span class="glyphicon glyphicon-search">
							</span></button>
						</span>
					</div>
<!-- /input-group -->
				</div>

				
                
                
                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><!-- 模态框（Modal） --><div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true">
	<div class="modal-dialog">
		<div class="modal-content">
			<div class="modal-header">
				<button type="button" class="close" data-dismiss="modal" aria-hidden="true">×
				</button>
				<h4 class="modal-title" id="myModalLabel">
					查找结果
				</h4>
			</div>
			<div class="modal-body">
				<div id="search-count" style="min-height:4rem;">
				查找中，请稍后...
				</div>
				<div id="search-result">
				</div>

				
			</div>
			<div class="modal-footer">
				<button type="button" class="btn btn-default" data-dismiss="modal">
					关闭
				</button>
			</div>
		</div>
<!-- /.modal-content -->
	</div>
<!-- /.modal-dialog -->
</div>
<!-- /.modal -->

<div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            

    


    
<div class="postindex">
    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/why-is-weight-vector-orthogonal-to-decision-plane-in-neural-networks/" class="u-url">Why is weight vector orthogonal to decision plane in neural networks</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="posts/why-is-weight-vector-orthogonal-to-decision-plane-in-neural-networks/" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T02:31:18+08:00" itemprop="datePublished" title="2023-02-28 02:31">2023-02-28 02:31</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>I am beginner in neural networks. I am learning about perceptrons. My question
is Why is weight vector perpendicular to decision boundary(Hyperplane)? I
referred many books but all are mentioning that weight vector is perpendicular
to decision boundary but none are saying why?</p>
<p>Can anyone give me an explanation or reference to a book?</p>
<p><br><br></p>
<h2>Answer</h2>
<p>The weights are simply the coefficients that define a separating plane. For
the moment, forget about neurons and just consider the geometric definition of
a plane in N dimensions:</p>
<div class="code"><pre class="code literal-block">w1*x1 + w2*x2 + ... + wN*xN - w0 = 0
</pre></div>

<p>You can also think of this as being a dot product:</p>
<div class="code"><pre class="code literal-block">w*x - w0 = 0
</pre></div>

<p>where <code>w</code> and <code>x</code> are both length-N vectors. This equation holds for all
points on the plane. Recall that we can multiply the above equation by a
constant and it still holds so we can define the constants such that the
vector <code>w</code> has unit length. Now, take out a piece of paper and draw your <code>x-y</code>
axes (<code>x1</code> and <code>x2</code> in the above equations). Next, draw a line (a plane in
<code>2D</code>) somewhere near the origin. <code>w0</code> is simply the perpendicular distance
from the origin to the plane and <code>w</code> is the unit vector that points from the
origin along that perpendicular. If you now draw a vector from the origin to
any point on the plane, the dot product of that vector with the unit vector
<code>w</code> will always be equal to <code>w0</code> so the equation above holds, right? This is
simply the geometric definition of a plane: a unit vector defining the
perpendicular to the plane (<code>w</code>) and the distance (<code>w0</code>) from the origin to
the plane.</p>
<p>Now our neuron is simply representing the same plane as described above but we
just describe the variables a little differently. We'll call the components of
<code>x</code> our "inputs", the components of <code>w</code> our "weights", and we'll call the
distance <code>w0</code> a bias. That's all there is to it.</p>
<p>Getting a little beyond your actual question, we don't really care about
points on the plane. We really want to know which side of the plane a point
falls on. While <code>w*x - w0</code> is exactly zero on the plane, it will have positive
values for points on one side of the plane and negative values for points on
the other side. That's where the neuron's activation function comes in but
that's beyond your actual question.</p>
<p><br></p>
<h3>Suggest</h3>
<p>Intuitively, in a binary problem the weight vector points in the direction of
the '1'-class, while the '0'-class is found when pointing away from the weight
vector. The decision boundary should thus be drawn perpendicular to the weight
vector.</p>
<p>See the image for a simplified example: You have a neural network with only 1
input which thus has 1 weight. If the weight is -1 (the blue vector), then all
negative inputs will become positive, so the whole negative spectrum will be
assigned to the '1'-class, while the positive spectrum will be the '0'-class.
The decision boundary in a 2-axis plane is thus a vertical line through the
origin (the red line). Simply said it is the line perpendicular to the weight
vector.</p>
<p>Lets go through this example with a few values. The output of the perceptron
is class 1 if the sum of all <code>inputs * weights</code> is larger than 0 (the default
threshold), otherwise if the output is smaller than the threshold of 0 then
the class is 0. Your input has value 1. The weight applied to this single
input is -1, so <code>1 * -1 = -1</code> which is less than 0. The input is thus assigned
class 0 (NOTE: class 0 and class 1 could have just been called class A or
class B, don't confuse them with the input and weight values). Conversely, if
the input is -1, then <code>input * weight</code> is <code>-1 * -1 = 1</code>, which is larger than
0, so the input is assigned to class 1. If you try every input value then you
will see that all the negative values in this example have an output larger
than 0, so all of them belong to class 1. All positive values will have an
output of smaller than 0 and therefore will be classified as class 0. Draw the
line which separates all positive and negative input values (the red line) and
you will see that this line is perpendicular to the weight vector.</p>
<p>Also note that the weight vector is only used to modify the inputs to fit the
wanted output. What would happen without a weight vector? An input of 1, would
result in an output of 1, which is larger than the threshold of 0, so the
class is '1'.</p>
<p><img alt="image" src="images/DybSR.png"></p>
<p>The second image on this page shows a perceptron with 2 inputs and a bias. The
first input has the same weight as my example, while the second input has a
weight of 1. The corresponding weight vector together with the decision
boundary are thus changed as seen in the image. Also the decision boundary has
been translated to the right due to an added bias of 1.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/what-are-some-impressive-algorithms-or-software-in-the-world-of-ai/" class="u-url">What are some impressive algorithms or software in the world of AI?</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="posts/what-are-some-impressive-algorithms-or-software-in-the-world-of-ai/" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T02:30:56+08:00" itemprop="datePublished" title="2023-02-28 02:30">2023-02-28 02:30</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>I have always loved the idea of AI and evolutionary algorithms. Unfortunately,
as we all know, the field hasn't developed nearly as fast as expected in the
early days.</p>
<p>What I am looking for are some examples that have the "wow" factor:</p>
<ul>
<li>
<p>Self-directed learning systems that adapted in unexpected ways.</p>
</li>
<li>
<p>Game agents that were particularly dynamic and produced unexpected strategies</p>
</li>
<li>
<p>Symbolic representation systems that actually produced some meaningful and insightful output</p>
</li>
<li>
<p>Interesting emergent behavior in multiple agent systems. </p>
</li>
</ul>
<p>Let's not get into the semantics of what defines AI. <em>If it looks or sounds
like AI, let's hear about it</em>.</p>
<p>I'll go first with a story from 1997.</p>
<p><em>Dr. Adrian Thompson is trying to use genetic algorithms to create a voice
recognition circuit in a FPGA. After a few thousand generations, he succeeds
in having the device distinguish between "stop" and "go" voice commands. He
examines the structure of the device and finds that some active logic gates
are disconnected from the rest of the circuit. When he disables these
supposedly useless gates, the circuit stops working...</em></p>
<hr>
<h4>Edit</h4>
<p>Can we try and keep the discussion to techniques/algorithms that produced
something impressive? I can google if I want to read about the thousands of AI
technologies that are <em>in the early stages but showing promise</em>.</p>
<p><br><br></p>
<h2>Answer</h2>
<p>I built an evolutionary algorithm for retail inventory replenishment in a
product targeted at huge plant nurseries (and there are some really big, smart
ones -- $200m companies).</p>
<p>It was probably the coolest thing I've ever worked on. Using three years of
historical data, it crunched and evolved for a week straight while I was on
vacation.</p>
<p>The end results were both positive and bizarre. Actually, I was pretty sure it
was broken at first.</p>
<p>The algorithm was ignoring sales from the previous few weeks, giving them a
weight of 0 for all indicators (which is at odds with how these guys currently
work -- right now they consider the same week in the previous year and also
factor in recent trends).</p>
<p>Eventually I realized what was going on. With the indicators the organism had
to work with, over time it was more efficient to look at the same part of the
previous month and ignore recent trends.</p>
<p>So instead of looking at the last several days, it looked at the same week in
the previous month because there were some subtle but steady trends that
repeat every 30 days. And they were more reliable than the more volatile day-
to-day trends.</p>
<p>And the result was a significant and reproducable improvement in efficiency.</p>
<p>Unfortunately, I was so excited by this that I told the customer about it and
they cancelled the project. That first run was extremely promising, but it was
hard to sell as proof even though you could crunch almost any data from the
last three years and see that the algorithm magically improved efficiency.
EA's are not hard, but people find them convoluted at first, and the idea of
doing something so arcane was just a little bit too much to swallow.</p>
<p>The big takeaway for me was that if I ever create something that appears a bit
too magical, I should hold off on talking about it until I can put together a
good presentation. :)</p>
<p><br></p>
<h3>Suggest</h3>
<p>Some times ago, I've found this series of articles: Designing Emergent AI.</p>
<p>The author of these articles has created the game "AI War: Fleet command" that
features an emergent AI. Maybe you'll find this interesting.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/consistent-and-admissible-heuristics/" class="u-url">Consistent and Admissible Heuristics</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="posts/consistent-and-admissible-heuristics/" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T02:30:36+08:00" itemprop="datePublished" title="2023-02-28 02:30">2023-02-28 02:30</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>Any consistent heuristic is also admissible. But when is a heuristic
admissible but not consistent (monotone)?</p>
<p>Please provide an example in which this is the case.</p>
<p><br><br></p>
<h2>Answer</h2>
<p>As Russel and Norvig point out in <em>Artificial Intelligence: A Modern Approach</em>
(the most commonly used AI textbook) it is challenging to come up with a
heuristic that is admissible but not consistent.</p>
<p>Obviously, you can select values for nodes in a graph such that the heuristic
they represent is admissible but not consistent. This paper by Felner et al
has a nice example of the two ways that this is possible, but it's a little
dense, so I'll summarize:</p>
<p><img alt="An admissible but inconsistent heuristic" src="images/MMEYu.png"></p>
<ul>
<li>This heuristic is inconsistent at <code>c1</code> because it is giving a lower (i.e. less informative) lower bound on the cost to get to the goal than its parent node is. The cost estimate of getting to the goal through the parent node is at least 10 (because the cost of the path to <code>p</code> is 5 and the heuristic estimate at <code>p</code> is also 5). The cost estimate for getting to the goal through <code>c1</code>, however, is just 8 (cost of parent (5), plus cost of path from parent (1), plus heuristic estimate at <code>c1</code> (2)).</li>
<li>Since this graph is undirected, this heuristic is also inconsistent at <code>c2</code>, because going from <code>c2</code> to <code>p</code> has the same problem as above.</li>
</ul>
<p>Felner et al also provide a few concrete examples of an admissible but
inconsistent heuristic. Consider the 8-puzzle problem:</p>
<p><img alt="The 8-puzzle problem" src="images/0lDTV.jpg"></p>
<p>In this puzzle there are 8 sliding tiles numbered 1-8, and one empty space.
The tiles start out out of order (as in the image on the left). The goal is to
get the puzzle into the state shown above on the right exclusively by sliding
tiles into the empty space. The classic heuristic for this problem (Manhattan
distance of each tile to the location where it is supposed to be) is
admissible and consistent.</p>
<p>However, you could come up with a different heuristic. Maybe you just want to
look at Manhattan distance (i.e. the number of squares away) of the 1, the 2,
and the 3 to the locations in which they are supposed to be in the goal state.
The heuristic, while less informative than Manhattan distance of all tiles, is
still admissible and consistent.</p>
<p>But let's say that you choose an additional group of squares, perhaps 5, 6,
and 7. And then let's say that the way you calculate the heuristic at each
node is by randomly selecting one of those sets (1,2, and 3) or (5, 6, and 7)
and computing their Manhattan distance to their goal locations. This heuristic
is <strong>still admissible</strong> - it can only ever underestimate or match the number
of moves needed to get to the goal state. However, it is <strong>no longer
consistent</strong> - there isn't a clear relationship between the heuristic
estimates at each node.</p>
<p><br></p>
<h3>Suggest</h3>
<h4>Admissible heuristic</h4>
<p>never overestimates the cost to reach the goal. f(n) never overestimates the
the cost of a solution along the current path through n. An obvious example of
an admissible heuristic is the straight-line distance.</p>
<h4>Consistency heuristic</h4>
<ul>
<li>Consistent heuristic: for every node n and every successor n' of n generated by any action a: h(n) ≤ c(n,a,n') + h(n')</li>
<li>Required only for applications of A* to graph search</li>
<li>Every consistent heuristic is also admissible.</li>
</ul>
</div>
    </article>
</div>

        <nav class="postindexpager"><ul class="pager">
<li class="previous">
                <a href="index-1366.html" rel="prev">Newer posts</a>
            </li>
            <li class="next">
                <a href="index-1364.html" rel="next">Older posts</a>
            </li>
        </ul></nav>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2023         Go to StackOverflow Chinese Site  <a href="http://stackoverflow.ink">StackOverflow-ZH</a>  
            
        </footer>
</div>
</div>


            <script src="assets/js/all-nocdn.js"></script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script><script src="assets/js/search.js"></script>
</body>
</html>
