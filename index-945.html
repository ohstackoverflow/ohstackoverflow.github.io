<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="This is a snapshot site for StackOverflow">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>StackOverflow Snapshot (old posts, page 945) | StackOverflow Snapshot</title>
<link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="canonical" href="https://ohstackoverflow.netlify.app/index-945.html">
<link rel="prev" href="index-946.html" type="text/html">
<link rel="next" href="index-944.html" type="text/html">
<!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]-->
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://ohstackoverflow.netlify.app/">

                <span id="blog-title">StackOverflow Snapshot</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="archive.html">Archive</a>
                </li>
<li>
<a href="categories/">Tags</a>

                
            </li>
</ul>
<ul class="nav navbar-nav navbar-right">
<div style="display:table;min-height:5rem;min-width:27rem;">
					<div class="input-group" style="display: table-cell;vertical-align: middle;">
						<input id="words" type="text" class="form-control" style="max-width:22rem;" onkeydown="if(event.keyCode==13){btn.click()}"><span class="input-group-btn" style="float:left">
							<button id="btn" class="btn btn-default" type="button" data-toggle="modal" data-target="#myModal">
								<span class="glyphicon glyphicon-search">
							</span></button>
						</span>
					</div>
<!-- /input-group -->
				</div>

				
                
                
                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><!-- 模态框（Modal） --><div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true">
	<div class="modal-dialog">
		<div class="modal-content">
			<div class="modal-header">
				<button type="button" class="close" data-dismiss="modal" aria-hidden="true">×
				</button>
				<h4 class="modal-title" id="myModalLabel">
					查找结果
				</h4>
			</div>
			<div class="modal-body">
				<div id="search-count" style="min-height:4rem;">
				查找中，请稍后...
				</div>
				<div id="search-result">
				</div>

				
			</div>
			<div class="modal-footer">
				<button type="button" class="btn btn-default" data-dismiss="modal">
					关闭
				</button>
			</div>
		</div>
<!-- /.modal-content -->
	</div>
<!-- /.modal-dialog -->
</div>
<!-- /.modal -->

<div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            

    


    
<div class="postindex">
    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/xun-lian-hou-ru-he-bao-cun-hui-fu-mo-xing/" class="u-url">训练后如何保存/恢复模型？</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="posts/xun-lian-hou-ru-he-bao-cun-hui-fu-mo-xing/" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-17T20:26:24+08:00" itemprop="datePublished" title="2023-02-17 20:26">2023-02-17 20:26</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>在 Tensorflow 中训练模型后：</p>
<ol>
<li>如何保存训练好的模型？</li>
<li>您稍后如何恢复这个保存的模型？</li>
</ol>
<p><br><br></p>
<h2>解答</h2>
<h2>Tensorflow 2 文档</h2>
<h4>保存检查点</h4>
<p>改编自文档</p>
<div class="code"><pre class="code literal-block"><span class="c1"># -------------------------</span>
<span class="c1"># -----  Toy Context  -----</span>
<span class="c1"># -------------------------</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>


<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""A simple linear model."""</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">l1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">l1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">toy_dataset</span><span class="p">():</span>
    <span class="n">inputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mf">10.0</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span> <span class="o">*</span> <span class="mf">5.0</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="mf">5.0</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
    <span class="k">return</span> <span class="p">(</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span><span class="nb">dict</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">inputs</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">labels</span><span class="p">))</span><span class="o">.</span><span class="n">repeat</span><span class="p">()</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">train_step</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">example</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Trains `net` on `example` using `optimizer`."""</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">example</span><span class="p">[</span><span class="s2">"x"</span><span class="p">])</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">output</span> <span class="o">-</span> <span class="n">example</span><span class="p">[</span><span class="s2">"y"</span><span class="p">]))</span>
    <span class="n">variables</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">trainable_variables</span>
    <span class="n">gradients</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">variables</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradients</span><span class="p">,</span> <span class="n">variables</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">loss</span>


<span class="c1"># ----------------------------</span>
<span class="c1"># -----  Create Objects  -----</span>
<span class="c1"># ----------------------------</span>

<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">toy_dataset</span><span class="p">()</span>
<span class="n">iterator</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">ckpt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Checkpoint</span><span class="p">(</span>
    <span class="n">step</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> <span class="n">net</span><span class="o">=</span><span class="n">net</span><span class="p">,</span> <span class="n">iterator</span><span class="o">=</span><span class="n">iterator</span>
<span class="p">)</span>
<span class="n">manager</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">CheckpointManager</span><span class="p">(</span><span class="n">ckpt</span><span class="p">,</span> <span class="s2">"./tf_ckpts"</span><span class="p">,</span> <span class="n">max_to_keep</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># ----------------------------</span>
<span class="c1"># -----  Train and Save  -----</span>
<span class="c1"># ----------------------------</span>

<span class="n">ckpt</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">manager</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">)</span>
<span class="k">if</span> <span class="n">manager</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Restored from </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">manager</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">))</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Initializing from scratch."</span><span class="p">)</span>

<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">50</span><span class="p">):</span>
    <span class="n">example</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">train_step</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">example</span><span class="p">,</span> <span class="n">opt</span><span class="p">)</span>
    <span class="n">ckpt</span><span class="o">.</span><span class="n">step</span><span class="o">.</span><span class="n">assign_add</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">int</span><span class="p">(</span><span class="n">ckpt</span><span class="o">.</span><span class="n">step</span><span class="p">)</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">save_path</span> <span class="o">=</span> <span class="n">manager</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"Saved checkpoint for step </span><span class="si">{}</span><span class="s2">: </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">ckpt</span><span class="o">.</span><span class="n">step</span><span class="p">),</span> <span class="n">save_path</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"loss </span><span class="si">{:1.2f}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span>


<span class="c1"># ---------------------</span>
<span class="c1"># -----  Restore  -----</span>
<span class="c1"># ---------------------</span>

<span class="c1"># In another script, re-initialize objects</span>
<span class="n">opt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">toy_dataset</span><span class="p">()</span>
<span class="n">iterator</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>
<span class="n">ckpt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Checkpoint</span><span class="p">(</span>
    <span class="n">step</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">optimizer</span><span class="o">=</span><span class="n">opt</span><span class="p">,</span> <span class="n">net</span><span class="o">=</span><span class="n">net</span><span class="p">,</span> <span class="n">iterator</span><span class="o">=</span><span class="n">iterator</span>
<span class="p">)</span>
<span class="n">manager</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">CheckpointManager</span><span class="p">(</span><span class="n">ckpt</span><span class="p">,</span> <span class="s2">"./tf_ckpts"</span><span class="p">,</span> <span class="n">max_to_keep</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="c1"># Re-use the manager code above ^</span>

<span class="n">ckpt</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">manager</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">)</span>
<span class="k">if</span> <span class="n">manager</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Restored from </span><span class="si">{}</span><span class="s2">"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">manager</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">))</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">"Initializing from scratch."</span><span class="p">)</span>

<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">50</span><span class="p">):</span>
    <span class="n">example</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">iterator</span><span class="p">)</span>
    <span class="c1"># Continue training or evaluate etc.</span>
</pre></div>

<h4>更多链接</h4>
<ul>
<li>
<p><strong><code>saved_model</code></strong> 关于-&gt; https://www.tensorflow.org/guide/saved_model的详尽且有用的教程</p>
</li>
<li>
<p><strong><code>keras</code></strong> 保存模型的详细指南 -&gt; https://www.tensorflow.org/guide/keras/save_and_serialize</p>
</li>
</ul>
<blockquote>
<p>检查点捕获模型使用的所有参数（tf.Variable 对象）的准确值。 <strong>检查点不包含模型定义的计算的任何描述</strong>
，因此通常仅在使用已保存参数值的源代码可用时才有用。</p>
<p>另一方面，除了参数值（检查点）之外， SavedModel 格式 <strong>还包括模型定义的计算的序列化描述。</strong> 这种格式的模型 <em>独立</em>
于创建模型的源代码。因此，它们适合通过 TensorFlow Serving、TensorFlow Lite、TensorFlow.js
或其他编程语言（C、C++、Java、Go、Rust、C# 等 TensorFlow API）的程序进行部署。</p>
</blockquote>
<p>（亮点是我自己的）</p>
<hr>
<h2>张量流 &lt; 2</h2>
<hr>
<p>从文档：</p>
<h4>节省</h4>
<div class="code"><pre class="code literal-block"><span class="c1"># Create some variables.</span>
<span class="n">v1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s2">"v1"</span><span class="p">,</span><span class="w"> </span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span><span class="w"> </span><span class="n">initializer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_initializer</span><span class="p">)</span>
<span class="n">v2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s2">"v2"</span><span class="p">,</span><span class="w"> </span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span><span class="w"> </span><span class="n">initializer</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_initializer</span><span class="p">)</span>

<span class="n">inc_v1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">v1</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">v1</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
<span class="n">dec_v2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">v2</span><span class="o">.</span><span class="n">assign</span><span class="p">(</span><span class="n">v2</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Add an op to initialize the variables.</span>
<span class="n">init_op</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span>

<span class="c1"># Add ops to save and restore all the variables.</span>
<span class="n">saver</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>

<span class="c1"># Later, launch the model, initialize the variables, do some work, and save the</span>
<span class="c1"># variables to disk.</span>
<span class="n">with</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">sess</span><span class="p">:</span>
<span class="w">  </span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">init_op</span><span class="p">)</span>
<span class="w">  </span><span class="c1"># Do some work with the model.</span>
<span class="w">  </span><span class="n">inc_v1</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
<span class="w">  </span><span class="n">dec_v2</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
<span class="w">  </span><span class="c1"># Save the variables to disk.</span>
<span class="w">  </span><span class="n">save_path</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span><span class="w"> </span><span class="s2">"/tmp/model.ckpt"</span><span class="p">)</span>
<span class="w">  </span><span class="nb">print</span><span class="p">(</span><span class="s2">"Model saved in path: </span><span class="si">%s</span><span class="s2">"</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">save_path</span><span class="p">)</span>
</pre></div>

<h4>恢复</h4>
<div class="code"><pre class="code literal-block"><span class="n">tf</span><span class="o">.</span><span class="n">reset_default_graph</span><span class="p">()</span>

<span class="c1"># Create some variables.</span>
<span class="n">v1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s2">"v1"</span><span class="p">,</span><span class="w"> </span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
<span class="n">v2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s2">"v2"</span><span class="p">,</span><span class="w"> </span><span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">])</span>

<span class="c1"># Add ops to save and restore all the variables.</span>
<span class="n">saver</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span>

<span class="c1"># Later, launch the model, use the saver to restore variables from disk, and</span>
<span class="c1"># do some work with the model.</span>
<span class="n">with</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">sess</span><span class="p">:</span>
<span class="w">  </span><span class="c1"># Restore variables from disk.</span>
<span class="w">  </span><span class="n">saver</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span><span class="w"> </span><span class="s2">"/tmp/model.ckpt"</span><span class="p">)</span>
<span class="w">  </span><span class="nb">print</span><span class="p">(</span><span class="s2">"Model restored."</span><span class="p">)</span>
<span class="w">  </span><span class="c1"># Check the values of the variables</span>
<span class="w">  </span><span class="nb">print</span><span class="p">(</span><span class="s2">"v1 : </span><span class="si">%s</span><span class="s2">"</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">v1</span><span class="o">.</span><span class="n">eval</span><span class="p">())</span>
<span class="w">  </span><span class="nb">print</span><span class="p">(</span><span class="s2">"v2 : </span><span class="si">%s</span><span class="s2">"</span><span class="w"> </span><span class="o">%</span><span class="w"> </span><span class="n">v2</span><span class="o">.</span><span class="n">eval</span><span class="p">())</span>
</pre></div>

<h3><code>simple_save</code></h3>
<p>许多好的答案，为了完整起见，我将添加我的 2 美分： <strong>simple_save</strong> 。也是使用 API 的独立代码示例<code>tf.data.Dataset</code>。</p>
<p>蟒蛇3；张量流 <strong>1.14</strong></p>
<div class="code"><pre class="code literal-block"><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.saved_model</span> <span class="kn">import</span> <span class="n">tag_constants</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
        <span class="o">...</span>

        <span class="c1"># Saving</span>
        <span class="n">inputs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">"batch_size_placeholder"</span><span class="p">:</span> <span class="n">batch_size_placeholder</span><span class="p">,</span>
            <span class="s2">"features_placeholder"</span><span class="p">:</span> <span class="n">features_placeholder</span><span class="p">,</span>
            <span class="s2">"labels_placeholder"</span><span class="p">:</span> <span class="n">labels_placeholder</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">"prediction"</span><span class="p">:</span> <span class="n">model_output</span><span class="p">}</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">saved_model</span><span class="o">.</span><span class="n">simple_save</span><span class="p">(</span>
            <span class="n">sess</span><span class="p">,</span> <span class="s1">'path/to/your/location/'</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">outputs</span>
        <span class="p">)</span>
</pre></div>

<p>恢复：</p>
<div class="code"><pre class="code literal-block"><span class="n">graph</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
<span class="n">with</span><span class="w"> </span><span class="n">restored_graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
<span class="w">    </span><span class="n">with</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="n">sess</span><span class="p">:</span>
<span class="w">        </span><span class="n">tf</span><span class="o">.</span><span class="n">saved_model</span><span class="o">.</span><span class="n">loader</span><span class="o">.</span><span class="n">load</span><span class="p">(</span>
<span class="w">            </span><span class="n">sess</span><span class="p">,</span>
<span class="w">            </span><span class="p">[</span><span class="n">tag_constants</span><span class="o">.</span><span class="n">SERVING</span><span class="p">],</span>
<span class="w">            </span><span class="s1">'path/to/your/location/'</span><span class="p">,</span>
<span class="w">        </span><span class="p">)</span>
<span class="w">        </span><span class="n">batch_size_placeholder</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">'batch_size_placeholder:0'</span><span class="p">)</span>
<span class="w">        </span><span class="n">features_placeholder</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">'features_placeholder:0'</span><span class="p">)</span>
<span class="w">        </span><span class="n">labels_placeholder</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">'labels_placeholder:0'</span><span class="p">)</span>
<span class="w">        </span><span class="n">prediction</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">restored_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">'dense/BiasAdd:0'</span><span class="p">)</span>

<span class="w">        </span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span><span class="w"> </span><span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
<span class="w">            </span><span class="n">batch_size_placeholder</span><span class="p">:</span><span class="w"> </span><span class="n">some_value</span><span class="p">,</span>
<span class="w">            </span><span class="n">features_placeholder</span><span class="p">:</span><span class="w"> </span><span class="n">some_other_value</span><span class="p">,</span>
<span class="w">            </span><span class="n">labels_placeholder</span><span class="p">:</span><span class="w"> </span><span class="n">another_value</span>
<span class="w">        </span><span class="p">})</span>
</pre></div>

<h2>独立示例</h2>
<p><strong>原博文</strong></p>
<p>The following code generates random data for the sake of the demonstration.</p>
<ol>
<li>We start by creating the placeholders. They will hold the data at runtime. From them, we create the <code>Dataset</code> and then its <code>Iterator</code>. We get the iterator's generated tensor, called <code>input_tensor</code> which will serve as input to our model.</li>
<li>The model itself is built from <code>input_tensor</code>: a GRU-based bidirectional RNN followed by a dense classifier. Because why not.</li>
<li>The loss is a <code>softmax_cross_entropy_with_logits</code>, optimized with <code>Adam</code>. After 2 epochs (of 2 batches each), we save the "trained" model with <code>tf.saved_model.simple_save</code>. If you run the code as is, then the model will be saved in a folder called <code>simple/</code> in your current working directory.</li>
<li>In a new graph, we then restore the saved model with <code>tf.saved_model.loader.load</code>. We grab the placeholders and logits with <code>graph.get_tensor_by_name</code> and the <code>Iterator</code> initializing operation with <code>graph.get_operation_by_name</code>.</li>
<li>Lastly we run an inference for both batches in the dataset, and check that the saved and restored model both yield the same values. They do!</li>
</ol>
<p>Code:</p>
<div class="code"><pre class="code literal-block"><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">shutil</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">from</span> <span class="nn">tensorflow.python.saved_model</span> <span class="kn">import</span> <span class="n">tag_constants</span>


<span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Create the model which consists of</span>
<span class="sd">    a bidirectional rnn (GRU(10)) followed by a dense classifier</span>

<span class="sd">    Args:</span>
<span class="sd">        graph (tf.Graph): Tensors' graph</span>
<span class="sd">        input_tensor (tf.Tensor): Tensor fed as input to the model</span>

<span class="sd">    Returns:</span>
<span class="sd">        tf.Tensor: the model's output layer Tensor</span>
<span class="sd">    """</span>
    <span class="n">cell</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">rnn_cell</span><span class="o">.</span><span class="n">GRUCell</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
        <span class="p">((</span><span class="n">fw_outputs</span><span class="p">,</span> <span class="n">bw_outputs</span><span class="p">),</span> <span class="p">(</span><span class="n">fw_state</span><span class="p">,</span> <span class="n">bw_state</span><span class="p">))</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">bidirectional_dynamic_rnn</span><span class="p">(</span>
            <span class="n">cell_fw</span><span class="o">=</span><span class="n">cell</span><span class="p">,</span>
            <span class="n">cell_bw</span><span class="o">=</span><span class="n">cell</span><span class="p">,</span>
            <span class="n">inputs</span><span class="o">=</span><span class="n">input_tensor</span><span class="p">,</span>
            <span class="n">sequence_length</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">]</span> <span class="o">*</span> <span class="mi">32</span><span class="p">,</span>
            <span class="kp">dtype</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span>
            <span class="n">swap_memory</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">scope</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">fw_outputs</span><span class="p">,</span> <span class="n">bw_outputs</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
        <span class="kp">mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">dense</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="kp">mean</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">dense</span>


<span class="k">def</span> <span class="nf">get_opt_op</span><span class="p">(</span><span class="n">graph</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">labels_tensor</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Create optimization operation from model's logits and labels</span>

<span class="sd">    Args:</span>
<span class="sd">        graph (tf.Graph): Tensors' graph</span>
<span class="sd">        logits (tf.Tensor): The model's output without activation</span>
<span class="sd">        labels_tensor (tf.Tensor): Target labels</span>

<span class="sd">    Returns:</span>
<span class="sd">        tf.Operation: the operation performing a stem of Adam optimizer</span>
<span class="sd">    """</span>
    <span class="k">with</span> <span class="n">graph</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">'loss'</span><span class="p">):</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax_cross_entropy_with_logits</span><span class="p">(</span>
                    <span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">labels_tensor</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">'xent'</span><span class="p">),</span>
                    <span class="n">name</span><span class="o">=</span><span class="s2">"mean-xent"</span>
                    <span class="p">)</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">variable_scope</span><span class="p">(</span><span class="s1">'optimizer'</span><span class="p">):</span>
            <span class="n">opt_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="mf">1e-2</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">opt_op</span>


<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s1">'__main__'</span><span class="p">:</span>
    <span class="c1"># Set random seed for reproducibility</span>
    <span class="c1"># and create synthetic data</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="kp">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">features</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">64</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
    <span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="kp">eye</span><span class="p">(</span><span class="mi">5</span><span class="p">)[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="kp">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="p">(</span><span class="mi">64</span><span class="p">,))]</span>

    <span class="n">graph1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">graph1</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
        <span class="c1"># Random seed for reproducibility</span>
        <span class="n">tf</span><span class="o">.</span><span class="n">set_random_seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
        <span class="c1"># Placeholders</span>
        <span class="n">batch_size_ph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">'batch_size_ph'</span><span class="p">)</span>
        <span class="n">features_data_ph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="mi">30</span><span class="p">],</span> <span class="s1">'features_data_ph'</span><span class="p">)</span>
        <span class="n">labels_data_ph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span> <span class="s1">'labels_data_ph'</span><span class="p">)</span>
        <span class="c1"># Dataset</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">((</span><span class="n">features_data_ph</span><span class="p">,</span> <span class="n">labels_data_ph</span><span class="p">))</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size_ph</span><span class="p">)</span>
        <span class="n">iterator</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Iterator</span><span class="o">.</span><span class="n">from_structure</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">output_types</span><span class="p">,</span> <span class="n">dataset</span><span class="o">.</span><span class="n">output_shapes</span><span class="p">)</span>
        <span class="n">dataset_init_op</span> <span class="o">=</span> <span class="n">iterator</span><span class="o">.</span><span class="n">make_initializer</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">'dataset_init'</span><span class="p">)</span>
        <span class="n">input_tensor</span><span class="p">,</span> <span class="n">labels_tensor</span> <span class="o">=</span> <span class="n">iterator</span><span class="o">.</span><span class="n">get_next</span><span class="p">()</span>

        <span class="c1"># Model</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">graph1</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">)</span>
        <span class="c1"># Optimization</span>
        <span class="n">opt_op</span> <span class="o">=</span> <span class="n">get_opt_op</span><span class="p">(</span><span class="n">graph1</span><span class="p">,</span> <span class="n">logits</span><span class="p">,</span> <span class="n">labels_tensor</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">graph1</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
            <span class="c1"># Initialize variables</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">session</span><span class="o">=</span><span class="n">sess</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
                <span class="n">batch</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="c1"># Initialize dataset (could feed epochs in Dataset.repeat(epochs))</span>
                <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                    <span class="n">dataset_init_op</span><span class="p">,</span>
                    <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
                        <span class="n">features_data_ph</span><span class="p">:</span> <span class="n">features</span><span class="p">,</span>
                        <span class="n">labels_data_ph</span><span class="p">:</span> <span class="n">labels</span><span class="p">,</span>
                        <span class="n">batch_size_ph</span><span class="p">:</span> <span class="mi">32</span>
                    <span class="p">})</span>
                <span class="n">values</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>
                    <span class="k">try</span><span class="p">:</span>
                        <span class="k">if</span> <span class="n">epoch</span> <span class="o">&lt;</span> <span class="mi">2</span><span class="p">:</span>
                            <span class="c1"># Training</span>
                            <span class="n">_</span><span class="p">,</span> <span class="n">value</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">opt_op</span><span class="p">,</span> <span class="n">logits</span><span class="p">])</span>
                            <span class="nb">print</span><span class="p">(</span><span class="s1">'Epoch </span><span class="si">{}</span><span class="s1">, batch </span><span class="si">{}</span><span class="s1"> | Sample value: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">value</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
                            <span class="n">batch</span> <span class="o">+=</span> <span class="mi">1</span>
                        <span class="k">else</span><span class="p">:</span>
                            <span class="c1"># Final inference</span>
                            <span class="n">values</span><span class="o">.</span><span class="kp">append</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">logits</span><span class="p">))</span>
                            <span class="nb">print</span><span class="p">(</span><span class="s1">'Epoch </span><span class="si">{}</span><span class="s1">, batch </span><span class="si">{}</span><span class="s1"> | Final inference | Sample value: </span><span class="si">{}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">values</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]))</span>
                            <span class="n">batch</span> <span class="o">+=</span> <span class="mi">1</span>
                    <span class="k">except</span> <span class="n">tf</span><span class="o">.</span><span class="n">errors</span><span class="o">.</span><span class="n">OutOfRangeError</span><span class="p">:</span>
                        <span class="k">break</span>
            <span class="c1"># Save model state</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Saving...'</span><span class="p">)</span>
            <span class="n">cwd</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">()</span>
            <span class="n">path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">cwd</span><span class="p">,</span> <span class="s1">'simple'</span><span class="p">)</span>
            <span class="n">shutil</span><span class="o">.</span><span class="n">rmtree</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="n">ignore_errors</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="n">inputs_dict</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">"batch_size_ph"</span><span class="p">:</span> <span class="n">batch_size_ph</span><span class="p">,</span>
                <span class="s2">"features_data_ph"</span><span class="p">:</span> <span class="n">features_data_ph</span><span class="p">,</span>
                <span class="s2">"labels_data_ph"</span><span class="p">:</span> <span class="n">labels_data_ph</span>
            <span class="p">}</span>
            <span class="n">outputs_dict</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">"logits"</span><span class="p">:</span> <span class="n">logits</span>
            <span class="p">}</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">saved_model</span><span class="o">.</span><span class="n">simple_save</span><span class="p">(</span>
                <span class="n">sess</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">inputs_dict</span><span class="p">,</span> <span class="n">outputs_dict</span>
            <span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">'Ok'</span><span class="p">)</span>
    <span class="c1"># Restoring</span>
    <span class="n">graph2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Graph</span><span class="p">()</span>
    <span class="k">with</span> <span class="n">graph2</span><span class="o">.</span><span class="n">as_default</span><span class="p">():</span>
        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">(</span><span class="n">graph</span><span class="o">=</span><span class="n">graph2</span><span class="p">)</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
            <span class="c1"># Restore saved values</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Restoring...'</span><span class="p">)</span>
            <span class="n">tf</span><span class="o">.</span><span class="n">saved_model</span><span class="o">.</span><span class="n">loader</span><span class="o">.</span><span class="kp">load</span><span class="p">(</span>
                <span class="n">sess</span><span class="p">,</span>
                <span class="p">[</span><span class="n">tag_constants</span><span class="o">.</span><span class="n">SERVING</span><span class="p">],</span>
                <span class="n">path</span>
            <span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">'Ok'</span><span class="p">)</span>
            <span class="c1"># Get restored placeholders</span>
            <span class="n">labels_data_ph</span> <span class="o">=</span> <span class="n">graph2</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">'labels_data_ph:0'</span><span class="p">)</span>
            <span class="n">features_data_ph</span> <span class="o">=</span> <span class="n">graph2</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">'features_data_ph:0'</span><span class="p">)</span>
            <span class="n">batch_size_ph</span> <span class="o">=</span> <span class="n">graph2</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">'batch_size_ph:0'</span><span class="p">)</span>
            <span class="c1"># Get restored model output</span>
            <span class="n">restored_logits</span> <span class="o">=</span> <span class="n">graph2</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s1">'dense/BiasAdd:0'</span><span class="p">)</span>
            <span class="c1"># Get dataset initializing operation</span>
            <span class="n">dataset_init_op</span> <span class="o">=</span> <span class="n">graph2</span><span class="o">.</span><span class="n">get_operation_by_name</span><span class="p">(</span><span class="s1">'dataset_init'</span><span class="p">)</span>

            <span class="c1"># Initialize restored dataset</span>
            <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span>
                <span class="n">dataset_init_op</span><span class="p">,</span>
                <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span>
                    <span class="n">features_data_ph</span><span class="p">:</span> <span class="n">features</span><span class="p">,</span>
                    <span class="n">labels_data_ph</span><span class="p">:</span> <span class="n">labels</span><span class="p">,</span>
                    <span class="n">batch_size_ph</span><span class="p">:</span> <span class="mi">32</span>
                <span class="p">}</span>

            <span class="p">)</span>
            <span class="c1"># Compute inference for both batches in dataset</span>
            <span class="n">restored_values</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>
                <span class="n">restored_values</span><span class="o">.</span><span class="kp">append</span><span class="p">(</span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">restored_logits</span><span class="p">))</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">'Restored values: '</span><span class="p">,</span> <span class="n">restored_values</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="mi">0</span><span class="p">])</span>

    <span class="c1"># Check if original inference and restored inference are equal</span>
    <span class="n">valid</span> <span class="o">=</span> <span class="nb">all</span><span class="p">((</span><span class="n">v</span> <span class="o">==</span> <span class="n">rv</span><span class="p">)</span><span class="o">.</span><span class="kp">all</span><span class="p">()</span> <span class="k">for</span> <span class="n">v</span><span class="p">,</span> <span class="n">rv</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">values</span><span class="p">,</span> <span class="n">restored_values</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'</span><span class="se">\n</span><span class="s1">Inferences match: '</span><span class="p">,</span> <span class="n">valid</span><span class="p">)</span>
</pre></div>

<p>This will print:</p>
<div class="code"><pre class="code literal-block">$<span class="w"> </span>python3<span class="w"> </span>save_and_restore.py

Epoch<span class="w"> </span><span class="m">0</span>,<span class="w"> </span>batch<span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>Sample<span class="w"> </span>value:<span class="w"> </span><span class="o">[</span>-0.13851789<span class="w"> </span>-0.3087595<span class="w">   </span><span class="m">0</span>.12804556<span class="w">  </span><span class="m">0</span>.20013677<span class="w"> </span>-0.08229901<span class="o">]</span>
Epoch<span class="w"> </span><span class="m">0</span>,<span class="w"> </span>batch<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>Sample<span class="w"> </span>value:<span class="w"> </span><span class="o">[</span>-0.00555491<span class="w"> </span>-0.04339041<span class="w"> </span>-0.05111827<span class="w"> </span>-0.2480045<span class="w">  </span>-0.00107776<span class="o">]</span>
Epoch<span class="w"> </span><span class="m">1</span>,<span class="w"> </span>batch<span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>Sample<span class="w"> </span>value:<span class="w"> </span><span class="o">[</span>-0.19321944<span class="w"> </span>-0.2104792<span class="w">  </span>-0.00602257<span class="w">  </span><span class="m">0</span>.07465433<span class="w">  </span><span class="m">0</span>.11674127<span class="o">]</span>
Epoch<span class="w"> </span><span class="m">1</span>,<span class="w"> </span>batch<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>Sample<span class="w"> </span>value:<span class="w"> </span><span class="o">[</span>-0.05275984<span class="w">  </span><span class="m">0</span>.05981954<span class="w"> </span>-0.15913513<span class="w"> </span>-0.3244143<span class="w">   </span><span class="m">0</span>.10673307<span class="o">]</span>
Epoch<span class="w"> </span><span class="m">2</span>,<span class="w"> </span>batch<span class="w"> </span><span class="m">0</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>Final<span class="w"> </span>inference<span class="w"> </span><span class="p">|</span><span class="w"> </span>Sample<span class="w"> </span>value:<span class="w"> </span><span class="o">[</span>-0.26331693<span class="w"> </span>-0.13013336<span class="w"> </span>-0.12553<span class="w">    </span>-0.04276478<span class="w">  </span><span class="m">0</span>.2933622<span class="w"> </span><span class="o">]</span>
Epoch<span class="w"> </span><span class="m">2</span>,<span class="w"> </span>batch<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="p">|</span><span class="w"> </span>Final<span class="w"> </span>inference<span class="w"> </span><span class="p">|</span><span class="w"> </span>Sample<span class="w"> </span>value:<span class="w"> </span><span class="o">[</span>-0.07730117<span class="w">  </span><span class="m">0</span>.11119192<span class="w"> </span>-0.20817074<span class="w"> </span>-0.35660955<span class="w">  </span><span class="m">0</span>.16990358<span class="o">]</span>

Saving...
INFO:tensorflow:Assets<span class="w"> </span>added<span class="w"> </span>to<span class="w"> </span>graph.
INFO:tensorflow:No<span class="w"> </span>assets<span class="w"> </span>to<span class="w"> </span>write.
INFO:tensorflow:SavedModel<span class="w"> </span>written<span class="w"> </span>to:<span class="w"> </span>b<span class="s1">'/some/path/simple/saved_model.pb'</span>
Ok

Restoring...
INFO:tensorflow:Restoring<span class="w"> </span>parameters<span class="w"> </span>from<span class="w"> </span>b<span class="s1">'/some/path/simple/variables/variables'</span>
Ok
Restored<span class="w"> </span>values:<span class="w">  </span><span class="o">[</span>-0.26331693<span class="w"> </span>-0.13013336<span class="w"> </span>-0.12553<span class="w">    </span>-0.04276478<span class="w">  </span><span class="m">0</span>.2933622<span class="w"> </span><span class="o">]</span>
Restored<span class="w"> </span>values:<span class="w">  </span><span class="o">[</span>-0.07730117<span class="w">  </span><span class="m">0</span>.11119192<span class="w"> </span>-0.20817074<span class="w"> </span>-0.35660955<span class="w">  </span><span class="m">0</span>.16990358<span class="o">]</span>

Inferences<span class="w"> </span>match:<span class="w">  </span>True
</pre></div>

<p><br></p>
<h3>更多建议</h3>
<p><code>tf.train.export_meta_graph</code>在 TensorFlow 0.11.0RC1
版本（及之后）中，您可以通过调用并<code>tf.train.import_meta_graph</code>根据https://www.tensorflow.org/programmers_guide/meta_graph直接保存和恢复您的模型。</p>
<h4>保存模型</h4>
<div class="code"><pre class="code literal-block"><span class="n">w1</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">truncated_normal</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="err">[</span><span class="mi">10</span><span class="err">]</span><span class="p">),</span><span class="w"> </span><span class="k">name</span><span class="o">=</span><span class="s1">'w1'</span><span class="p">)</span>
<span class="n">w2</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">truncated_normal</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="err">[</span><span class="mi">20</span><span class="err">]</span><span class="p">),</span><span class="w"> </span><span class="k">name</span><span class="o">=</span><span class="s1">'w2'</span><span class="p">)</span>
<span class="n">tf</span><span class="p">.</span><span class="n">add_to_collection</span><span class="p">(</span><span class="s1">'vars'</span><span class="p">,</span><span class="w"> </span><span class="n">w1</span><span class="p">)</span>
<span class="n">tf</span><span class="p">.</span><span class="n">add_to_collection</span><span class="p">(</span><span class="s1">'vars'</span><span class="p">,</span><span class="w"> </span><span class="n">w2</span><span class="p">)</span>
<span class="n">saver</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="n">train</span><span class="p">.</span><span class="n">Saver</span><span class="p">()</span>
<span class="n">sess</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="p">.</span><span class="k">Session</span><span class="p">()</span>
<span class="n">sess</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="n">global_variables_initializer</span><span class="p">())</span>
<span class="n">saver</span><span class="p">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span><span class="w"> </span><span class="s1">'my-model'</span><span class="p">)</span>
<span class="c1"># `save` method will call `export_meta_graph` implicitly.</span>
<span class="c1"># you will get saved graph files:my-model.meta</span>
</pre></div>

<h4>恢复模型</h4>
<div class="code"><pre class="code literal-block"><span class="n">sess</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span>
<span class="n">new_saver</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">import_meta_graph</span><span class="p">(</span><span class="s1">'my-model.meta'</span><span class="p">)</span>
<span class="n">new_saver</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">latest_checkpoint</span><span class="p">(</span><span class="s1">'./'</span><span class="p">))</span>
<span class="n">all_vars</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="s1">'vars'</span><span class="p">)</span>
<span class="k">for</span><span class="w"> </span><span class="n">v</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">all_vars</span><span class="p">:</span>
<span class="w">    </span><span class="n">v_</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">v_</span><span class="p">)</span>
</pre></div>

<p><br><br><a href="posts/how-to-save-restore-a-model-after-training/">查看原文</a></p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/cun-chu-php-shu-zu-de-shou-xuan-fang-fa-json-encode-yu-xu-lie-hua/" class="u-url">存储 PHP 数组的首选方法（json_encode 与序列化）</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="posts/cun-chu-php-shu-zu-de-shou-xuan-fang-fa-json-encode-yu-xu-lie-hua/" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-17T20:25:45+08:00" itemprop="datePublished" title="2023-02-17 20:25">2023-02-17 20:25</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>我需要将多维关联数据数组存储在平面文件中以用于缓存目的。我可能偶尔会遇到需要将其转换为 JSON 以便在我的 Web
应用程序中使用，但绝大多数时候我会直接在 PHP 中使用数组。</p>
<p>将数组存储为 JSON 或此文本文件中的 PHP 序列化数组会更有效吗？我环顾四周，似乎在最新版本的 PHP (5.3)
中，<code>json_decode</code>实际上比<code>unserialize</code>.</p>
<p>我目前倾向于将数组存储为 JSON，因为我觉得如果有必要，它更容易被人类阅读，它可以在 PHP 和 JavaScript
中使用，而且只需很少的努力，而且从我读过的内容来看，它甚至可能是解码速度更快（虽然不确定编码）。</p>
<p>有谁知道任何陷阱？任何人都有很好的基准来显示这两种方法的性能优势？</p>
<p><br><br></p>
<h2>解答</h2>
<p>取决于您的优先级。</p>
<p>如果性能是您绝对的驾驶特性，那么一定要使用最快的。在做出选择之前，请确保您对差异有充分的了解</p>
<ul>
<li>不像<code>serialize()</code>你需要添加额外的参数来保持 UTF-8 字符不变：（<code>json_encode($array, JSON_UNESCAPED_UNICODE)</code>否则它会将 UTF-8 字符转换为 Unicode 转义序列）。</li>
<li>JSON 将不记得对象的原始类是什么（它们总是作为 stdClass 的实例恢复）。</li>
<li>你不能<code>__sleep()</code>利用<code>__wakeup()</code>JSON</li>
<li>默认情况下，只有公共属性使用 JSON 进行序列化。（<code>PHP&gt;=5.4</code>你可以实现JsonSerializable来改变这种行为）。</li>
<li>JSON 更便携</li>
</ul>
<p>可能还有其他一些我目前无法想到的差异。</p>
<p>比较两者的简单速度测试</p>
<div class="code"><pre class="code literal-block"><span class="cp">&lt;?php</span>

<span class="nb">ini_set</span><span class="p">(</span><span class="s1">'display_errors'</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
<span class="nb">error_reporting</span><span class="p">(</span><span class="k">E_ALL</span><span class="p">);</span>

<span class="c1">// Make a big, honkin test array</span>
<span class="c1">// You may need to adjust this depth to avoid memory limit errors</span>
<span class="nv">$testArray</span> <span class="o">=</span> <span class="nx">fillArray</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">);</span>

<span class="c1">// Time json encoding</span>
<span class="nv">$start</span> <span class="o">=</span> <span class="nb">microtime</span><span class="p">(</span><span class="k">true</span><span class="p">);</span>
<span class="nb">json_encode</span><span class="p">(</span><span class="nv">$testArray</span><span class="p">);</span>
<span class="nv">$jsonTime</span> <span class="o">=</span> <span class="nb">microtime</span><span class="p">(</span><span class="k">true</span><span class="p">)</span> <span class="o">-</span> <span class="nv">$start</span><span class="p">;</span>
<span class="k">echo</span> <span class="s2">"JSON encoded in </span><span class="si">$jsonTime</span><span class="s2"> seconds</span><span class="se">\n</span><span class="s2">"</span><span class="p">;</span>

<span class="c1">// Time serialization</span>
<span class="nv">$start</span> <span class="o">=</span> <span class="nb">microtime</span><span class="p">(</span><span class="k">true</span><span class="p">);</span>
<span class="nb">serialize</span><span class="p">(</span><span class="nv">$testArray</span><span class="p">);</span>
<span class="nv">$serializeTime</span> <span class="o">=</span> <span class="nb">microtime</span><span class="p">(</span><span class="k">true</span><span class="p">)</span> <span class="o">-</span> <span class="nv">$start</span><span class="p">;</span>
<span class="k">echo</span> <span class="s2">"PHP serialized in </span><span class="si">$serializeTime</span><span class="s2"> seconds</span><span class="se">\n</span><span class="s2">"</span><span class="p">;</span>

<span class="c1">// Compare them</span>
<span class="k">if</span> <span class="p">(</span><span class="nv">$jsonTime</span> <span class="o">&lt;</span> <span class="nv">$serializeTime</span><span class="p">)</span> <span class="p">{</span>
    <span class="nb">printf</span><span class="p">(</span><span class="s2">"json_encode() was roughly %01.2f%% faster than serialize()</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span> <span class="p">(</span><span class="nv">$serializeTime</span> <span class="o">/</span> <span class="nv">$jsonTime</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">);</span>
<span class="p">}</span>
<span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="nv">$serializeTime</span> <span class="o">&lt;</span> <span class="nv">$jsonTime</span> <span class="p">)</span> <span class="p">{</span>
    <span class="nb">printf</span><span class="p">(</span><span class="s2">"serialize() was roughly %01.2f%% faster than json_encode()</span><span class="se">\n</span><span class="s2">"</span><span class="p">,</span> <span class="p">(</span><span class="nv">$jsonTime</span> <span class="o">/</span> <span class="nv">$serializeTime</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span><span class="p">);</span>
<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
    <span class="k">echo</span> <span class="s2">"Impossible!</span><span class="se">\n</span><span class="s2">"</span><span class="p">;</span>
<span class="p">}</span>

<span class="k">function</span> <span class="nf">fillArray</span><span class="p">(</span> <span class="nv">$depth</span><span class="p">,</span> <span class="nv">$max</span> <span class="p">)</span> <span class="p">{</span>
    <span class="k">static</span> <span class="nv">$seed</span><span class="p">;</span>
    <span class="k">if</span> <span class="p">(</span><span class="nb">is_null</span><span class="p">(</span><span class="nv">$seed</span><span class="p">))</span> <span class="p">{</span>
        <span class="nv">$seed</span> <span class="o">=</span> <span class="k">array</span><span class="p">(</span><span class="s1">'a'</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">'c'</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="s1">'e'</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="s1">'g'</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="s1">'i'</span><span class="p">,</span> <span class="mi">10</span><span class="p">);</span>
    <span class="p">}</span>
    <span class="k">if</span> <span class="p">(</span><span class="nv">$depth</span> <span class="o">&lt;</span> <span class="nv">$max</span><span class="p">)</span> <span class="p">{</span>
        <span class="nv">$node</span> <span class="o">=</span> <span class="k">array</span><span class="p">();</span>
        <span class="k">foreach</span> <span class="p">(</span><span class="nv">$seed</span> <span class="k">as</span> <span class="nv">$key</span><span class="p">)</span> <span class="p">{</span>
            <span class="nv">$node</span><span class="p">[</span><span class="nv">$key</span><span class="p">]</span> <span class="o">=</span> <span class="nx">fillArray</span><span class="p">(</span><span class="nv">$depth</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="nv">$max</span><span class="p">);</span>
        <span class="p">}</span>
        <span class="k">return</span> <span class="nv">$node</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="k">return</span> <span class="s1">'empty'</span><span class="p">;</span>
<span class="p">}</span>
</pre></div>

<p><br></p>
<h3>更多建议</h3>
<p><strong>JSON</strong> 比 PHP 的序列化格式更简单、更快，应该使用， <strong>除非</strong> ：</p>
<ul>
<li>您正在存储深度嵌套的数组：：<code>json_decode()</code>“如果 JSON 编码数据的深度超过 127 个元素，则此函数将返回 false。”</li>
<li>您正在存储需要反序列化为正确类的对象</li>
<li>您正在与不支持 json_decode 的旧 PHP 版本交互</li>
</ul>
<p><br><br><a href="posts/preferred-method-to-store-php-arrays-json-encode-vs-serialize/">查看原文</a></p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/ru-he-jiang-wpf-bang-ding-yu-relativesource-yi-qi-shi-yong/" class="u-url">如何将 WPF 绑定与 RelativeSource 一起使用？</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="posts/ru-he-jiang-wpf-bang-ding-yu-relativesource-yi-qi-shi-yong/" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-17T20:25:07+08:00" itemprop="datePublished" title="2023-02-17 20:25">2023-02-17 20:25</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>如何使用<code>RelativeSource</code>WPF 绑定以及有哪些不同的用例？</p>
<p><br><br></p>
<h2>解答</h2>
<p>如果你想绑定到对象的另一个属性：</p>
<div class="code"><pre class="code literal-block">{Binding Path=PathToProperty, RelativeSource={RelativeSource Self}}
</pre></div>

<p>如果你想获得祖先的财产：</p>
<div class="code"><pre class="code literal-block">{Binding Path=PathToProperty,
    RelativeSource={RelativeSource AncestorType={x:Type typeOfAncestor}}}
</pre></div>

<p>如果您想获得模板化父级的属性（这样您就可以在 ControlTemplate 中进行 2 种方式绑定）</p>
<div class="code"><pre class="code literal-block">{Binding Path=PathToProperty, RelativeSource={RelativeSource TemplatedParent}}
</pre></div>

<p>或者，更短（这只适用于单向绑定）：</p>
<div class="code"><pre class="code literal-block">{TemplateBinding Path=PathToProperty}
</pre></div>

<p><br></p>
<h3>更多建议</h3>
<div class="code"><pre class="code literal-block">Binding RelativeSource={
    RelativeSource Mode=FindAncestor, AncestorType={x:Type ItemType}
}
...
</pre></div>

<p>的默认属性<code>RelativeSource</code>是<code>Mode</code>property。此处给出了一组完整的有效值（来自 MSDN）：</p>
<ul>
<li>
<p><em>PreviousData</em> 允许您绑定正在显示的数据项列表中的前一个数据项（不是包含该数据项的控件）。</p>
</li>
<li>
<p><em>TemplatedParent</em> 指的是应用模板（其中存在数据绑定元素）的元素。这类似于设置 TemplateBindingExtension，并且仅当 Binding 在模板内时才适用。</p>
</li>
<li>
<p><em>Self</em> 指的是要在其上设置绑定的元素，并允许您将该元素的一个属性绑定到同一元素上的另一个属性。</p>
</li>
<li>
<p><em>FindAncestor</em> 引用数据绑定元素的父链中的祖先。您可以使用它来绑定到特定类型或其子类的祖先。如果您想要指定 AncestorType 和/或 AncestorLevel，这就是您使用的模式。</p>
</li>
</ul>
<p><br><br><a href="posts/how-do-i-use-wpf-bindings-with-relativesource/">查看原文</a></p>
    </div>
    </article>
</div>

        <nav class="postindexpager"><ul class="pager">
<li class="previous">
                <a href="index-946.html" rel="prev">Newer posts</a>
            </li>
            <li class="next">
                <a href="index-944.html" rel="next">Older posts</a>
            </li>
        </ul></nav>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2023         Go to StackOverflow Chinese Site  <a href="http://stackoverflow.ink">StackOverflow-ZH</a>  
            
        </footer>
</div>
</div>


            <script src="assets/js/all-nocdn.js"></script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script><script src="assets/js/search.js"></script>
</body>
</html>
