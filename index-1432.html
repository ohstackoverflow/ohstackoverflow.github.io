<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="description" content="This is a snapshot site for StackOverflow">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>StackOverflow Snapshot (old posts, page 1432) | StackOverflow Snapshot</title>
<link href="assets/css/all-nocdn.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#5670d4">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="canonical" href="https://ohstackoverflow.netlify.app/index-1432.html">
<link rel="prev" href="index-1433.html" type="text/html">
<link rel="next" href="index-1431.html" type="text/html">
<!--[if lt IE 9]><script src="assets/js/html5.js"></script><![endif]-->
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-inverse navbar-static-top"><div class="container">
<!-- This keeps the margins nice -->
        <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="https://ohstackoverflow.netlify.app/">

                <span id="blog-title">StackOverflow Snapshot</span>
            </a>
        </div>
<!-- /.navbar-header -->
        <div class="collapse navbar-collapse" id="bs-navbar" aria-expanded="false">
            <ul class="nav navbar-nav">
<li>
<a href="archive.html">Archive</a>
                </li>
<li>
<a href="categories/">Tags</a>

                
            </li>
</ul>
<ul class="nav navbar-nav navbar-right">
<div style="display:table;min-height:5rem;min-width:27rem;">
					<div class="input-group" style="display: table-cell;vertical-align: middle;">
						<input id="words" type="text" class="form-control" style="max-width:22rem;" onkeydown="if(event.keyCode==13){btn.click()}"><span class="input-group-btn" style="float:left">
							<button id="btn" class="btn btn-default" type="button" data-toggle="modal" data-target="#myModal">
								<span class="glyphicon glyphicon-search">
							</span></button>
						</span>
					</div>
<!-- /input-group -->
				</div>

				
                
                
                
            </ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><!-- 模态框（Modal） --><div class="modal fade" id="myModal" tabindex="-1" role="dialog" aria-labelledby="myModalLabel" aria-hidden="true">
	<div class="modal-dialog">
		<div class="modal-content">
			<div class="modal-header">
				<button type="button" class="close" data-dismiss="modal" aria-hidden="true">×
				</button>
				<h4 class="modal-title" id="myModalLabel">
					查找结果
				</h4>
			</div>
			<div class="modal-body">
				<div id="search-count" style="min-height:4rem;">
				查找中，请稍后...
				</div>
				<div id="search-result">
				</div>

				
			</div>
			<div class="modal-footer">
				<button type="button" class="btn btn-default" data-dismiss="modal">
					关闭
				</button>
			</div>
		</div>
<!-- /.modal-content -->
	</div>
<!-- /.modal-dialog -->
</div>
<!-- /.modal -->

<div class="container" id="content" role="main">
    <div class="body-content">
        <!--Body content-->
        <div class="row">
            
            

    


    
<div class="postindex">
    <article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/how-to-propagate-fire-recurrent-neural-networks-rnn/" class="u-url">How to propagate/fire recurrent neural networks(RNN)?</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="posts/how-to-propagate-fire-recurrent-neural-networks-rnn/" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T03:43:33+08:00" itemprop="datePublished" title="2023-02-28 03:43">2023-02-28 03:43</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>I'm learning about artificial neural networks and have implemented a standard
feed-forward net with a couple hidden layers. Now, I'm trying to understand
how a recurrent neural network(RNN) works in practice, and am having trouble
with how activation/propagation flows through the network.</p>
<p>In my feed-forward, the activation is a simple layer by layer firing of the
neurons. In a recurrent net, the neurons connect back to previous layers and
sometimes themselves, so the way to propagate the network must be different.
Trouble is, I can't seem to find an explanation of exactly how the propagation
happens.</p>
<p>How might it occur say for a network like this:</p>
<div class="code"><pre class="code literal-block"><span class="n">Input1</span><span class="w"> </span><span class="o">---&gt;</span><span class="n">Neuron</span><span class="w"> </span><span class="n">A1</span><span class="w"> </span><span class="o">---------&gt;</span><span class="w">  </span><span class="n">Neuron</span><span class="w"> </span><span class="n">B1</span><span class="w"> </span><span class="o">---------------------&gt;</span><span class="w"> </span><span class="kr">Output</span>
<span class="w">                </span><span class="o">^</span><span class="w">                   </span><span class="o">^</span><span class="w">     </span><span class="o">^</span><span class="w">      </span><span class="o">|</span>
<span class="w">                </span><span class="o">|</span><span class="w">                   </span><span class="o">|</span><span class="w">     </span><span class="o">--------</span>
<span class="w">                </span><span class="o">|</span><span class="w">                   </span><span class="o">|</span>
<span class="n">Input2</span><span class="w"> </span><span class="o">---&gt;</span><span class="n">Neuron</span><span class="w"> </span><span class="n">A2</span><span class="w"> </span><span class="o">---------&gt;</span><span class="w">  </span><span class="n">Neuron</span><span class="w"> </span><span class="n">B2</span>
</pre></div>

<p>I imagined it would be a rolling activation with a gradual die down as the
neuron's thresholds decrease the neuron firing to 0, much like in biology, but
it appears there is a much more computational efficient way to do this through
derivatives?</p>
<p><br><br></p>
<h2>Answer</h2>
<p>I think I have a grasp now on the basic principle of propagating recurrent
versus feed-forward networks: an explicit time step.</p>
<p>In a feed-forward, the propagation happens layer by layer, so Layer 1 neurons
fire first, followed by Layers 2, 3 etc, so the propagation is one neuron
activation stimulating activation in the neurons that take it as input.</p>
<p>Alternatively, we can think of propagation instead as the neurons whose inputs
are active at any given point in time are the ones to fire. So if we have a
time t=0 were Layer 1 neurons are active, at the next time t=1 the next layer
Layer 2 will activate, since the neurons in Layer 2 take the neurons in Layer
1 as input.</p>
<p>While the difference in thinking may seem like semantics, for me it was
crucial in figuring out how to implement recurrent networks. In the feed-
forward the time step is implicit, and the code passes over the neuron layers
in turn, activating them like falling dominoes. In a recurrent network, trying
the falling-domino way of activation where every neuron specifies what neuron
it activates next would be a nightmare for large, convoluted networks.
Instead, it makes sense to poll very neuron in the network at a give time t,
to see if it activates based on its inputs.</p>
<p>There are of course many different types of recurrent neural network, but I
think it is this crucial explicit time step that is the key to recurrent
network propagation.</p>
<p>The differential equations part I was wondering about comes in to play if
instead of having discrete time steps of t be 0, 1, 2, etc., to try and have
smoother, more continuous network flow by modeling the propagation over very
small time increments, like 0.2, 0.1, 0.05, etc.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/multithreaded-a-search-in-java-or-lisp-or-c/" class="u-url">Multithreaded A* Search in Java or Lisp or C#</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="posts/multithreaded-a-search-in-java-or-lisp-or-c/" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T03:43:16+08:00" itemprop="datePublished" title="2023-02-28 03:43">2023-02-28 03:43</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>Is there a good way to do a multithreaded A* search? Single threaded is fairly
easy, as given in (for example) Artificial Intelligence: A Modern Approach,
but I have not come across a good multithreaded version.</p>
<p>Assume a sane language like Java or C# or Lisp where we have thread pools and
work blocks, and of course garbage collection.</p>
<p><br><br></p>
<h2>Answer</h2>
<p>I recommend reading this paper:</p>
<p>"Parallel bidirectional A* search on a symmetry multiprocessor"</p>
<p>There is also another paper, also at IEEE called:</p>
<p>"Parallel Astar search on message-passing architectures"</p>
<p>Both papers find novel methods for gaining quite a bit of speedup.</p>
    </div>
    </article><article class="h-entry post-text" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title"><a href="posts/looping-through-training-data-in-neural-networks-backpropagation-algorithm/" class="u-url">Looping through training data in Neural Networks Backpropagation Algorithm</a></h1>
        <div class="metadata">
            <p class="byline author vcard"><span class="byline-name fn" itemprop="author">
                <a href="authors/arya/">Arya</a>
            </span></p>
            <p class="dateline">
            <a href="posts/looping-through-training-data-in-neural-networks-backpropagation-algorithm/" rel="bookmark">
            <time class="published dt-published" datetime="2023-02-28T03:42:58+08:00" itemprop="datePublished" title="2023-02-28 03:42">2023-02-28 03:42</time></a>
            </p>
        </div>
    </header><div class="e-content entry-content">
    <p>How many times do I use a sample of training data in one training cycle? Say I
have 60 training data. I go through the 1st row and do a forward pass and
adjust weights using results from backward pass. Using the sigmoidal function
as below:</p>
<div class="code"><pre class="code literal-block">Forward pass 
Si = sum of (Wi * Uj)
Ui = f(Si) = 1 / 1 + e^ - Si

Backward pass 
Output Cell = (expected -Ui)(f'(Si)), where 
f'(Si) = Ui(1-Ui)
</pre></div>

<p>Do I then go through the 2nd row and do the same process as the 1st or do I go
around the 1st row until the error is less?</p>
<p>I hope someone can help please</p>
<p><br><br></p>
<h2>Answer</h2>
<h2>Training the network</h2>
<p>You should use each instance of the training set once per training epoch.</p>
<blockquote>
<p>A <em>training epoch</em> is a complete cycle through your dataset.</p>
</blockquote>
<p>After you've looped through the dataset and calculated the deltas, you should
adjust the weights of the network. Then you may perform a new forward pass on
the neural network and do another training epoch, looping through your
training dataset.  </p>
<p><strong>Graphical representation</strong><br>
A really great graphical representation of backpropagation may be found at
this link.</p>
<hr>
<h2>Single-step training</h2>
<p>There are two approaches to train you network to perform classification on a
dataset. The easiest method is called single-step or online learning. This is
the method you will find in most litterature, and it is also the fastest to
converge. As you train your network you will calculate the deltas for each
layer and adjust the weights for <em>each instance of your dataset</em>.</p>
<p>Thus if you have a dataset of 60 instances, this means you should have
adjusted the weights 60 times before the training epoch is over.</p>
<h2>Batch training</h2>
<p>The other approach is called batch training or offline learning. This approach
often yields a network with a lower residual error. When you train the network
you should calculate the deltas for each layer for every instance of the
dataset, and then finally average the individual deltas and <em>correct the
weights once per epoch</em>.</p>
<p>If you have a dataset of 60 instances, this means you should have adjusted the
weights once before the training epoch is over.</p>
    </div>
    </article>
</div>

        <nav class="postindexpager"><ul class="pager">
<li class="previous">
                <a href="index-1433.html" rel="prev">Newer posts</a>
            </li>
            <li class="next">
                <a href="index-1431.html" rel="next">Older posts</a>
            </li>
        </ul></nav>
</div>
        <!--End of body content-->

        <footer id="footer">
            Contents © 2023         Go to StackOverflow Chinese Site  <a href="http://stackoverflow.ink">StackOverflow-ZH</a>  
            
        </footer>
</div>
</div>


            <script src="assets/js/all-nocdn.js"></script><!-- fancy dates --><script>
    moment.locale("en");
    fancydates(0, "YYYY-MM-DD HH:mm");
    </script><!-- end fancy dates --><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script><script src="assets/js/search.js"></script>
</body>
</html>
